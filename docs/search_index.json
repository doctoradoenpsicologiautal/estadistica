[["index.html", "Estadística con R Preámbulo", " Estadística con R Facultad de Psicología, Universidad de Talca 2022-12-25 Preámbulo Este curso se basa en Statistics without tears de Derek Rowntree y Discovering statistics using R de Andy Field, Jeremy Miles y Zoë Field. Este curso también utiliza material del libro &quot;Discovering statistics using R&quot;. Este material es accesible aquí. Este curso asume que no sabes nada de estadística. Sin embargo, si asume que sabes aritmética básica y fracciones. La base de datos que vamos a utilizar se encuentra aquí. ¡Que disfrutes el curso! "],["introducción-a-la-estadística.html", "Capítulo 1 Introducción a la estadística 1.1 ¿Qué es la estadística? 1.2 ¿Variables? 1.3 Diseños experimentales 1.4 ¿Qué medimos? 1.5 Un prueba estadística 1.6 ¿Que diseño usaré? 1.7 Una historia fantástica 1.8 ¿Randomizar?", " Capítulo 1 Introducción a la estadística En este capítulo introductorio vamos a ir paso a paso. Vamos a hacernos de una visión general de la estadística y vamos a entender por qué tenemos que hacer &quot;inferencias&quot;, es decir, sacar conclusiones de algunos datos que recolectamos para saber algo del mundo alredor nuestro (de una población en particular). 1.1 ¿Qué es la estadística? Revisa este video (9') y trata de responder: ¿Qué es la estadística descriptiva y la estadística inferencial? ¿Qué es una población y una muestra? ¿Qué son los &quot;parámetros&quot;&quot; y los &quot;estadísticos&quot;? ¿Por qué necesitamos obtener una muestra para nuestros experimentos? ¿Por qué necesitamos las probabilidades para realizar análisis estadísticos? 1.2 ¿Variables? Revisa este video (9') y trata de responder: ¿Qué tipos de variables existen? ¿Que significa definir variables y operacionalizar? ¿Que es una variable independiente? ¿Que es una variable dependiente? ¿Cómo se construye una hipótesis? 1.3 Diseños experimentales Revisa este video (4') y trata de responder: ¿Qué tipos de diseño experimental existen? ¿Cuáles son las ventajas y desventajas de cada uno de ellos? 1.4 ¿Qué medimos? Revisa este video (7') y trata de responder: ¿Qué aspectos son importantes a la hora de diseñar un experimento? ¿Qué es la validez de una medición? ¿Qué es la replicabilidad de una medición? ¿Qué es un factor confundente? 1.5 Un prueba estadística Revisa este video (14') y trata de responder: ¿Por qué es tan importante evaluar como cambian (o varían) las variables? ¿Qué hace un prueba estadística (en términos de los cambios que experimenta una variable)? ¿Qué es la variación sistemática (VS)? ¿Qué es la variación no sistemática (VNS)? Sí una manipulación experimental produce un efecto genuino como será la razón VS/VNS? 1.6 ¿Que diseño usaré? Revisa este video (4') y trata de responder: ¿Cuál es la diferencia entre un diseño intra-sujetos y un diseño entre-sujetos? ¿Cuál es la relación entre un diseño experimental y su análisis estadístico asociado? 1.7 Una historia fantástica Revisa este video (9') y trata de responder: ¿Quién fué Roland Fisher? ¿Dé dónde viene el 5% (o p = 0.05) que usamos en estadística? 1.8 ¿Randomizar? Revisa este video (6') y trata de responder: ¿Para que se usa la randomización? ¿Qué son los efectos de práctica y de aburrimiento en un diseño intra-sujetos? ¿Cómo podemos confeccionar un buen diseño entre-sujetos? "],["conceptos-estadísticos.html", "Capítulo 2 Conceptos estadísticos 2.1 La significancia 2.2 Colas 2.3 Errores estadísticos 2.4 Tamaño &amp; poder 2.5 Planificar mi estudio", " Capítulo 2 Conceptos estadísticos 2.1 La significancia Revisa este video (9') y trata de responder: ¿Qué me dice y qué no me dice el valor de p? ¿Cómo se interpreta un resultado estadístico nulo? 2.2 Colas Revisa este video (11') y trata de responder: ¿Cuál es la diferencia entre una hipótesis de una cola y una hipótesis de dos colas? ¿Por qué los criterios de significancia son más altos para una hipótesis de una cola que para una hipótesis de dos colas? 2.3 Errores estadísticos Revisa este video (9') y trata de responder: ¿Qué es un error de tipo I? ¿Qué es un error de tipo II? ¿Por qué hay un balance entre el error de tipo I y II? ¿Qué es mas perjudicial para un estudio? ¿Un error de tipo I o II? 2.4 Tamaño &amp; poder Revisa este video (8') y trata de responder: ¿Qué es el tamaño del efecto? ¿Cómo se contabiliza el tamaño del efecto? ¿Qué es el poder estadístico? ¿Cómo definimos el tamaño de la muestra que necesitamos para un experimento? 2.5 Planificar mi estudio Revisa este video (9') y trata de responder: ¿Cómo planificar mejor mi estudio? ¿Por qué debo planificar mi análisis ANTES de recolectar los datos? "],["programación.html", "Capítulo 3 Programación 3.1 ¿Que significa programar? 3.2 La shell (consola) versus el script 3.3 Intro a la programación 3.4 Empezando a programar 3.5 Trabajando con data frames 3.6 Importando datos 3.7 Seleccionando datos 3.8 Transformado datos en formato long a wide y viceversa 3.9 Exportando datos 3.10 En la práctica", " Capítulo 3 Programación En este capítulo te voy a mostrar las primeras ideas para que puedas programar en R. 3.1 ¿Que significa programar? Revisa este video (8') y trata de responder: ¿Qué habilidades permite desarrollar el conocimiento de programación? ¿Qué es un algoritmo? ¿Qué es un lenguaje de programación? 3.2 La shell (consola) versus el script Revisa este video (6') y trata de responder: ¿Cuál es la diferencia entre un compilador y un intérprete? ¿Cuál es la diferencia entre usar la shell (consola) y usar un script? ¿Qué es el CRAN? 3.3 Intro a la programación Revisa este video (16') para comenzar a trabajar en RStudio. Mas abajo repetiré el mismo contenido para que vayas viendo como usar el material que viene mas abajo. La idea es que vayas trabajando tus propios scripts ordenadamente en tu computador. 3.4 Empezando a programar En lo que sigue te recomiendo que crees un script (lo nombres &quot;Curso_1&quot; o algo así) y que vayas escribiendo o copiando lo que vamos viendo más abajo. En general, luego de una línea de código aparece el resultado precedido por ##. En un script es esencial incluir comentarios. De esta manera puedes acordarte (y otros puedes entender) que está haciendo tu código. Para escribir un comentario debes anteponer un #. En el inicio de un script es un buen hábito poner una fecha y tus iniciales. Por ejemplo: # JLUF 16/08/2022 También es buena idea que agregues una breve descripción de lo que hace tu código. # JLUF 16/08/2022 # Estadística descriptiva R tiene algunas funciones integradas. Por ejemplo: el promedio (mean) y la desviación estándar (sd). Para probar estas funciones podemos aplicarlas a una series de números (o vector). Para crear un vector podemos usar la c y un paréntesis. Lo que hacemos con la c es concatenar números. # JLUF 16/08/2022 # Estadística descriptiva # Promedio entre 2 y 3 mean(c(2,3)) ## [1] 2.5 # Deviación estándar entre 2 y 3 sd(c(2,3)) ## [1] 0.7071068 Comúnmente para hacer un cálculo de manera óptima usamos algo que se llama asignación. Es decir, creamos una variable y le asignamos un valor. Por ejemplo, definimos que a equivale a 2 y b equivale a 3. Luego podemos usar solamente esas variables para hacer cálculos. Para asignar ponemos una flecha: &quot;&lt;-&quot; a &lt;- 2 b &lt;- 3 mean(c(a,b)) ## [1] 2.5 También podemos crear variables que contengan texto. Por ejemplo, podemos crear una lista con los integrantes de Metallica. metallica &lt;- c(&quot;Lars&quot;, &quot;James&quot;, &quot;Jason&quot;, &quot;Kirk&quot;) metallica ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Jason&quot; &quot;Kirk&quot; Este es un vector de carácteres. Además, puedes usar las funciones str() y class() para averiguar la naturaleza de estas variables. class(metallica) ## [1] &quot;character&quot; str(metallica) ## chr [1:4] &quot;Lars&quot; &quot;James&quot; &quot;Jason&quot; &quot;Kirk&quot; Para inspeccionar cada elemento de esta variable puedes usar el paréntesis cuadrado. Esto se llama indexar. Por ejemplo, para ver el primer elemento puedes hacer lo siguiente: metallica[1] ## [1] &quot;Lars&quot; O podrías ver desde el primero al segundo. metallica[1:2] ## [1] &quot;Lars&quot; &quot;James&quot; O podrías ver desde el segundo al tercero. metallica[2:3] ## [1] &quot;James&quot; &quot;Jason&quot; Si te das cuenta que tu lista tiene un elemento incorrecto lo puedes eliminar. Para ello debes crear una nueva variable a partir de metallica pero dentro del paréntesis cuadrado usamos una fórmula lógica. La fórmula nos permite seleccionar ciertos elementos. Por ejemplo, si queremos todos los elementos de la variable metallica excepto el elemento Jason (de ahí viene la parte !=) podemos hacer lo siguente: new_metallica &lt;- metallica[metallica != &quot;Jason&quot;] new_metallica ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; También puedes eliminar dos elementos indicandole a R que quieres eliminar los elementos del 2 al 3: metallica_duo &lt;- metallica[-c(2,3)] metallica_duo ## [1] &quot;Lars&quot; &quot;Kirk&quot; Lo que podríamos hacer enseguida es agregar un nuevo elemento. Para hacer esto concatenamos, usado la c, un variable con otra variable. Por ejemplo, para concatenar new_metallica con &quot;Rob&quot; hacemos lo siguiente: last_metallica &lt;- c(new_metallica, &quot;Rob&quot;) last_metallica ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; &quot;Rob&quot; Incluso podríamos elegir dónde agregar a Rob. Por ejemplo, lo podemos agregar al final. last_metallica_2 &lt;- c(&quot;Rob&quot;, new_metallica) last_metallica_2 ## [1] &quot;Rob&quot; &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; O lo podemos agregar en la penúltima posición: last_metallica_3 &lt;- c(new_metallica[1:2], &quot;Rob&quot;, new_metallica[3]) last_metallica_3 ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Rob&quot; &quot;Kirk&quot; Ejercicio: Crea una variable que represente a tu banda favorita. 3.5 Trabajando con data frames Podemos crear variables de distintos tipos (lista de palabras o listas de números): metallicaNames &lt;- c(&quot;Lars&quot;, &quot;James&quot;, &quot;Kirk&quot;, &quot;Rob&quot;) metallicaNames ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; &quot;Rob&quot; metallicaAges &lt;- c(47, 47, 48, 46) metallicaAges ## [1] 47 47 48 46 metallicaColor &lt;- c(&quot;Blue&quot;, &quot;Red&quot;, &quot;Yellow&quot;, &quot;Green&quot;) metallicaColor ## [1] &quot;Blue&quot; &quot;Red&quot; &quot;Yellow&quot; &quot;Green&quot; Pero más importante que eso es que podemos reunir estas variables en una estructura mas compleja. Esta estructura se llama data frame. Un data frame puede acomodar distintos tipos de datos y los pone en distintas &quot;cajas&quot;. Para crear un data frame usamos la función data.frame metallicaDataFrame &lt;- data.frame(metallicaNames, metallicaAges, metallicaColor) metallicaDataFrame ## metallicaNames metallicaAges metallicaColor ## 1 Lars 47 Blue ## 2 James 47 Red ## 3 Kirk 48 Yellow ## 4 Rob 46 Green Fijate que al crear el data frame el nombre de la variable se vuelve el encabezado de esos datos en el dataframe. Si queremos podemos cambiarle el nombre a estos encabezados. Podemos hacer esto usando la función colnames. colnames(metallicaDataFrame) &lt;- c(&quot;name&quot;, &quot;age&quot;, &quot;color&quot;) metallicaDataFrame ## name age color ## 1 Lars 47 Blue ## 2 James 47 Red ## 3 Kirk 48 Yellow ## 4 Rob 46 Green O mejor aún puedes definirlo al momento de crear la data frame: metallicaDataFrame &lt;- data.frame(Name = metallicaNames, Age = metallicaAges, Color = metallicaColor) metallicaDataFrame ## Name Age Color ## 1 Lars 47 Blue ## 2 James 47 Red ## 3 Kirk 48 Yellow ## 4 Rob 46 Green Mira también la estructura de este data frame. Verás que hay 4 observacions y 3 variables. Dos de estas listas son carácteres. str(metallicaDataFrame) ## &#39;data.frame&#39;: 4 obs. of 3 variables: ## $ Name : chr &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; &quot;Rob&quot; ## $ Age : num 47 47 48 46 ## $ Color: chr &quot;Blue&quot; &quot;Red&quot; &quot;Yellow&quot; &quot;Green&quot; Para mirar cada una de las lista puedes usar el símbolo $ metallicaDataFrame$Name ## [1] &quot;Lars&quot; &quot;James&quot; &quot;Kirk&quot; &quot;Rob&quot; metallicaDataFrame$Age ## [1] 47 47 48 46 metallicaDataFrame$Color ## [1] &quot;Blue&quot; &quot;Red&quot; &quot;Yellow&quot; &quot;Green&quot; Además, podemos eliminar una de estas listas si no nos interesa. metallicaDataFrame$Color &lt;- NULL metallicaDataFrame ## Name Age ## 1 Lars 47 ## 2 James 47 ## 3 Kirk 48 ## 4 Rob 46 Mas importante aún es el hecho que podemos hacer cálculos matemáticos de forma masiva. Primero, agreguemos una columna nueva: metallicaDataFrame$ChildAge &lt;- c(12, 12, 4, 6) metallicaDataFrame ## Name Age ChildAge ## 1 Lars 47 12 ## 2 James 47 12 ## 3 Kirk 48 4 ## 4 Rob 46 6 Luego, podemos calcular la diferencia entre estas dos columnas y la asignamos a una nueva columna: metallicaDataFrame$FatherhoodAge &lt;- metallicaDataFrame$Age - metallicaDataFrame$ChildAge metallicaDataFrame ## Name Age ChildAge FatherhoodAge ## 1 Lars 47 12 35 ## 2 James 47 12 35 ## 3 Kirk 48 4 44 ## 4 Rob 46 6 40 Podemos agregar mas datos a partir de otra variable. Y para crear variables podemos concatenar pedazos de datos. Por ejemplo, podríamos querer crear un set de datos de 15 valores que representen 3 condiciones experimentales. Cada condición experimental podría estar repetida 5 veces. Si queremos repetir la condición 1 tres veces hacemos: rep(1,5) ## [1] 1 1 1 1 1 El primer parámetro dentro de la función rep es el número que quieres repetir. El segundo parámetro define las veces que se va a definir ese número. Luego, podemos concatenar repeticiones de distintos números. vector1 &lt;- c(rep(1,5), rep(2,5), rep(3,5)) vector1 ## [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 Y eso lo podemos agregar luego en una data frame. Veamos un ejemplo mas elaborado. Vamos a crear un base de datos sobre el nombre, la fecha de nacimiento y el trabajo de distintas personas. Para que R identifique los números como fechas usamos la función as.Date(por defecto el formato es yyyy-mm-dd). name &lt;- c(&quot;Ben&quot;, &quot;Martin&quot;,&quot;Andy&quot;,&quot;Paul&quot;, &quot;Graham&quot;,&quot;Carina&quot;,&quot;Karina&quot;,&quot;Doug&quot;,&quot;Mark&quot;, &quot;Zoe&quot;) name ## [1] &quot;Ben&quot; &quot;Martin&quot; &quot;Andy&quot; &quot;Paul&quot; &quot;Graham&quot; &quot;Carina&quot; &quot;Karina&quot; &quot;Doug&quot; &quot;Mark&quot; &quot;Zoe&quot; birth_date &lt;- as.Date(c(&quot;1977-07-03&quot;, &quot;1969-05-24&quot;, &quot;1973-06-21&quot;, &quot;1970-07-16&quot;, &quot;1949-10-10&quot;, &quot;1983-11-05&quot;, &quot;1987-10-08&quot;, &quot;1989-09-16&quot;, &quot;1973-05-20&quot;, &quot;1984-11-12&quot;)) birth_date ## [1] &quot;1977-07-03&quot; &quot;1969-05-24&quot; &quot;1973-06-21&quot; &quot;1970-07-16&quot; &quot;1949-10-10&quot; &quot;1983-11-05&quot; &quot;1987-10-08&quot; ## [8] &quot;1989-09-16&quot; &quot;1973-05-20&quot; &quot;1984-11-12&quot; job &lt;- c(rep(1, 5), rep(2, 5)) # que es el equivalente a: job &lt;- c(1,1,1,1,1,2,2,2,2,2) job ## [1] 1 1 1 1 1 2 2 2 2 2 La variable job es categórica. El número 1 indica que es un profesor y el 2 indica que es un estudiante. Para R son sólo números. Para decirle a R que es una variable categórica (o en el lenguaje de R un factor) tenemos que indicarselo usando la función factor. Además, podemos crear etiquetas o nombres que nos hagan mas sentido a nosotros. En este caso este factor tiene dos niveles: Lecturer y Student. job &lt;- factor(job, levels = c(1:2), labels = c(&quot;Lecturer&quot;, &quot;Student&quot;)) job ## [1] Lecturer Lecturer Lecturer Lecturer Lecturer Student Student Student Student Student ## Levels: Lecturer Student Luego, el paso final es poner todo junto: dataframe1 &lt;- data.frame(name, birth_date, job) dataframe1 ## name birth_date job ## 1 Ben 1977-07-03 Lecturer ## 2 Martin 1969-05-24 Lecturer ## 3 Andy 1973-06-21 Lecturer ## 4 Paul 1970-07-16 Lecturer ## 5 Graham 1949-10-10 Lecturer ## 6 Carina 1983-11-05 Student ## 7 Karina 1987-10-08 Student ## 8 Doug 1989-09-16 Student ## 9 Mark 1973-05-20 Student ## 10 Zoe 1984-11-12 Student Ejercicio: Crea una data frame con los integrantes de tu grupo familiar o de tu curso. En tu data frame agrega el nombre, apellido y la edad. 3.6 Importando datos La mayoría del tiempo vas a importar más que crear datos. Para ello cuando trabajes en R debes decirle en que carpeta de tu computador están esos archivos. Es decir, debes definir tu directorio de trabajo con la función setwd Por ejemplo, para mí sería algo así: setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Stats_UTalca/database_2020_DocPsychol&quot;) La función getwd() (sin nada entre paréntesis) te permite sabes cual es tu directorio actual. getwd() ## [1] &quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot; Para importar datos puedes usar distintas funciones. Por ejemplo, para importar datos de tipo .txt debemos usar la función read.delim setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) dat &lt;- read.delim(file = &quot;data/facebook_friends_1.txt&quot;) dat ## X108 ## 1 103 ## 2 252 ## 3 121 ## 4 93 ## 5 57 ## 6 40 ## 7 53 ## 8 22 ## 9 116 ## 10 98 Si ejecutas este comando en tu computador y lo comparas con los datos originales te darás cuenta que hay un error. Cuando importate tus datos a R perdiste el 108. Esto occurre porque por defecto esta función asume que tus datos tienen un encabezado (el &quot;header&quot;). Es decir, el parámetro llamado &quot;header&quot; esta fijado en &quot;TRUE&quot;&quot;, que significa que la función espera un encabezado. Para corregir esto debes explícitamente decirle a R que no hay header, así: setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) dat &lt;- read.delim(file = &quot;data/facebook_friends_1.txt&quot;, header = FALSE) dat ## V1 ## 1 108 ## 2 103 ## 3 252 ## 4 121 ## 5 93 ## 6 57 ## 7 40 ## 8 53 ## 9 22 ## 10 116 ## 11 98 Fijate ahora que R le asigna un nombre a tu columna (V1). Es buena práctica ponerme un nombre a tu columna que haga sentido. Por ejemplo, podemos llamarla &quot;friends&quot;: colnames(dat) &lt;- c(&quot;friends&quot;) dat ## friends ## 1 108 ## 2 103 ## 3 252 ## 4 121 ## 5 93 ## 6 57 ## 7 40 ## 8 53 ## 9 22 ## 10 116 ## 11 98 Cuando tus datos ya tienen un encabezado te ahorras estos problemas. Fjate que para importar este otro archivo no necesitas definir que el header a FALSE. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) dat &lt;- read.delim(file = &quot;data/facebook_friends_2.txt&quot;) dat ## AMIGOS ## 1 108 ## 2 103 ## 3 252 ## 4 121 ## 5 93 ## 6 57 ## 7 40 ## 8 53 ## 9 22 ## 10 116 ## 11 98 Típicamente vas a importar que has registrado en archivos de tipo Excel (.xls o .xlsx). El archivo Excel se puede transformar en un archivo de tipo csv. Este arhivo csv se importa de la siguiente manera: setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) dat2 &lt;- read.csv(&quot;data/facebook_friends_1.csv&quot;, header = FALSE) dat2 ## V1 ## 1 108 ## 2 103 ## 3 252 ## 4 121 ## 5 93 ## 6 57 ## 7 40 ## 8 53 ## 9 22 ## 10 116 ## 11 98 Para importar archivos siempre asegurate que has seteado bien tu directorio de trabajo y que los archivos están ahí. Ejercicio: Trata de importar algún archivo csv a tu sesión de R. 3.7 Seleccionando datos Una vez que tienes datos en tu espacio de trabajo en R la idea es que puedas manipular esos datos. Uno de los aspectos fundamentales de esta manipulación es la selección de datos. Primero, importemos alguna base de datos. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) lecturerDat &lt;- read.csv(&quot;data/lecturer_data.csv&quot;) lecturerDat ## name birth_date job friends alcohol income neurotic ## 1 Ben 07/03/1977 1 5 10 20000 10 ## 2 Martin 5/24/1969 1 2 15 40000 17 ## 3 Andy 6/21/1973 1 0 20 35000 14 ## 4 Paul 7/16/1970 1 4 5 22000 13 ## 5 Graham 10/10/1949 1 1 30 50000 21 ## 6 Carina 11/05/1983 2 10 25 5000 7 ## 7 Karina 10/08/1987 2 12 20 100 13 ## 8 Doug 1/23/1989 2 15 16 3000 9 ## 9 Mark 5/20/1973 2 12 17 10000 14 ## 10 Zoe 11/12/1984 2 17 18 10 13 Antes de proceder vamos a transformar la variable &quot;job&quot; a factor, y vamos a crear rótulos que nos hagan mas sentido. Esto lo podemos hacer porque sabemos que el rótulo 1 corresponde a &quot;Lecturer&quot; y el rótulo 2 corresponde a &quot;Student&quot;. lecturerDat$job &lt;- factor(lecturerDat$job, levels = c(1:2), labels = c(&quot;Lecturer&quot;, &quot;Student&quot;)) lecturerDat ## name birth_date job friends alcohol income neurotic ## 1 Ben 07/03/1977 Lecturer 5 10 20000 10 ## 2 Martin 5/24/1969 Lecturer 2 15 40000 17 ## 3 Andy 6/21/1973 Lecturer 0 20 35000 14 ## 4 Paul 7/16/1970 Lecturer 4 5 22000 13 ## 5 Graham 10/10/1949 Lecturer 1 30 50000 21 ## 6 Carina 11/05/1983 Student 10 25 5000 7 ## 7 Karina 10/08/1987 Student 12 20 100 13 ## 8 Doug 1/23/1989 Student 15 16 3000 9 ## 9 Mark 5/20/1973 Student 12 17 10000 14 ## 10 Zoe 11/12/1984 Student 17 18 10 13 Ahora, imagina que quieres seleccionar datos de aquellos participantes que eran sólo &quot;Lecturer&quot;. Podemos seleccionar esos datos y asignarlos a una nueva variable, así: onlyLecturer &lt;- lecturerDat[lecturerDat$job == &quot;Lecturer&quot;,] onlyLecturer ## name birth_date job friends alcohol income neurotic ## 1 Ben 07/03/1977 Lecturer 5 10 20000 10 ## 2 Martin 5/24/1969 Lecturer 2 15 40000 17 ## 3 Andy 6/21/1973 Lecturer 0 20 35000 14 ## 4 Paul 7/16/1970 Lecturer 4 5 22000 13 ## 5 Graham 10/10/1949 Lecturer 1 30 50000 21 Ahora, imagina que quieres seleccionar datos de aquellos participantes cuyo nivel de alcohol es menor o igual a 15: lightAlcoholics &lt;- lecturerDat[lecturerDat$alcohol &lt;= 15,] lightAlcoholics ## name birth_date job friends alcohol income neurotic ## 1 Ben 07/03/1977 Lecturer 5 10 20000 10 ## 2 Martin 5/24/1969 Lecturer 2 15 40000 17 ## 4 Paul 7/16/1970 Lecturer 4 5 22000 13 Lo que acabas de hacer es seleccionar sólo algunas filas. Algo que también puedes realizar es seleccionar sólo algunas columnas. Por ejemplo, podrías seleccionar sólo aquellos datos relacionados con las columnas &quot;friends&quot;, &quot;alcohol&quot; y &quot;neurotic&quot;. Para ello puedes hacer: lecturerPersonality &lt;- lecturerDat[, c(&quot;friends&quot;, &quot;alcohol&quot;, &quot;neurotic&quot;)] lecturerPersonality ## friends alcohol neurotic ## 1 5 10 10 ## 2 2 15 17 ## 3 0 20 14 ## 4 4 5 13 ## 5 1 30 21 ## 6 10 25 7 ## 7 12 20 13 ## 8 15 16 9 ## 9 12 17 14 ## 10 17 18 13 Incluso puedes combinar la selección de filas y de columnas. Por ejemplo podrías seleccionar las columnas &quot;friends&quot;, &quot;alcohol&quot; y &quot;neurotic&quot; de aquello participantes cuyo nivel de alcohol es menor o igual a 15: lightAlcoholicsPerso &lt;- lecturerDat[lecturerDat$alcohol &lt;= 15, c(&quot;friends&quot;, &quot;alcohol&quot;, &quot;neurotic&quot;)] lightAlcoholicsPerso ## friends alcohol neurotic ## 1 5 10 10 ## 2 2 15 17 ## 4 4 5 13 3.8 Transformado datos en formato long a wide y viceversa Otro aspecto muy importante que debes entender es como transformar de un formato a otro en R. En R hay dos formatos típicos. Cuando hay múltiples mediciones de un mismo sujeto, por ejemplo, a lo largo del tiempo o cuando se realizan distintas mediciones los datos a menudo se anotan en formato wide. En un formato wide la data frame contiene valores que no se repiten en la primera columna. En un formato long la data frame contiene valores que se repiten en la primera columna. Por ejemplo, importemos un set de datos que está en formato wide: setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) satisfactionData &lt;- read.csv(&quot;data/Honeymoon_Period.csv&quot;) head(satisfactionData) ## Person Satisfaction_Base Satisfaction_6_Months Satisfaction_12_Months Satisfaction_18_Months ## 1 1 6 6 5 2 ## 2 2 7 7 8 4 ## 3 3 4 6 2 2 ## 4 4 6 9 4 1 ## 5 5 6 7 6 6 ## 6 6 5 10 4 2 ## Gender ## 1 0 ## 2 1 ## 3 1 ## 4 0 ## 5 0 ## 6 1 Con head miramos sólo los primeras 6 filas de la base de datos. En esta data frame están los niveles de satisfacción con la pareja al momento de casarse, y luego de 6, 12 y 18 meses. Además está el género del entrevistado. Esta data frame la podemos a transformar a un formato long usando la función stack. Esta función la usamos de la siguiente manera: newDataFrame &lt;- stack(oldDataFrame, select = c(variable_list)) En nuestro ejemplo podemos hacerlo así: satisfactionStacked &lt;- stack(satisfactionData, select = c(&quot;Satisfaction_Base&quot;, &quot;Satisfaction_6_Months&quot;, &quot;Satisfaction_12_Months&quot;, &quot;Satisfaction_18_Months&quot;)) colnames(satisfactionStacked) &lt;- c(&quot;Values&quot;, &quot;SatisfType&quot;) # cambiamos los encabezados head(satisfactionStacked) ## Values SatisfType ## 1 6 Satisfaction_Base ## 2 7 Satisfaction_Base ## 3 4 Satisfaction_Base ## 4 6 Satisfaction_Base ## 5 6 Satisfaction_Base ## 6 5 Satisfaction_Base En esta data frame se puede ver que los valores de satisfacción se ubican en una columna y la condición se ubica en otra columna. El problema con esta transformación es que perdemos la información de género y el número de la persona. Más adelante veremos una manera de hacer esta transformación sin perder esta información. Esta data frame la podemos reconvertir en formato wide con la función unstack. Esta función la usamos de la siguiente manera: newDataFrame &lt;- unstack(oldDataFrame, scores ~ columns) O simplemente: newDataFrame &lt;- unstack(oldDataFrame) En nuestro ejemplo podemos hacerlo así: satisfactionUnstacked &lt;- unstack(satisfactionStacked) head(satisfactionUnstacked) ## Satisfaction_Base Satisfaction_6_Months Satisfaction_12_Months Satisfaction_18_Months ## 1 6 6 5 2 ## 2 7 7 8 4 ## 3 4 6 2 2 ## 4 6 9 4 1 ## 5 6 7 6 6 ## 6 5 10 4 2 satisfactionUnstacked2 &lt;- unstack(satisfactionStacked, Values ~ SatisfType) head(satisfactionUnstacked2) ## Satisfaction_Base Satisfaction_6_Months Satisfaction_12_Months Satisfaction_18_Months ## 1 6 6 5 2 ## 2 7 7 8 4 ## 3 4 6 2 2 ## 4 6 9 4 1 ## 5 6 7 6 6 ## 6 5 10 4 2 Otra manera de transformar datos a formato long es usando la función melt. Para ello necesitamos cargar la librería reshape. Esta función la usamos de la siguiente manera: newDataFrame &lt;- melt(oldDataFrame, id = c(constant_variables), measured = c(variables_that_change_across_columns)) En nuestro ejemplo podemos hacerlo así: library(reshape) restructuredData &lt;- melt(satisfactionData, id = c(&quot;Person&quot;, &quot;Gender&quot;), measured = c(&quot;Satisfaction_Base&quot;, &quot;Satisfaction_6_Months&quot;, &quot;Satisfaction_12_Months&quot;, &quot;Satisfaction_18_Months&quot;)) colnames(restructuredData)[3:4] &lt;- c(&quot;SatisfType&quot;, &quot;Values&quot;) # cambiamos los encabezados head(restructuredData) ## Person Gender SatisfType Values ## 1 1 0 Satisfaction_Base 6 ## 2 2 1 Satisfaction_Base 7 ## 3 3 1 Satisfaction_Base 4 ## 4 4 0 Satisfaction_Base 6 ## 5 5 0 Satisfaction_Base 6 ## 6 6 1 Satisfaction_Base 5 Bonus.También podemos aprovechar de reordenar los datos. Para ello usamos la función order. reorder2 &lt;- restructuredData[order(restructuredData$Person),] head(reorder2) ## Person Gender SatisfType Values ## 1 1 0 Satisfaction_Base 6 ## 116 1 0 Satisfaction_6_Months 6 ## 231 1 0 Satisfaction_12_Months 5 ## 346 1 0 Satisfaction_18_Months 2 ## 2 2 1 Satisfaction_Base 7 ## 117 2 1 Satisfaction_6_Months 7 En esta data frame se puede ver que los valores de satisfacción se ubican en una columna y la condición se ubica en otra columna. La ventaja de melt es que conserva la información de género y el número de la persona. Por último, esta data frame la podemos reconvertir en formato wide con la función cast. Esta función la usamos de la siguiente manera: newData &lt;- cast(longData, variables_coded_within_a_single_column ~ variables_coded_across_many_columns, value = &quot;outcome_variable&quot;) En nuestro ejemplo podemos hacerlo así: wideData &lt;- cast(restructuredData, Person + Gender ~ SatisfType, value = &quot;Values&quot;) head(wideData) ## Person Gender Satisfaction_Base Satisfaction_6_Months Satisfaction_12_Months ## 1 1 0 6 6 5 ## 2 2 1 7 7 8 ## 3 3 1 4 6 2 ## 4 4 0 6 9 4 ## 5 5 0 6 7 6 ## 6 6 1 5 10 4 ## Satisfaction_18_Months ## 1 2 ## 2 4 ## 3 2 ## 4 1 ## 5 6 ## 6 2 3.9 Exportando datos Finalmente podrías querer exportar estos datos seleccionados. Para ello puede crear archivos de tipo txt o csv aplicado algunas funciones. Los archivos se crearán en tu actual directorio (para saber cual es puedes hacer getwd()) write.table(lightAlcoholics, &quot;datoExportado.txt&quot;, sep=&quot;\\t&quot;) write.csv(lightAlcoholics, &quot;datoExportado.csv&quot;) 3.10 En la práctica Veamos que información podemos sacar de datos que importamos. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) Primero importemos datos. dat &lt;- read.csv(&quot;data/latidos_cardiacos.csv&quot;, header = TRUE) # load data Luego calculemos algunos estadísticos. mean(dat$latidos) ## [1] 79.08 sd(dat$latidos) ## [1] 7.674075 Y hagamos algunos gráficos (más de esto luego). h1 &lt;- ggplot(dat, aes(latidos)) h1 + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. h1 &lt;- ggplot(dat, aes(&quot;&quot;, latidos)) h1 + geom_boxplot() Veámos otros datos. dat &lt;- read.csv(&quot;data/demografia_salud.csv&quot;, header = TRUE) # load data table(dat$Sexo) ## ## Hombre Mujer ## 24 16 table(dat$Estado.Civil) ## ## Casado Divorciado Soltero Viudo ## 24 6 6 4 mean(dat$Número.de.hijos) ## [1] 1.475 sd(dat$Número.de.hijos) ## [1] 1.154423 min(dat$Peso) ## [1] 58 max(dat$Peso) ## [1] 89 dat$Altura &lt;- as.numeric(gsub(&quot;,&quot;, &quot;.&quot;, dat$Altura)) aggregate(Altura ~ Sexo, data = dat, mean) ## Sexo Altura ## 1 Hombre 1.703333 ## 2 Mujer 1.646875 aggregate(Altura ~ Sexo, data = dat, sd) ## Sexo Altura ## 1 Hombre 0.07653738 ## 2 Mujer 0.06279265 dat$PA.Min &lt;- dat$Pr.Arter.Máx dat$PA.Max &lt;- dat$Pr.Arter.Mín aggregate(PA.Max ~ Estado.Civil, data = dat, mean) ## Estado.Civil PA.Max ## 1 Casado 141.7917 ## 2 Divorciado 137.1667 ## 3 Soltero 142.0000 ## 4 Viudo 144.2500 aggregate(PA.Max ~ Estado.Civil, data = dat, sd) ## Estado.Civil PA.Max ## 1 Casado 9.002315 ## 2 Divorciado 10.553041 ## 3 Soltero 6.000000 ## 4 Viudo 7.675719 "],["gráficos.html", "Capítulo 4 Gráficos 4.1 ¿Cómo graficamos en R? 4.2 Gráfico de puntos 4.3 Gráfico de dispersión 4.4 Histograma 4.5 Boxplot 4.6 Gráfico de barras 4.7 Gráfico de líneas (1 factor) 4.8 Gráfico de líneas (2 factores)", " Capítulo 4 Gráficos En este capítulo vamos a revisar algunos aspectos básicos para hacer gráficos en R. 4.1 ¿Cómo graficamos en R? Revisa este video (16') y trata de responder: ¿Cómo se hace un buen gráfico? ¿Qué significa que se usen capas para hacer gráficos en R? 4.2 Gráfico de puntos Primero seteamos nuestro directorio de trabajo. Para graficar cargamos la librería ggplot2 (que tiene que haber sido previamente instalada). Al mismo tiempo se cargan otras librerías que nos serviran. Si no tienes estas librerías debes instalarlas. Finalmente importamos un set de datos y lo miramos. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(reshape) library(plyr) library(Rmisc) facebookData &lt;- read.delim(&quot;data/FacebookNarcissism.dat&quot;, header = TRUE) # load data head(facebookData) ## id NPQC_R_Total Rating_Type Rating ## 1 1 31 Attractive 2 ## 2 1 31 Fashionable 2 ## 3 1 31 Glamourous 2 ## 4 1 31 Cool 2 ## 5 2 37 Attractive 2 ## 6 2 37 Fashionable 2 En este estudio se recolectaron una serie de datos de los participantes relacionados con rasgos de personalidad y niveles de narcisimo. id indica la identidad del participante. NPQC_R_Total indica la puntuación total en el cuestionario de narcisismo. Rating_Type una característica de personalidad y Rating indica la calificación (en una escala de 1 a 5) de esa característica de personalidad. Ubcaremos NPQC_R_Total en el eje X y Rating en el eje Y. Acuérdate que para crear gráficos con ggplot debes crear un objeto dónde se encuentra la estructura base. Para visualizar el gráfico se debe invocar el objeto y al mismo debes agregar las distintas capas que constituyen el gráfico. Por ejemplo, un capa de puntos. graph &lt;- ggplot(facebookData, aes(NPQC_R_Total, Rating)) graph + geom_point() Además, puedes ir agregando otras capas. Por ejemplo, el título. graph &lt;- ggplot(facebookData, aes(NPQC_R_Total, Rating)) graph + geom_point() + labs(title = &quot;Figura 1&quot;) Podemos cambiar los puntos por triángulos, usando el parámetro shape. graph + geom_point(shape = 17) O podemos cambiar el tamaño de los puntos, usando el parámetro size. graph + geom_point(size = 6) También podemos colorear los puntos en función de los diferentes puntajes. Para ello debemos definir un color dentro del parámetro aes. graph + geom_point(aes(colour = Rating_Type)) Por último, podríamos tener un problema de &quot;sobreploteo&quot;, es decir, dado que hay un limitado número de respuestas que la personas podrían dar para valores equivalentes no se van a observar puntos diferentes. Para evitar esto podemos cambiar el parámetro position para agregar un retraso (o &quot;jitter). graph + geom_point(aes(colour = Rating_Type), position = &quot;jitter&quot;) 4.3 Gráfico de dispersión En un gráfico de dispersión se dibuja la puntuación de una una variable frente a la puntuación de otra variable. En este ejemplo un psicólogo estaba interesado en entender los efectos que produce el estrés sobre el rendimiento en este examen. Se diseñó y se validó un cuestionario para evaluar el estado de ansiedad relacionado con los exámenes (llamado Cuestionario de Ansiedad ante los Exámenes, o EAQ). Esta escala produce un puntaje de ansiedad desd 1 a 100. La ansiedad se midió antes de un examen, y la calificación de cada estudiante en el examen se utilizó para medir el rendimiento del examen. Primero, importemos los datos. No es necesario que carguemos la librerías si ya están cargadas. examData &lt;- read.delim(&quot;data/ExamAnxiety.dat&quot;, header = TRUE) head(examData) ## Code Revise Exam Anxiety Gender ## 1 1 4 40 86.298 Male ## 2 2 11 65 88.716 Female ## 3 3 27 80 70.178 Male ## 4 4 53 80 61.312 Male ## 5 5 4 40 89.522 Male ## 6 6 22 70 60.506 Female Fíjate que en la data frame hay 5 variables: Code: Un número que indica la identidad del participante. Revise: El total de horas que los participantes dedicaron para estudiar. Exam: La nota en el examen que tuvo el participante (como porcentaje). Anxiety: La puntuación en la esclala de ansiedad. Gender: El género (masculino o femenino). Primero, vamos a crear la estructura base del gráfico. scatter &lt;- ggplot(examData, aes(Anxiety, Exam)) Fíjate que la estuctura base definimos que vamos a gráficar la relación entre la ansiedad (Anxiety) y las notas (Exam). Luego, podemos ir agregando las capas. Por ejemplo, los puntos que relfejan cada participante y los títulos en los ejes. scatter + geom_point() + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) En general, en los gráficos de dispersión agregamos una línea de tendencia que resume la relación entre las variables. La sombra asociada a la línea representa un intervalo de confianza (CI) al 95%. scatter + geom_point() + geom_smooth() + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Pero, en general, se agrega una linea recta. Para ello usamos la función geom_smooth. scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;) + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Opcionalmente se puede omitir la sombra. scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Green&quot;, se = FALSE) + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Además, podemos cambiar la transparencia de la línea, cambiando el parámetro alpha. Y también podamos cambiar el relleno (&quot;fill&quot;) de la sombra. scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, alpha = 0.1, fill = &quot;Blue&quot;) + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ¿Qué pasa si queremos hacer gráficos de dispersión en función de más de una variable? Por ejemplo, podríamos querer ver las distintas relaciones entre ansiedad y puntajes en la prueba, en función del género (hombres versus mujeres). Para ello debemos re-definir la estructura base del gráfico, y debemmos agregar la variable género dentro del parámetro aes. scatter &lt;- ggplot(examData, aes(Anxiety, Exam, colour = Gender)) Luego podemos hacer un nuevo gráfico. scatter + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; También podemos dibujar las líneas de acuerdo al género (y además podemos hacer las líneas transparentes). Para ello debemos definir un parámetro aes dentro de la función geom_smooth. scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, alpha = 0.1, aes(fill = Gender)) + labs(x = &quot;Exam Anxiety&quot;, y = &quot;Exam Performance %&quot;, colour = &quot;Gender&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 4.4 Histograma Un histograma es una representación gráfica de una variable en forma de barras, donde la superficie de cada barra es proporcional a la frecuencia de los valores representados. En este ejemplo un biólogo estaba preocupado por los posibles efectos en la salud de los festivales de música. Un año fue al Download Music Festival y midió los niveles de higiene de 810 asistentes al concierto durante los tres días del festival. Dado que era difícil rastrear a todas las personas en esta base de datos faltaban algunos datos en los días 2 y 3. La higiene se midió utilizando una técnica estandarizada que da como resultado una puntuación que oscila entre 0 (hueles como un cadáver) y 4 (hueles a rosas dulces en un día fresco de primavera). Primero, importemos los datos. No es necesario que carguemos la librerías si ya están cargadas. festivalData &lt;- read.delim(&quot;data/DownloadFestival.dat&quot;, header = TRUE) head(festivalData) ## ticknumb gender day1 day2 day3 ## 1 2111 Male 2.64 1.35 1.61 ## 2 2229 Female 0.97 1.41 0.29 ## 3 2338 Male 0.84 NA NA ## 4 2384 Female 3.03 NA NA ## 5 2401 Female 0.88 0.08 NA ## 6 2405 Male 0.85 NA NA Primero, vamos a crear la estructura base del gráfico. festivalHistogram &lt;- ggplot(festivalData, aes(day1)) Y luego hacemos el gráfico. festivalHistogram + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Por defecto se realizan los agrupamientos (o &quot;bins) en grupos de 30 puntos. Hay varias cosas que podemos observar en este gráfico. Se observa inmediatamente que hay una valor mucho más alto que el resto de los valores. Podría ser un potencial outlier. También nos damos cuenta que podríamos usar una mejor definición de bins. Para ello podemos modificar el parámetro bindwith. Además, le podemos agregar unos títulos a los ejes. festivalHistogram + geom_histogram(binwidth = 0.4) + labs(x = &quot;Hygiene (Day 1 of Festival)&quot;, y = &quot;Frequency&quot;) Para lidiar con el outlier tenemos 2 opciones. Podemos eliminarlo de archivo original. O sea importamos un nuevo archivo. # import data festivalDataAlt &lt;- read.delim(&quot;data/DownloadFestival_NoOutlier.dat&quot;, header = TRUE) # define base graph festivalHistogramAlt &lt;- ggplot(festivalDataAlt, aes(day1)) # add layers festivalHistogramAlt + geom_histogram(binwidth = 0.6) + labs(x = &quot;Hygiene (Day 1 of Festival)&quot;, y = &quot;Frequency&quot;) Mejor aún. Como una segunda opción podemos ubicar el outlier en la data frame. Para ello usamos la función order para order los datos de menor a mayor. Luego usamos la función tail para ver los últimos puntos de los datos. # import data festivalData &lt;- festivalData[order(festivalData$day1),] tail(festivalData) ## ticknumb gender day1 day2 day3 ## 774 4564 Female 3.38 3.44 3.41 ## 300 3371 Female 3.41 NA NA ## 657 4264 Male 3.44 NA NA ## 303 3374 Male 3.58 3.35 NA ## 574 4016 Female 3.69 NA NA ## 611 4158 Female 20.02 2.44 NA Aquí nos fijamos que hay un valor exageradamente alto. Se escribe 20.02, y es probable que sea un error de registro. Lo que podemos hacer es eliminar manualmente el valor o modificarlo a 2.02. festivalDataGood &lt;- festivalData festivalDataGood$day1[810] &lt;- 2.02 Y podemos re-hacer el gráfico. festivalHistogramGood &lt;- ggplot(festivalDataGood, aes(day1)) festivalHistogramGood + geom_histogram(binwidth = 0.4) + labs(x = &quot;Hygiene (Day 1 of Festival)&quot;, y = &quot;Frequency&quot;) 4.5 Boxplot En un boxplot (o gráfico de cajas y bigotes) visualizamos la distribución y la asimetría en los datos mostrando los promedios y cuartiles (o percentiles) del set de datos. Vamos a usar los mismos que usamos antes. Veamos los datos originales, pero esta veámoslo en función del género. Debemos re-hacer la estructura base. festivalBoxplot &lt;- ggplot(festivalData, aes(gender, day1)) festivalBoxplot + geom_boxplot() + labs(x = &quot;Gender&quot;, y = &quot;Hygiene (Day 1 of Festival)&quot;) En este tipo de gráfico también se puede visualizar el outlier. Ya habíamos lidiado con este problema transformando el valor del oulier. Podemos hacer un boxplot con la nueva data frame. # define base graph festivalBoxplotAlt &lt;- ggplot(festivalDataAlt, aes(gender, day1)) # add layers festivalBoxplotAlt + geom_boxplot() + labs(x = &quot;Gender&quot;, y = &quot;Hygiene (Day 1 of Festival)&quot;) Por último, podemos hacer los boxplots para el día 2. festivalBoxplot &lt;- ggplot(festivalData, aes(gender, day2)) festivalBoxplot + geom_boxplot() + labs(x = &quot;Gender&quot;, y = &quot;Hygiene (Day 2 of Festival)&quot;) ## Warning: Removed 546 rows containing non-finite values (stat_boxplot). Y para el día 3. festivalBoxplot &lt;- ggplot(festivalData, aes(gender, day3)) festivalBoxplot + geom_boxplot() + labs(x = &quot;Gender&quot;, y = &quot;Hygiene (Day 3 of Festival)&quot;) ## Warning: Removed 687 rows containing non-finite values (stat_boxplot). 4.6 Gráfico de barras El gráfico de barras es el más común de las visualizaciones. En este ejemplo un el director de una compañía cinematográfica estuvo interesado en saber si realmente existía el efecto llamado &quot;chick flick&quot;, es decir, el hecho que hay películas que atraen más a las mujeres que a los hombres. Para investigar esta pregunta reclutó a 20 hombres y 20 mujeres y les mostró a la mitad de cada grupo una película que se suponía era para chicas (&quot;El diario de Bridget Jones), y a la otra mitad de cada grupo una película que no caía en esta categoría de película (Memento). En todos los casos midió la excitación fisiológica (la conductancia de la piel) como indicador de cuánto disfrutaron la película los participantes. Como siempre, primero importemos los datos. No es necesario que carguemos la librerías si ya están cargadas. chickFlick &lt;- read.csv(&quot;data/chick_flick.csv&quot;, header = TRUE) head(chickFlick) ## genero pelicula estado.de.alerta ## 1 Hombre Bridget Jones&#39; Diary 22 ## 2 Hombre Bridget Jones&#39; Diary 13 ## 3 Hombre Bridget Jones&#39; Diary 16 ## 4 Hombre Bridget Jones&#39; Diary 10 ## 5 Hombre Bridget Jones&#39; Diary 18 ## 6 Hombre Bridget Jones&#39; Diary 24 # cambiemos los nombres colnames(chickFlick) &lt;- c(&quot;gender&quot;, &quot;film&quot;, &quot;arousal&quot;) head(chickFlick) ## gender film arousal ## 1 Hombre Bridget Jones&#39; Diary 22 ## 2 Hombre Bridget Jones&#39; Diary 13 ## 3 Hombre Bridget Jones&#39; Diary 16 ## 4 Hombre Bridget Jones&#39; Diary 10 ## 5 Hombre Bridget Jones&#39; Diary 18 ## 6 Hombre Bridget Jones&#39; Diary 24 Fíjate que hay variables: gender: El género del participante. film: La película que estaba vió el participante. arousal: El nivel de excitación del participante. Antes de crear la estructura base del gráfico vamos a hacer algunos cálculos. Para ello nos vamos a valer de algunas funciones estadísticas. La función summarySE nos permite calcular varias métricas estadísticas (N, promedio, SD, SE, CI) en función de otra variable. En este caso vamos a calcular el arousal promedio en función del tipo de film. Está función necesita de la librería Rmisc que ya está cargada. dataSumm &lt;- summarySE(chickFlick, measurevar=&quot;arousal&quot;, groupvars = c(&quot;film&quot;)) dataSumm ## film N arousal sd se ci ## 1 Bridget Jones&#39; Diary 20 14.80 5.727128 1.280625 2.680379 ## 2 Memento 20 25.25 7.129442 1.594192 3.336682 Y luego hacemos el gráfico. # usamos la tabla que recién creamos y graficamos el promedio del arousal (eje Y) en fución del film (eje X) ggplot(dataSumm, aes(x=film, y=arousal)) + # agregamos las barras dónde estan los promedios # dodge permite crear un pequeño desfase entre la posición dónde se ubican los promedios geom_bar(position = position_dodge(width = 0.9), stat=&quot;identity&quot;, color=&quot;black&quot;, fill=&quot;green&quot;, show.legend=FALSE) + # agregamos las barras de error # dodge permite crear un pequeño desfase entre la posición dónde se ubican los promedios # podemos modificar el ancho de las barras de error con &quot;width&quot; # podemos definir los mínimos y máximos de las barras de error, tipicamente el error se muestra hacia arriba geom_errorbar(position = position_dodge(width=0.9), width=0.25, aes(ymin=arousal, ymax=arousal+se)) + # creamos un fondo blanco para que se vea mejor # se elimina la rejilla que aparece en el fondo theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + # podemos cambiar los límites y las separaciones del eje Y scale_y_continuous(limits = c(0,30), breaks = seq(0, 30, 5)) + # también podemos renombrar la etiqueta de los ejes ylab(&quot;Arousal&quot;) + xlab(&quot;Film&quot;) Para entender mejor el rol de estos parámetros en la configuración del gráfico, cámbialos. Además, podríamos querer visualizar los valores de excitación no sólo en función de las películas, sino que también en función del género. Usamos la función summarySE para calcular el arousal promedio en función del tipo de film y del género. dataSumm &lt;- summarySE(chickFlick, measurevar=&quot;arousal&quot;, groupvars = c(&quot;film&quot;, &quot;gender&quot;)) dataSumm ## film gender N arousal sd se ci ## 1 Bridget Jones&#39; Diary Hombre 10 17.2 4.779586 1.511438 3.419110 ## 2 Bridget Jones&#39; Diary Mujer 10 12.4 5.796551 1.833030 4.146603 ## 3 Memento Hombre 10 25.8 7.238784 2.289105 5.178314 ## 4 Memento Mujer 10 24.7 7.364328 2.328805 5.268123 Luego graficamos. # Aquí debemos definir como ver el género dento del parámetro aes. ggplot(dataSumm, aes(x=film, y=arousal, fill=gender)) + geom_bar(position = position_dodge(width = 0.9), stat=&quot;identity&quot;, color=&quot;black&quot;) + geom_errorbar(position = position_dodge(width=0.9), width=0.25, aes(ymin=arousal, ymax=arousal+se)) + # podemos cambiar los colores de relleno scale_fill_manual(values=c(&quot;white&quot;, &quot;black&quot;)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + scale_y_continuous(limits = c(0,30), breaks = seq(0, 30, 5)) + ylab(&quot;Arousal&quot;) + xlab(&quot;Film&quot;) 4.7 Gráfico de líneas (1 factor) El gráfico de líneas es también muy común para visualizar datos. En este ejemplo se reclutaron 15 personas con hipo y durante un ataque de hipo se administraron tres procedimientos para detener el hipo (recibir un susto, ingerir un poco de azúcar y respirar en una bolsa) en orden aleatorio y a intervalos de 5 minutos. Además, se tomó una línea de base de cuántos hipo tuvieron por minuto. Durante al aplicación de los procedimientos para detener el hipo se contaron el numero de hipos por minuto. Como siempre, primero importemos los datos. hiccupsData &lt;- read.csv(&quot;data/hipo.csv&quot;, header = TRUE) head(hiccupsData) ## ID Linea.base Susto Azucar Bolsa ## 1 1 15 9 7 2 ## 2 2 13 18 7 4 ## 3 3 9 17 5 4 ## 4 4 7 15 10 5 ## 5 5 11 18 7 4 ## 6 6 14 8 10 3 colnames(hiccupsData)[2] &lt;- &quot;Base&quot; head(hiccupsData) ## ID Base Susto Azucar Bolsa ## 1 1 15 9 7 2 ## 2 2 13 18 7 4 ## 3 3 9 17 5 4 ## 4 4 7 15 10 5 ## 5 5 11 18 7 4 ## 6 6 14 8 10 3 Hay cuatro tratamientos: Base: el número de hipos sin ningún tratamiento. Susto: número de hipos al recibir un susto. Azucar: número de hipo al ingerir un poco de azúcar. Bolsa: número de hipos al respirar en una bolsa. Cada fila en la base de datos representa a una persona diferente. Esto refleja un diseño de medidas repetidas. Cada columna representa una condición de tratamiento diferente. Y cada persona que se somete a cada uno de los tratamientos. Antes de graficar con ggplot debemos cambiar el formato de la base de datos. El ID no nos interesa y nos podemos deshacer de él. hiccupsData$ID &lt;- NULL hiccups &lt;- stack(hiccupsData) head(hiccups) ## values ind ## 1 15 Base ## 2 13 Base ## 3 9 Base ## 4 7 Base ## 5 11 Base ## 6 14 Base colnames(hiccups) &lt;- c(&quot;Hipos&quot;,&quot;Tratamiento&quot;) head(hiccups) ## Hipos Tratamiento ## 1 15 Base ## 2 13 Base ## 3 9 Base ## 4 7 Base ## 5 11 Base ## 6 14 Base Para graficar una variable categórica en ggplot debemos transformarla a factor. A veces R automáticamente identifica esta variables como categóricas. Además, podemos cambiar el orden en que aparecen las condiciones en el gráfico, # Si una variable es categórica se puede ver hacia el final de los datos que existen niveles. # En este caso la variable &quot;Tratamieto&quot; tiene 4 niveles. hiccups$Tratamiento ## [1] Base Base Base Base Base Base Base Base Base Base Base Base Base ## [14] Base Base Susto Susto Susto Susto Susto Susto Susto Susto Susto Susto Susto ## [27] Susto Susto Susto Susto Azucar Azucar Azucar Azucar Azucar Azucar Azucar Azucar Azucar ## [40] Azucar Azucar Azucar Azucar Azucar Azucar Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa ## [53] Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa ## Levels: Base Susto Azucar Bolsa hiccups$Tratamiento2 &lt;- factor(hiccups$Tratamiento, levels(hiccups$Tratamiento)[c(1, 4, 2, 3)]) hiccups$Tratamiento2 ## [1] Base Base Base Base Base Base Base Base Base Base Base Base Base ## [14] Base Base Susto Susto Susto Susto Susto Susto Susto Susto Susto Susto Susto ## [27] Susto Susto Susto Susto Azucar Azucar Azucar Azucar Azucar Azucar Azucar Azucar Azucar ## [40] Azucar Azucar Azucar Azucar Azucar Azucar Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa ## [53] Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa Bolsa ## Levels: Base Bolsa Susto Azucar Usamos la función summarySE para calcular el número de hipos promedio en función del tratamiento. dataSumm &lt;- summarySE(hiccups, measurevar=&quot;Hipos&quot;, groupvars=&quot;Tratamiento&quot;) dataSumm ## Tratamiento N Hipos sd se ci ## 1 Base 15 13.133333 4.8383390 1.2492537 2.6793828 ## 2 Susto 15 12.800000 5.4142669 1.3979577 2.9983211 ## 3 Azucar 15 8.733333 2.3441924 0.6052679 1.2981705 ## 4 Bolsa 15 3.533333 0.8338094 0.2152887 0.4617482 Luego graficamos. # Para hacer un gráfico de línea debemos setear en el aes una estética de grupo igual a 1 # Esto nos permite agrupar puntos promedio dentro de un grupo en una línea ggplot(dataSumm, aes(x=Tratamiento, y=Hipos, group=1)) + # agregamos las barras de error geom_errorbar(width=0.1, aes(ymin=Hipos-se, ymax=Hipos+se)) + # agregamos las líneas que unen los puntos geom_line(colour = &quot;Red&quot;, linetype = &quot;dashed&quot;) + # agregamos los puntos que indican los promedios geom_point() + ylab(&quot;Número de hipos&quot;) + # coord_cartesian(ylim = c(830, 900)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) 4.8 Gráfico de líneas (2 factores) Imagina que llevamos a cabo un experimento en el que a un grupo de 25 niños se les pidió enviar mensajes de texto vía sus teléfonos móviles durante un período de seis meses. A un segundo grupo de 25 niños se le prohibió enviar mensajes de texto por el mismo período. A estos dos grupos se les aplicó una pueba gramatical para medir el efecto de enviar mensajes de texto sobre su habilidades gramaticales. La primera variable independiente fue el uso de mensajes de texto (uso de mensajes de texto versus controles) y la segunda variable independiente fue el tiempo (línea de base versus después de 6 meses). Importemos los datos. textData &lt;- read.csv(&quot;data/usuarios_de_whatsapp.csv&quot;, header = TRUE) head(textData) ## Grupo Linea.base X6.meses ## 1 Usarios de Whatsapp 52 32 ## 2 Usarios de Whatsapp 68 48 ## 3 Usarios de Whatsapp 85 62 ## 4 Usarios de Whatsapp 47 16 ## 5 Usarios de Whatsapp 73 63 ## 6 Usarios de Whatsapp 57 53 # missing something! colnames(textData) &lt;- c(&quot;Group&quot;, &quot;Baseline&quot;, &quot;Six_months&quot;) head(textData) ## Group Baseline Six_months ## 1 Usarios de Whatsapp 52 32 ## 2 Usarios de Whatsapp 68 48 ## 3 Usarios de Whatsapp 85 62 ## 4 Usarios de Whatsapp 47 16 ## 5 Usarios de Whatsapp 73 63 ## 6 Usarios de Whatsapp 57 53 Hay 3 variables: Grupo: especifica si estaban en el grupo de mensajes de texto o en el grupo de control. Baseline: puntajes de gramática en la línea de base. Six_months: puntajes de gramática después de 6 meses. Cada fila en la base de datos representa a una persona diferente. Estos datos están nuevamente en el formato incorrecto para ggplot. En lugar del formato wide actual necesitamos los datos en formato long. Entonces necesitamos reestructurar los datos a una nueva data frame. textMessages &lt;- melt(textData, id = c(&quot;Group&quot;), measured = c(&quot;Baseline&quot;, &quot;Six_months&quot;)) head(textMessages) ## Group variable value ## 1 Usarios de Whatsapp Baseline 52 ## 2 Usarios de Whatsapp Baseline 68 ## 3 Usarios de Whatsapp Baseline 85 ## 4 Usarios de Whatsapp Baseline 47 ## 5 Usarios de Whatsapp Baseline 73 ## 6 Usarios de Whatsapp Baseline 57 colnames(textMessages)[c(2,3)] &lt;- c(&quot;Time&quot;, &quot;Grammar_Score&quot;) head(textMessages) ## Group Time Grammar_Score ## 1 Usarios de Whatsapp Baseline 52 ## 2 Usarios de Whatsapp Baseline 68 ## 3 Usarios de Whatsapp Baseline 85 ## 4 Usarios de Whatsapp Baseline 47 ## 5 Usarios de Whatsapp Baseline 73 ## 6 Usarios de Whatsapp Baseline 57 A esta altura podríamos querer cambiar los nombres de las condiciones. También podemos hacer eso. head(textMessages) ## Group Time Grammar_Score ## 1 Usarios de Whatsapp Baseline 52 ## 2 Usarios de Whatsapp Baseline 68 ## 3 Usarios de Whatsapp Baseline 85 ## 4 Usarios de Whatsapp Baseline 47 ## 5 Usarios de Whatsapp Baseline 73 ## 6 Usarios de Whatsapp Baseline 57 textMessages$Time &lt;- factor(textMessages$Time, labels = c(&quot;Baseline&quot;, &quot;6 Months&quot;)) tail(textMessages) ## Group Time Grammar_Score ## 95 Controles 6 Months 78 ## 96 Controles 6 Months 62 ## 97 Controles 6 Months 71 ## 98 Controles 6 Months 55 ## 99 Controles 6 Months 46 ## 100 Controles 6 Months 79 En esta base de datos tenemos las siguientes variables: Grupo: especifica si estaban en el grupo de mensajes de texto o en el grupo de control. Time: especifica si la puntuación se relaciona con la línea de base o después de 6 meses. Grammar_Score: especifica las puntuaciones de gramática. Enseguida, Usamos la función summarySE para calcular los puntajes de grámatica promedio en función de la condición y el tiempo. dataSumm &lt;- summarySE(textMessages, measurevar=&quot;Grammar_Score&quot;, groupvars=c(&quot;Group&quot;, &quot;Time&quot;)) dataSumm ## Group Time N Grammar_Score sd se ci ## 1 Controles Baseline 25 65.60 10.835897 2.167179 4.472839 ## 2 Controles 6 Months 25 61.84 9.410455 1.882091 3.884445 ## 3 Usarios de Whatsapp Baseline 25 64.84 10.679732 2.135946 4.408377 ## 4 Usarios de Whatsapp 6 Months 25 52.96 16.331156 3.266231 6.741170 Luego graficamos. # En este caso debemos decirle a R que coloree las líneas en función de las condiciones experimentales. ggplot(dataSumm, aes(x=Time, y=Grammar_Score, colour=Group)) + # agregamos las barras de error geom_errorbar(aes(ymin=Grammar_Score-se, ymax=Grammar_Score+se), width=.1, position=position_dodge(0.1)) + # agregamos las líneas que unen los puntos geom_line(position=position_dodge(0.1), aes(group=Group), show.legend=FALSE) + # agregamos los puntos que indican los promedios geom_point(position=position_dodge(0.1), aes(group=Group), show.legend=FALSE) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + ylab(&quot;Mean Grammar Score&quot;) + scale_colour_manual(values=c(&quot;red&quot;, &quot;blue&quot;)) + coord_cartesian(ylim = c(45, 70)) "],["caracterizar-datos.html", "Capítulo 5 Caracterizar datos 5.1 Visualizar los datos 5.2 La curva normal 5.3 La curva normal en la práctica (1) 5.4 La curva normal en la práctica (2) 5.5 De la muestra a la población 5.6 La muestra en la vida real 5.7 Los intervalos de confianza (1) 5.8 Los intervalos de confianza (2)", " Capítulo 5 Caracterizar datos En este capítulo vamos a revisar algunos elementos relacionados con la estadística inferencial. Para entender estas ideas primero vamos a hablar sobre como caracterizamos y visualizamos nuestros datos. 5.1 Visualizar los datos Revisa este video (17') y trata de responder: ¿Por qué es importante graficar los datos? ¿Cómo se calcula la desviación estándar? ¿Qué es la suma de cuadrados (o suma de los errores al cuadrado)? 5.2 La curva normal Revisa este video (10') y trata de responder: ¿Cómo se puede visualizar la &quot;forma&quot; de los datos? ¿Qué características tiene la curva normal? ¿Cómo estimamos cuantas observaciones caen entre dos valores para una set de datos? ¿Qué porcentaje de los datos esta entre -1 SD y 1 SD? 5.3 La curva normal en la práctica (1) Revisa este video (8') y trata de responder: ¿Cuantos vehículos anduvieron a exceso de velocidad? PAUSA el video para responder ¿Qué porcentaje de los datos esta entre -2 SD y 2 SD? ¿Qué porcentaje de los datos esta entre -2.5 SD y 2.5 SD? 5.4 La curva normal en la práctica (2) Revisa este video (9') y trata de responder: ¿Entre cuantas SD tenemos prácticamente todos los puntos de un set de datos? ¿Entre Linda y Bill quien saco mejor puntaje dentro de su cohorte? PAUSA el video para responder 5.5 De la muestra a la población Revisa este video (17') y trata de responder: ¿Qué significa generalizar nuestros hallazgos? ¿Qué son los parámetros? ¿Qué son los estadísticos? ¿Qué es la variación de la muestra (o sampling variation)? ¿Qué representa el promedio de los promedios de las muestras? 5.6 La muestra en la vida real Revisa este video (10') y trata de responder: ¿Qué pasa en la vida con respecto a la distribución de los promedios de las muestras? ¿Qué es el error estándar y como se calcula? 5.7 Los intervalos de confianza (1) Revisa este video (13') y trata de responder: ¿Cómo se calcula el SE? ¿Cómo se estima el promedio de la población? ¿Qué son los intervalos de confianza? 5.8 Los intervalos de confianza (2) Revisa este video (6') y trata de responder: ¿Qué significa que cálculemos un promedio con un intervalo de confianza al 68%? ¿Qué significa que cálculemos un promedio con un intervalo de confianza al 95%? "],["t-test.html", "Capítulo 6 T-test 6.1 ¿Cómo comparamos datos de dos grupos? 6.2 La distribución normal para dos grupos 6.3 La prueba de hipótesis 6.4 El t-test como un modelo líneal general 6.5 El t-test con R", " Capítulo 6 T-test En este capítulo vamos a revisar la típica prueba para comparar dos grupos, el t-test. 6.1 ¿Cómo comparamos datos de dos grupos? Revisa este video (10') y trata de responder: ¿Cómo se sabe si dos muestras viene de una misma población o de poblaciones diferentes? ¿Cómo podemos usar los intervalos de confianzar para estimar las diferencias entre dos muestras? 6.2 La distribución normal para dos grupos Revisa este video (9') y trata de responder: ¿Para que nos sirve la distribución normal para compara dos muestras? 6.3 La prueba de hipótesis Revisa este video (12') y trata de responder: ¿Cuál es la hipótesis nula cuando comparamos dos muestras? 6.4 El t-test como un modelo líneal general Revisa este video (15') y trata de responder: ¿Cómo se refleja un t-test en un modelo lineal general (GLM)? ¿Qué representa el intercepto de la ecuación de un GLM para una variable outcome cuando se comparan dos grupos? ¿Qué representa la pendiente de la ecuación de un GLM para una variable outcome cuando se comparan dos grupos? 6.5 El t-test con R Ahora vamos a hacer el análisis. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). Luego importamos el set de datos y le damos una mirada. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Hmisc) library(Rmisc) library(effsize) library(pastecs) library(reshape2) library(car) library(effsize) spiderLong &lt;- read.csv(&quot;data/ansiedad_por_arañas_indep.csv&quot;, header = TRUE) # load data spiderLong$Condicion &lt;- factor(spiderLong$Condicion) head(spiderLong) ## Sujeto Condicion Conductancia ## 1 1 imagen 30 ## 2 2 imagen 35 ## 3 3 imagen 45 ## 4 4 imagen 40 ## 5 5 imagen 50 ## 6 6 imagen 35 Luego, mirar los datos siempre es bueno graficar. # Podemos usar esta función para calcular los estadísticos a través de los participantes. datac &lt;- summarySE(spiderLong, measurevar=&quot;Conductancia&quot;, groupvars = &quot;Condicion&quot;) # Luego hacemos el gráfico ggplot(datac, aes(x = Condicion, y = Conductancia)) + geom_bar(position = position_dodge(width = 0.9), stat = &quot;identity&quot;, color = &quot;black&quot;, fill = &quot;White&quot;, show.legend=FALSE) + geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin = Conductancia, ymax = Conductancia+se)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + scale_y_continuous(limits = c(0,55), breaks = seq(0, 55, 10)) + ylab(&quot;Conductancia&quot;) Recordando lo que acabamos de aprender vamos a comparar los promedios por cada grupo con la información que resulta de aplicar una regresión lineal a estos datos. Primero describamos los datos. lapply(by(spiderLong$Conductancia, spiderLong$Condicion, stat.desc, basic = FALSE, norm = TRUE), round, 2) ## $imagen ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 40.00 40.00 2.68 5.90 86.36 9.29 0.23 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.00 0.00 -1.39 -0.57 0.97 0.85 ## ## $real ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 50.00 47.00 3.18 7.01 121.64 11.03 0.23 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## -0.01 0.00 -1.46 -0.59 0.95 0.62 La función by permite calcular los estadísticos. La función round redondea los valores a dos décimas. Y la función lapply permite aplicar la función round de forma másiva. Ahora, vamos a realiza una regresión lineal. Lo que queremos es predecir los valores de conductancia en función de los grupos (o condiciones) que tenemos. Para realizar la regresión usamos la función lm Luego de hacer la regresión lineal podemos revisar su contenido con la función summary. Recuerda mirar los coeficientes. ¿Qué ves? m1 &lt;- lm(Conductancia ~ Condicion, data=spiderLong) summary(m1) ## ## Call: ## lm(formula = Conductancia ~ Condicion, data = spiderLong) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.0 -8.5 1.5 8.0 18.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 40.000 2.944 13.587 3.53e-12 *** ## Condicionreal 7.000 4.163 1.681 0.107 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 10.2 on 22 degrees of freedom ## Multiple R-squared: 0.1139, Adjusted R-squared: 0.07359 ## F-statistic: 2.827 on 1 and 22 DF, p-value: 0.1068 Finalmente, podemos hacer el t-test. Pero, antes de hacerlo debemos verificar si existen problemas de homgeneidad de varianza. Podemos hacerlo con la función leveneTest leveneTest(spiderLong$Conductancia, spiderLong$Condicion) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.2991 0.59 ## 22 Luego podemos hacer el análisis estadístico, aplicando la función t.test. De la siguiente forma: newModel &lt;- t.test(outcome ~ predictor, data=df, var.equal = TRUE/FALSE, paired=TRUE/FALSE). Ya que no tenemos problemas de homogeneidad de varianzar seteamos var.equal a FALSE. t_test1 &lt;- t.test(Conductancia ~ Condicion, data=spiderLong, var.equal = TRUE, paired = FALSE) t_test1 ## ## Two Sample t-test ## ## data: Conductancia by Condicion ## t = -1.6813, df = 22, p-value = 0.1068 ## alternative hypothesis: true difference in means between group imagen and group real is not equal to 0 ## 95 percent confidence interval: ## -15.634222 1.634222 ## sample estimates: ## mean in group imagen mean in group real ## 40 47 Para terminar siempre es bueno calcular el tamaño del efecto. t &lt;- t_test1$statistic[[1]] df &lt;- t_test1$parameter[[1]] r &lt;- sqrt(t**2/(t**2+df)) r ## [1] 0.3374392 Ahora, imaginemos que en realidad nuestro diseño experimental era intra-sujetos. Vamos a usar exactamente los mismos datos que antes pero asumiendo un diseño intra-sujetos. Y asumiremos que estos datos viendo en un formato wide. spiderWide &lt;- read.csv(&quot;data/ansiedad_por_arañas_dep.csv&quot;, header = TRUE) # load data head (spiderWide) ## Sujeto imagen real ## 1 1 30 40 ## 2 2 35 35 ## 3 3 45 50 ## 4 4 40 55 ## 5 5 50 65 ## 6 6 35 55 Para realizar el gráfico primero transformamos los datos a formato Long. spiderLongNew &lt;- melt(spiderWide, id = c(&quot;Sujeto&quot;), measured = c(&quot;imagen&quot;, &quot;real&quot;)) names(spiderLongNew) &lt;- c(&quot;Sujeto&quot;, &quot;Condicion&quot;, &quot;Conductancia&quot;) Luego procedemos como antes. # Podemos usar esta función para calcular los estadísticos para un diseño intra-sujetos. datac2 &lt;- summarySEwithin(spiderLongNew, measurevar=&quot;Conductancia&quot;, withinvars=&quot;Condicion&quot;, idvar=&quot;Sujeto&quot;) ggplot(datac2, aes(x=Condicion, y=Conductancia)) + geom_bar(position = position_dodge(width = 0.9), stat=&quot;identity&quot;, color=&quot;black&quot;, fill=&quot;White&quot;, show.legend=FALSE) + geom_errorbar(position=position_dodge(.9), width=.25, aes(ymin=Conductancia, ymax=Conductancia+se)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) + scale_y_continuous(limits = c(0,55), breaks = seq(0, 55, 10)) + ylab(&quot;Conductancia&quot;) Luego podemos chequear algunos supuestos. spiderWide$diff &lt;- spiderWide$imagen - spiderWide$real # calcula la diferencia stat.desc(spiderWide$diff, basic = FALSE, norm = TRUE) # calcula los estadísticos ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## -7.5000000 -7.0000000 2.8311043 6.2312185 96.1818182 9.8072330 -1.4010333 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.2464810 0.1933785 -1.2342159 -0.5007991 0.9557903 0.7224801 Y luego haces el t-test. t_test2 &lt;- t.test(spiderWide$real, spiderWide$imagen, paired = TRUE) t_test2 ## ## Paired t-test ## ## data: spiderWide$real and spiderWide$imagen ## t = 2.4725, df = 11, p-value = 0.03098 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.7687815 13.2312185 ## sample estimates: ## mean of the differences ## 7 # Pero también lo podrías hacer si estuvieran en formato Long. t.test(Conductancia ~ Condicion, data=spiderLong, paired = TRUE) ## ## Paired t-test ## ## data: Conductancia by Condicion ## t = -2.4725, df = 11, p-value = 0.03098 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -13.2312185 -0.7687815 ## sample estimates: ## mean of the differences ## -7 Para terminar siempre es bueno calcular el tamaño del efecto. Podemos calcularlo de diferentes formas. t &lt;- t_test2$statistic[[1]] df &lt;- t_test2$parameter[[1]] (r &lt;- sqrt(t**2/(t**2+df))) ## [1] 0.5976869 r ## [1] 0.5976869 O podemos usar una función. # Cohen&#39;s d = (M2 - M1) / SDpooled # SDpooled = sqrt((SD1^2 + SD2^2)/ 2) cohen.d(spiderWide$real, spiderWide$imagen, paired = TRUE) ## ## Cohen&#39;s d ## ## d estimate: 0.6805173 (medium) ## 95 percent confidence interval: ## lower upper ## 0.04707723 1.31395743 "],["la-regresión.html", "Capítulo 7 La regresión 7.1 Modelos estadísticos 7.2 La ecuación de la recta 7.3 La suma de cuadrados 7.4 La regresión con R 7.5 La correlación con R", " Capítulo 7 La regresión En este capítulo vamos a revisar el elemento básico para hacer modelos estadísticos: la regresión lineal. 7.1 Modelos estadísticos Revisa este video (17') y trata de responder: ¿Qué es un modelo estadístico? ¿Por qué es importante tener buenos modelos? ¿Cómo de determina el error en un modelo? ¿Qué son los grados de libertad? 7.2 La ecuación de la recta Revisa este video (8') y trata de responder: ¿Cómo se define la línea de la ecuación de un GLM que se ajuste mejor a los datos? ¿Cuál es el modelo más básico con el cual se compara un modelo que uno construya? 7.3 La suma de cuadrados Revisa este video (14') y trata de responder: ¿Qué es la SS total? ¿Qué es la SS de los residuales? ¿Qué es la SS del modelo? ¿Cómo se establece que un modelo dado explica mejor los datos que un modelo básico? ¿Cómo se establece cuan bueno es un modelo comparado con cuan malo es? ¿Lo que explica y lo que no explica un modelo? 7.4 La regresión con R Ahora vamos a hacer un análisis básico de regresión. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). Luego importamos el set de datos y le damos una mirada. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(car) Imagina que eres manager de un grupo musical y debes definir como invertir parte de tu presupuesto. A lo que aspiras en el fondo esa aumentar la venta de discos. Para ellos pirmero debes evaluar que factores afectan la venta de discos. Uno de estos factores es la cantidad de dineo invertido en la publicidad. En ese sentido, te gustaría saber cuál es la relación entre el dinero invertido en publicidad y el número de discos vendidos. album1 &lt;- read.csv(&quot;data/datos_ventas_de_discos_1.csv&quot;, header = TRUE) # load data head(album1) ## publicidad ventas ## 1 10.256 330 ## 2 985.685 120 ## 3 1445.563 360 ## 4 1188.193 270 ## 5 574.513 220 ## 6 568.954 170 Primero graficamos. ggplot(album1, aes(publicidad, ventas)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x=&quot;Cantidad de dinero gastado en publicidad&quot;, y=&quot;Ventas&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Lo que nos dice el sentido común, y lo que vemos en el gráfico efectivamente es que a mayor dinero invertido en publicidad debería haber mayores ventas. Es este un buen modelo para predecir el número de ventas a partir del dinero invertido en publicidad? Para analizar estos podemos hacer un modelo lineal con la función lm. En esta función usamos la típica relación entre resultado (ouctome) y variable explicativa (predictor), y le indicamos a R que base de datos usamos (datos): newModel &lt;- lm(outcome~predictor, datos) Luego podemos visualizar los resulatdos con la función summary. m_album &lt;- lm(ventas ~ publicidad, data = album1) summary(m_album) ## ## Call: ## lm(formula = ventas ~ publicidad, data = album1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -152.949 -43.796 -0.393 37.040 211.866 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.341e+02 7.537e+00 17.799 &lt;2e-16 *** ## publicidad 9.612e-02 9.632e-03 9.979 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 65.99 on 198 degrees of freedom ## Multiple R-squared: 0.3346, Adjusted R-squared: 0.3313 ## F-statistic: 99.59 on 1 and 198 DF, p-value: &lt; 2.2e-16 En qué debemos fijarnos dentro de los resultados que obtenemos al aplicar un módelo líneal? En la línea siguientes a &quot;Call&quot; aparece el módelo que usamos. También aparecen los llamados coeficientes que reflejan bajo el nombre de &quot;Estimate&quot; que refleja con que magnitud una variable predictora predice una variable resultado. Por ejemplo, por cada unidad de publicidad invertida el aumento en el número de ventas es 0.09. Y esta relación es significativa, o sea es diferente de 0 (lo que ocurre cuando no hay ninguna relación entre ambas variables). En el fondo este análisis nos dice que la publicidad si impacta sobre la venta de los discos. Sin embargo, a publicidad no es el único que podría afectar las ventas. En este sentido, podríamos estudiar otros factores que afectan esta variable resultados. Para ello hacemos lo que se llama una regresión múltiple. Primero cargamos los datos. album2 &lt;- read.csv(&quot;data/datos_ventas_de_discos_2.csv&quot;, header = TRUE) # load data head(album2) ## publicidad ventas radio eventos ## 1 10.256 330 43 10 ## 2 985.685 120 28 7 ## 3 1445.563 360 35 7 ## 4 1188.193 270 33 7 ## 5 574.513 220 44 5 ## 6 568.954 170 19 5 Podemos graficar la relación entre alguna variable de interés y el número de ventas. Por ejemplo, podríamos visualizar el impacto de la frecuencia de aparición de un tema musical en la radio. ggplot(album2, aes(publicidad, radio)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x=&quot;Número de apariciones en la radio&quot;, y=&quot;Ventas&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Luego podríamos hacer un modelo para entender el impacto de distintos factores en la venta de discos. m_album2 &lt;- lm(ventas ~ publicidad + radio + eventos, data = album2) summary(m_album2) ## ## Call: ## lm(formula = ventas ~ publicidad + radio + eventos, data = album2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -121.324 -28.336 -0.451 28.967 144.132 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -26.612958 17.350001 -1.534 0.127 ## publicidad 0.084885 0.006923 12.261 &lt; 2e-16 *** ## radio 3.367425 0.277771 12.123 &lt; 2e-16 *** ## eventos 11.086335 2.437849 4.548 9.49e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 47.09 on 196 degrees of freedom ## Multiple R-squared: 0.6647, Adjusted R-squared: 0.6595 ## F-statistic: 129.5 on 3 and 196 DF, p-value: &lt; 2.2e-16 ¿Qué conclusiones sacas de este análisis? 7.5 La correlación con R Ahora vamos a hacer un análisis de correlación. En la práctica es lo mismo que hacer una regresión, pero hay algunas funciones dedicadas más a las correlaciones. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(Hmisc) library(ggplot2) library(boot) library(ggm) library(ggpubr) library(ggcorrplot) library(dplyr) Luego importamos el set de datos y le damos una mirada. examData &lt;- read.delim(&quot;data/ExamAnxiety.dat&quot;, header = TRUE) head(examData) ## Code Revise Exam Anxiety Gender ## 1 1 4 40 86.298 Male ## 2 2 11 65 88.716 Female ## 3 3 27 80 70.178 Male ## 4 4 53 80 61.312 Male ## 5 5 4 40 89.522 Male ## 6 6 22 70 60.506 Female Recuerda siempre hacer un gráfico para ver los datos. Por ejemplo, podríamos graficar los niveles de ansiedad versus los resultados en un exámen. scatter &lt;- ggplot(examData, aes(Anxiety, Exam)) scatter + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;Red&quot;) + labs(x = &quot;Niveles de ansiedad&quot;, y = &quot;Desempeño en el examen (%)&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Para hacer una correlación podemos simplemente usar la función cor seleccionando nuestras colmunas de interés. Esta función nos devuelve los coeficientes de correlación. Por defecto se ejecuta una correlación de Pearson. cor(examData[, c(&quot;Exam&quot;, &quot;Anxiety&quot;)]) ## Exam Anxiety ## Exam 1.0000000 -0.4409934 ## Anxiety -0.4409934 1.0000000 Otra función que podemos usar rcorr. Esta función nos devuelve los coeficientes de correlación. Fíjate que para usar esta función le decimos a R explícitamente que librería queremos usar, es decir, Hmisc. Hmisc::rcorr(as.matrix(examData[, c(&quot;Exam&quot;, &quot;Anxiety&quot;)])) ## Exam Anxiety ## Exam 1.00 -0.44 ## Anxiety -0.44 1.00 ## ## n= 103 ## ## ## P ## Exam Anxiety ## Exam 0 ## Anxiety 0 Por último otra función que podemos usar cor.test. Esta función nos devuelve Varias cosas: el valor de p y el coeficiente de correlación. cor.test(examData$Anxiety, examData$Exam) ## ## Pearson&#39;s product-moment correlation ## ## data: examData$Anxiety and examData$Exam ## t = -4.938, df = 101, p-value = 3.128e-06 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.5846244 -0.2705591 ## sample estimates: ## cor ## -0.4409934 También existen otras funciones que nos permiten hacer un gráfico que contenga ggscatter(examData, x = &quot;Anxiety&quot;, y = &quot;Exam&quot;, add = &quot;reg.line&quot;, conf.int = TRUE, cor.coef = TRUE, cor.method = &quot;spearman&quot;, xlab = &quot;Niveles de ansiedad &quot;, ylab = &quot;Desempeño en el examen (%)&quot;) + theme(text = element_text(size=15)) ## `geom_smooth()` using formula &#39;y ~ x&#39; El coeficiente de determinación es una medida que indica la varianza en una variable que es comparida por otra variable. El coeficiente de determinación se puede calcular desde el coeficiente de correlación, elevándolo al cuadrado, y adicionalmente lo podemos multiplicar por 100 para leerlo como porcentaje. cor(examData[, c(&quot;Exam&quot;, &quot;Anxiety&quot;)])^2 * 100 ## Exam Anxiety ## Exam 100.00000 19.44752 ## Anxiety 19.44752 100.00000 corr_selected &lt;- examData %&gt;% dplyr::select(Revise, Exam, Anxiety) %&gt;% cor(use = &quot;pairwise&quot;) %&gt;% round(1) ggcorrplot(corr_selected, type = &quot;lower&quot;, lab = TRUE, show.legend = TRUE) Un paso mas allá de las correlaciones bivariadas (entre dos variables) son las correlaciones parciales. La correlación nos permiten investigar la asociación entre dos variables, tomando en cuenta una tercera variable. Es decir, estudiamos una correlación entre dos variables controlando por el efecto de una tercera variable. Para trabajar esto en R primero vamos a seleccionar algunas columnas de interés. examData2 &lt;- examData[, c(&quot;Exam&quot;, &quot;Anxiety&quot;, &quot;Revise&quot;)] Luego aplicamos la función pcor. En esta función las primeras dos variables son las que queremos estudiar, y en tercer lugar la variables por la que queremos controlar. En el siguiente ejemplo queremos estudiar la relación entre el desempeño en una examen y los niveles de ansiedad, controlando por el tiempo que pasaron los estudiantes haciendo revisión antes del examen. (pc &lt;- pcor(c(&quot;Exam&quot;, &quot;Anxiety&quot;, &quot;Revise&quot;), var(examData2))) ## [1] -0.2466658 Nuevamente podemos calcular el coeficiente de determinación pc^2 * 100 ## [1] 6.084403 Para obtener mas información podemos usar la función pcor.test a la que le inyectamos el objeto que recién creamos. Al usar la función primero hay que decirle cuál es la variable dónde esta los datos (pc en nuestro caso), luego cuantas variables controles hay (1 en nuestro caso) y finalmente cuál es el tamaño de la muestra (103 en nuestro caso). pcor.test(pc, 1, 103) ## $tval ## [1] -2.545307 ## ## $df ## [1] 100 ## ## $pvalue ## [1] 0.01244581 De esta manera sabemos el valor de p para la prueba de asociación entre dos variables, controlando por el efecto de una tercera variable. "],["anova.html", "Capítulo 8 ANOVA 8.1 ¿Por qué necesitamos un ANOVA? 8.2 El ANOVA como un modelo líneal general 8.3 La lógica del ANOVA 8.4 El ANOVA con R", " Capítulo 8 ANOVA En este capítulo vamos a revisar el típico análisis para comparar más de dos grupos, el ANOVA. 8.1 ¿Por qué necesitamos un ANOVA? Revisa este video (9') y trata de responder: ¿Cómo comparamos varias condiciones experimentales? ¿Cuántos distintos tipos de ANOVA existen? ¿De qué dependen del tipo de ANOVA que usemos para realizar un análisis? ¿Qué es un factor en un ANOVA? ¿Qué es un nivel en un ANOVA? ¿Qué es un ANOVA mixto? ¿En un experimento hipotético con 3 condiciones experimentales por qué no podemos usar 3 t-test? ¿Cuanto aumenta el error de tipo 1 cuando aumentamos el número de comparaciones que hacemos? ¿Qué es una prueba omnibus? ¿Cuáles son los supuestos del ANOVA? 8.2 El ANOVA como un modelo líneal general Revisa este video (18') y trata de responder: ¿Qué nos dice el valor F en un ANOVA? ¿Por qué el ANOVA se puede representar como una regresión? ¿Cómo se refleja un t-test en un modelo lineal general (GLM)? ¿Para que nos sirven las variables ficticias (dummy coding) en el ANOVA? ¿Qué refleja el intercepto de la ecuación que representa el ANOVA? ¿Qué reflejan los coeficientes (o betas) de la ecuación que representa el ANOVA? 8.3 La lógica del ANOVA Revisa este video (15') y trata de responder: ¿Qué reflejan los coeficientes (o betas) de la ecuación que representa el ANOVA? ¿Cómo serían los promedios de los grupos si la hipótesis nula se tuviera que aceptar? ¿Qué es la suma de cuadrados (SS) total? ¿Qué es la suma de cuadrados (SS) del modelo? ¿Qué es la suma de cuadrados (SS) de los residuales? 8.4 El ANOVA con R Ahora vamos a hacer el análisis. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Hmisc) library(Rmisc) library(effsize) library(pastecs) library(reshape2) library(car) library(effsize) Luego importamos el set de datos. Aprovechamos de agregar unas etiquetas que nos sirvan a visualizar las condiciones experimentales. Y le damos una mirada. dat1 &lt;- read.csv(&quot;data/inteligencia.csv&quot;, header = TRUE) dat1$Dosis &lt;- factor(dat1$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) dat1 ## Dosis Inteligencia ## 1 Placebo 3 ## 2 Placebo 2 ## 3 Placebo 1 ## 4 Placebo 1 ## 5 Placebo 4 ## 6 Baja 5 ## 7 Baja 2 ## 8 Baja 4 ## 9 Baja 2 ## 10 Baja 3 ## 11 Alta 7 ## 12 Alta 4 ## 13 Alta 5 ## 14 Alta 3 ## 15 Alta 6 Luego, mirar los datos siempre es bueno graficar. # Podemos usar esta función para calcular los estadísticos a través de los participantes. datac &lt;- summarySE(dat1, measurevar=&quot;Inteligencia&quot;, groupvars=&quot;Dosis&quot;) # Luego hacemos el gráfico ggplot(datac, aes(x=Dosis, y=Inteligencia, group=1)) + geom_errorbar(width=.1, aes(ymin=Inteligencia-se, ymax=Inteligencia+se)) + geom_line(colour = &quot;Red&quot;, linetype = &quot;dashed&quot;) + geom_point() + ylab(&quot;Niveles de inteligencia&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) Luego podemos hacer una descripción de los datos. test &lt;- by(dat1$Inteligencia, dat1$Dosis, stat.desc, basic = FALSE, norm = TRUE) lapply(test,round,2) ## $Placebo ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 2.00 2.20 0.58 1.62 1.70 1.30 0.59 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.26 0.14 -1.96 -0.49 0.90 0.42 ## ## $Baja ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 3.00 3.20 0.58 1.62 1.70 1.30 0.41 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.26 0.14 -1.96 -0.49 0.90 0.42 ## ## $Alta ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 5.00 5.00 0.71 1.96 2.50 1.58 0.32 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.00 0.00 -1.91 -0.48 0.99 0.97 La función by permite calcular los estadísticos. La función round redondea los valores a dos décimas. Y la función lapply permite aplicar la función round de forma másiva. Antes de hacer el ANOVA verificamos si existen problemas de homgeneidad de varianza. Podemos hacerlo con la función leveneTest leveneTest(dat1$Inteligencia, dat1$Dosis, center = mean) ## Levene&#39;s Test for Homogeneity of Variance (center = mean) ## Df F value Pr(&gt;F) ## group 2 0.0917 0.913 ## 12 Si la prueba de Levene es significativa entonces las varianzas son diferentes entre los grupos. En ese caso podemos aplicar la F de Welch a los datos. Esta prueba hace ajustes por las diferencias que hay entre las varianzas de cada grupo. AOV_W &lt;- oneway.test(Inteligencia ~ Dosis, data = dat1) AOV_W ## ## One-way analysis of means (not assuming equal variances) ## ## data: Inteligencia and Dosis ## F = 4.3205, num df = 2.0000, denom df = 7.9434, p-value = 0.05374 En nuestro caso no tuvimos problema en relación a la homgeneidad de varianza. Podemos hacer entonces el análisis estadístico, aplicando la función aov. Enseguida aplicamos la función sumary para visualizar los resultados del test. m_AOV &lt;- aov(Inteligencia ~ Dosis, data = dat1) summary(m_AOV) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dosis 2 20.13 10.067 5.119 0.0247 * ## Residuals 12 23.60 1.967 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Pr(&gt;F) indica la probabilidad de que ocurra un F-ratio del tamaño del obtenido si no hubiera efecto en la población. En esta punto sabemos que existe un efecto en alguna parte. El ANOVA es un test omnibus. Pero todavía no sabemos exactamente dónde esta el efecto. Es decir, entre qué grupos hay diferencias. Vamos a volver sobre las ideas comentadas en los videos anteriores. ¿Te acuerdas que reflejan el intercepto y la pendiente (o beta) de una ecuación que represente el ANOVA? Vamos a usar el dummy coding para desarrollar esta idea. Primero carguemos uno base de datos idéntica a la anterior pero con una columna extra con el dumming coding. dat2 &lt;- read.csv(&quot;data/inteligencia_c_Variables.csv&quot;, header = TRUE) dat2$Dosis &lt;- factor(dat2$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) dat2 ## Dosis Inteligencia Baja Alta ## 1 Placebo 3 0 0 ## 2 Placebo 2 0 0 ## 3 Placebo 1 0 0 ## 4 Placebo 1 0 0 ## 5 Placebo 4 0 0 ## 6 Baja 5 1 0 ## 7 Baja 2 1 0 ## 8 Baja 4 1 0 ## 9 Baja 2 1 0 ## 10 Baja 3 1 0 ## 11 Alta 7 0 1 ## 12 Alta 4 0 1 ## 13 Alta 5 0 1 ## 14 Alta 3 0 1 ## 15 Alta 6 0 1 Vamos a hacer un modelo lineal dónde tratemos de predecir los niveles de inteligencia en base a nuestro dummy coding (que en el fondo refleja los efectos que resultan de comparar los grupos experimentales con un grupo base). m_dummy1 &lt;- lm(Inteligencia ~ Baja + Alta, data = dat2) summary(m_dummy1) ## ## Call: ## lm(formula = Inteligencia ~ Baja + Alta, data = dat2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2000 0.6272 3.508 0.00432 ** ## Baja 1.0000 0.8869 1.127 0.28158 ## Alta 2.8000 0.8869 3.157 0.00827 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Al mismo tiempo aprovechemos de calcular los promedios para los valores de inteligencia de acuerdo a cada grupo experimental aggregate(dat2$Inteligencia, list(dat2$Dosis), mean) ## Group.1 x ## 1 Placebo 2.2 ## 2 Baja 3.2 ## 3 Alta 5.0 Fíjate que: El intercepto del modelo (el &quot;Estimate&quot; de la fila &quot;Intercept&quot;) corresponde al promedio en los niveles de inteligencia para el grupo placebo. El beta 1 del modelo (el &quot;Estimate&quot; de la fila &quot;Baja&quot;) corresponde a la diferencia en los niveles de inteligencia entre el grupo con dosis baja y el grupo placebo. El beta 2 del modelo (el &quot;Estimate&quot; de la fila &quot;Alta&quot;) corresponde a la diferencia en los niveles de inteligencia entre el grupo con dosis alta y el grupo placebo. Tal como lo habíamos concebido anteriormente! ¿Necesitamos definir un dummy coding para hacer esto? En realidad R lo hace por defecto. Si hacemos un modelo para predecir los niveles de inteligencia directamente de la columna que indica las dosis obtenemos exactamente el mismo modelo. m_dummy2 &lt;- lm(Inteligencia ~ Dosis, data = dat2) summary(m_dummy2) ## ## Call: ## lm(formula = Inteligencia ~ Dosis, data = dat2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2000 0.6272 3.508 0.00432 ** ## DosisBaja 1.0000 0.8869 1.127 0.28158 ## DosisAlta 2.8000 0.8869 3.157 0.00827 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Por úlitmo, fíjate que cuando usamos la función aov para hacer el ANOVA obtuvimos una versión resumida de lo que obtenemos al realizar el modelo lineal con la función lm. En el fondo esto refleja que una ANOVA es un modelo lineal que esta disfrazado. Esto es lo que se llama una función wraper. De hecho podemos ver el modelo completo si al resultado del aov le aplicamos la función summary.lm. summary.lm(m_AOV) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = dat1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2000 0.6272 3.508 0.00432 ** ## DosisBaja 1.0000 0.8869 1.127 0.28158 ## DosisAlta 2.8000 0.8869 3.157 0.00827 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Por último, podemos hacer algunos gráficos que podemos extraer del modelo de ANOVA. plot(m_AOV) Los dos primeros gráficos son los mas importantes. El gráfico 1 muestra la homogeneidad de varianza. Si ves una forma de embudo entonces hay en problemas en la homgeneidad de varianza. La idea es que los puntos estén igualmente repartidos. Es decir, las variaciones son similares entre los grupos. El gráfico 2 es un gráfico Q-Q. Si los puntos están sobre la diagonal entonces se cumple el suspuesto de la normalidad de los datos. "],["pasos-después-de-un-anova.html", "Capítulo 9 Pasos después de un ANOVA 9.1 ¿Qué hacemos después de un ANOVA? 9.2 Comparaciones planificadas 9.3 Cálculos con R 9.4 Pruebas post-hoc 9.5 Cálculos con R", " Capítulo 9 Pasos después de un ANOVA En este capítulo vamos a revisar que podemos hacer después de un ANOVA. 9.1 ¿Qué hacemos después de un ANOVA? Revisa este video (12') y trata de responder: ¿Que hago después de una prueba omnibus? ¿De qué depende el tipo de análisis que se hace después del ANOVA? ¿Qué significa que desglocemos la varianza explicada en los distintos contrastes en el análisis de contrastes planificados? ¿En un experimento dónde analizo el efecto de dos dosis de droga comparada con un placebo, que contrastes planificados se podrían hacer y que indican el intercepto y los betas de este modelo? ¿Por que es importante que el contraste que hagamos sea un contraste ortogonal? 9.2 Comparaciones planificadas Revisa este video (18') y trata de responder: ¿Para que sirven los contrastes que evaluan una tendencia líneal o cuadrática? 9.3 Cálculos con R Ahora vamos a hacer el análisis. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Hmisc) library(Rmisc) library(effsize) library(pastecs) library(reshape2) library(car) library(effsize) Primero, vamos a revisar el código para realizar los contrastes planificados. Recuerda que se utiliza un dummy coding en un modelo de regresión para que los valores b representen las diferencias entre los promedios de los contrastes que se quieren evaluar. Importamos el set de datos. Aprovechamos de agregar unas etiquetas que nos sirvan a visualizar las condiciones experimentales. Y le damos una mirada. contrastData &lt;- read.csv(&quot;data/inteligencia_c_Contrast_Planif.csv&quot;, header = TRUE) contrastData$Dosis &lt;- factor(contrastData$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) contrastData ## Dosis Inteligencia Compars1 Compars2 ## 1 Placebo 3 -2 0 ## 2 Placebo 2 -2 0 ## 3 Placebo 1 -2 0 ## 4 Placebo 1 -2 0 ## 5 Placebo 4 -2 0 ## 6 Baja 5 1 -1 ## 7 Baja 2 1 -1 ## 8 Baja 4 1 -1 ## 9 Baja 2 1 -1 ## 10 Baja 3 1 -1 ## 11 Alta 7 1 1 ## 12 Alta 4 1 1 ## 13 Alta 5 1 1 ## 14 Alta 3 1 1 ## 15 Alta 6 1 1 Usemos las columnas que corresponden a las variables dummy. Compars1 refleja la diferencia para los niveles de inteligencia entre el placebo y cualquier dosis de droga (en realidad el promedio de ambas). Compars2 refleja la diferencia para los niveles de inteligencia entre la dosis baja y la dosis alta. m_contrastedAOV &lt;- lm(Inteligencia ~ Compars1 + Compars2, data = contrastData) summary(m_contrastedAOV) ## ## Call: ## lm(formula = Inteligencia ~ Compars1 + Compars2, data = contrastData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4667 0.3621 9.574 5.72e-07 *** ## Compars1 0.6333 0.2560 2.474 0.0293 * ## Compars2 0.9000 0.4435 2.029 0.0652 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 ¿Qué nos dice este modelo? El F es el mismo. Lo que cambia son los coeficientes de regresión. Primero. El intercepto es el gran promedio (3.467). Verifiquemos. # promedio a través de todas las condiciones mean(contrastData$Inteligencia) ## [1] 3.466667 # promedio a través de todas las condiciones experimentales varX &lt;- contrastData[contrastData$Dosis != &quot;Placebo&quot;,] mean(varX$Inteligencia) ## [1] 4.1 El contraste 1 (o b1) refleja la diferencia en los niveles de inteligencia entre la aplicación de la droga y el placebo. El coeficiente de regresión (0.63) para el contraste 1 es 1/3 de esta diferencia (1.9/3 = 0.633). El FWE se controla haciendo que el coeficiente de regresión sea igual a la diferencia real dividida por el número de grupos en el contraste (en este caso 3). El contraste 2 (o b2) refleja la diferencia en los niveles de inteligencia entre la aplicación de una dosis alta droga y una dosis baja de droga. El coeficiente de regresión (0.9) para el contraste 1 es 1/2 de esta diferencia (1.8/2 = 0.9). El FWE se controla haciendo que el coeficiente de regresión sea igual a la diferencia real dividida por el número de grupos en el contraste (en este caso 3). Uno podría pensar que siempre hay que crear las dos columnas del dummy coding en los datos. En realidad eso se puede hacer en R. Importemos los datos originales. inteligData2 &lt;- read.csv(&quot;data/inteligencia.csv&quot;, header = TRUE) inteligData2$Dosis &lt;- factor(inteligData2$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) Si revisas los valores de dosis encontrarás que tienen los nombres correspondientes a las condiciones experimentales, y al final veras que tiene 3 niveles: Placebo, Baja y Alta inteligData2$Dosis ## [1] Placebo Placebo Placebo Placebo Placebo Baja Baja Baja Baja Baja Alta ## [12] Alta Alta Alta Alta ## Levels: Placebo Baja Alta Por defecto R toma el primer grupo base y crea dos variables dummy que se comparan con ese grupo base. Puedes mirar estos contrastes con la función contrasts. contrasts(inteligData2$Dosis) ## Baja Alta ## Placebo 0 0 ## Baja 1 0 ## Alta 0 1 Pero, tu puedes crear manualmente contrastes específicos. Por ejemplo, con la función contr.treatment puedes crear 2 variables dummy (a partir de 3 condiciones exprimentales) dónde decidas que el grupo base es el segundo. contr.treatment(3, base = 2) ## 1 3 ## 1 1 0 ## 2 0 0 ## 3 0 1 Luego para que estos contraste surgan efecto lo inyectas como contrastes contrasts(inteligData2$Dosis) &lt;- contr.treatment(3, base = 2) Luego verificas como quedaron los contrastes. inteligData2$Dosis ## [1] Placebo Placebo Placebo Placebo Placebo Baja Baja Baja Baja Baja Alta ## [12] Alta Alta Alta Alta ## attr(,&quot;contrasts&quot;) ## 1 3 ## Placebo 1 0 ## Baja 0 0 ## Alta 0 1 ## Levels: Placebo Baja Alta Y finalmente realizas el ANOVA nuevamente. m_AOV3 &lt;- aov(Inteligencia ~ Dosis, data = inteligData2) summary.lm(m_AOV3) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = inteligData2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.2000 0.6272 5.102 0.000261 *** ## Dosis1 -1.0000 0.8869 -1.127 0.281584 ## Dosis3 1.8000 0.8869 2.029 0.065192 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Fíjate los betas son diferentes. Ahora, en R hay ciertos contrastes que ya están preparados. Uno de ellos es el contraste Helmert. Trata de entender que contrastes se hacen en este caso. Igual que antes creas el contraste lo inyectas en la base de datos y verificas. contr.helmert(3) ## [,1] [,2] ## 1 -1 -1 ## 2 1 -1 ## 3 0 2 contrasts(inteligData2$Dosis) &lt;- contr.helmert(3) inteligData2$Dosis ## [1] Placebo Placebo Placebo Placebo Placebo Baja Baja Baja Baja Baja Alta ## [12] Alta Alta Alta Alta ## attr(,&quot;contrasts&quot;) ## [,1] [,2] ## Placebo -1 -1 ## Baja 1 -1 ## Alta 0 2 ## Levels: Placebo Baja Alta Luego calculas el ANOVA nuevamente. m_AOV4 &lt;- aov(Inteligencia ~ Dosis, data = inteligData2) summary.lm(m_AOV4) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = inteligData2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4667 0.3621 9.574 5.72e-07 *** ## Dosis1 0.5000 0.4435 1.127 0.2816 ## Dosis2 0.7667 0.2560 2.994 0.0112 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Más importante que esto es que puedas crear tu propios contrastes. Para ello, te recomiendo darles nombres que te permitan entender esos contrastes. Por ejemplo, siguiendo nuestro ejemplo anterior podríamos tener dos hipótesis específicas. Primero, comparamos el efecto del tratamiento de la droga versus el grupo placebo. Para ello concatenamos -2, 1 y 1, que corresponden respectivamente a Placebo, Low y High. C_vs_Treatment &lt;- c(-2,1,1) Segundo, comparamos el efecto del dosis alta versus la dsis baja. Para ello concatenamos 0, -1 y 1, que corresponden respectivamente a Placebo, Low y High. Low_vs_High &lt;- c(0,-1,1) Luego ponemos los dos contrastes en la base de datos y calculamos un nuevo ANOVA. contrasts(inteligData2$Dosis) &lt;- cbind(C_vs_Treatment, Low_vs_High) m_AOV4 &lt;- aov(Inteligencia ~ Dosis, data = inteligData2) summary.lm(m_AOV4) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = inteligData2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4667 0.3621 9.574 5.72e-07 *** ## DosisC_vs_Treatment 0.6333 0.2560 2.474 0.0293 * ## DosisLow_vs_High 0.9000 0.4435 2.029 0.0652 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 Fíjate que obtenemos los mismos resultados que cuando utilizamos la base de datos dónde orginalmente se había definido las variables dummy. Por último, algo que también podriamos hacer es un análisis de tendencia líneal. Si pensamos en los efectos de las drogas (vean el gráfico arriba) esperaríamos que a medida que aumenta la dosis aumentará su efecto de manera lineal. Para ello podemos crear un contraste que de cuenta de este efecto lineal. Para ello usamos la función contr.poly y lo inyectamos en la base de datos. contr.poly(3) ## .L .Q ## [1,] -7.071068e-01 0.4082483 ## [2,] -7.850462e-17 -0.8164966 ## [3,] 7.071068e-01 0.4082483 contrasts(inteligData2$Dosis) &lt;- contr.poly(3) contrasts(inteligData2$Dosis) ## .L .Q ## Placebo -7.071068e-01 0.4082483 ## Baja -7.850462e-17 -0.8164966 ## Alta 7.071068e-01 0.4082483 Finalmente, calculamos el ANOVA nuevamente trend_M &lt;- aov(Inteligencia ~ Dosis, data = inteligData2) summary.lm(trend_M) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = inteligData2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4667 0.3621 9.574 5.72e-07 *** ## Dosis.L 1.9799 0.6272 3.157 0.00827 ** ## Dosis.Q 0.3266 0.6272 0.521 0.61201 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 La fila &quot;L&quot; indica un efecto lineal y la fila &quot;Q&quot; indica un efecto cuadrático. ¿Qué ves? 9.4 Pruebas post-hoc Revisa este video (15') y trata de responder: ¿Qué tipos de pruebas post-hoc existen? ¿Cuál es el riesgo que corremos si usamos una prueba post-hoc muy exigente (o conservadora)? ¿Cuál es el riesgo que corremos si usamos una prueba post-hoc poco exigente (o conservadora)? 9.5 Cálculos con R Ahora vamos a revisar el código para realizar las pruebas post-hoc. Usemos el set de datos originales. Aprovechamos de agregar unas etiquetas que nos sirvan a visualizar las condiciones experimentales. Y le damos una mirada. dat1 &lt;- read.csv(&quot;data/inteligencia.csv&quot;, header = TRUE) dat1$Dosis &lt;- factor(dat1$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) En las pruebas post-hoc comparamos todo con todo. Para ello usamos la función pairwise.t.test. Pero, además podemos aplicar una corrección (en el parámetro p.adjust.method) para lidiar con el error de tipo 1. Veamos que pasa cuando no agregamos ninguna corrección. pairwise.t.test(dat1$Inteligencia, dat1$Dosis, p.adjust.method = &quot;none&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: dat1$Inteligencia and dat1$Dosis ## ## Placebo Baja ## Baja 0.2816 - ## Alta 0.0083 0.0652 ## ## P value adjustment method: none Veamos que pasa cuando usamos una corrección de Bonferroni. pairwise.t.test(dat1$Inteligencia, dat1$Dosis, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: dat1$Inteligencia and dat1$Dosis ## ## Placebo Baja ## Baja 0.845 - ## Alta 0.025 0.196 ## ## P value adjustment method: bonferroni Veamos que pasa cuando usamos una corrección de Benjamini-Hochberg. pairwise.t.test(dat1$Inteligencia, dat1$Dosis, p.adjust.method = &quot;BH&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: dat1$Inteligencia and dat1$Dosis ## ## Placebo Baja ## Baja 0.282 - ## Alta 0.025 0.098 ## ## P value adjustment method: BH Para terminar siempre es bueno calcular el tamaño del efecto. Recuerda que hicimos en el ANOVA. m_AOV &lt;- aov(Inteligencia ~ Dosis, data = dat1) summary.lm(m_AOV) ## ## Call: ## aov(formula = Inteligencia ~ Dosis, data = dat1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.0 -1.2 -0.2 0.9 2.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2000 0.6272 3.508 0.00432 ** ## DosisBaja 1.0000 0.8869 1.127 0.28158 ## DosisAlta 2.8000 0.8869 3.157 0.00827 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.402 on 12 degrees of freedom ## Multiple R-squared: 0.4604, Adjusted R-squared: 0.3704 ## F-statistic: 5.119 on 2 and 12 DF, p-value: 0.02469 En el contexto de ANOVA, r^2 generalmente se llama eta cuadrado. Alternativamente también podemos usar una función. omega &lt;- function(SSm, SSr, dfm, MSr) { SSt = SSm + SSr omega = (SSm-(dfm*MSr))/(SSt+MSr) print(paste(&quot;Omega-Squared: &quot;, omega)) omega } omega1 &lt;- omega(20.133, 23.600, 2, 1.9667) ## [1] &quot;Omega-Squared: 0.35447935106795&quot; sqrt(omega1) ## [1] 0.5953817 "],["otros-anova.html", "Capítulo 10 Otros ANOVA 10.1 Tipos de ANOVA 10.2 ANOVA factorial 10.3 ANOVA de medidas repetidas 10.4 ANCOVA 10.5 MANOVA", " Capítulo 10 Otros ANOVA En este capítulo vamos a revisar que otros tipos de ANOVA podemos realizar. 10.1 Tipos de ANOVA Revisa este video (13') y trata de responder: ¿De qué depende el tipo de ANOVA que utilicemos? 10.2 ANOVA factorial Ahora vamos a hacer un análisis de ANOVA factorial. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Hmisc) library(Rmisc) library(effsize) library(pastecs) library(reshape2) library(car) library(effsize) Primero importamos el set de datos y le damos una mirada. gogglesData &lt;- read.csv(&quot;data/goggle_beer_effect.csv&quot;, header = TRUE) head(gogglesData) ## gender alcohol attractiveness ## 1 Female None 65 ## 2 Female None 70 ## 3 Female None 60 ## 4 Female None 60 ## 5 Female None 60 ## 6 Female None 55 Enseguida es útil decirle a R que variables corresponden a factores. gogglesData$gender &lt;- factor(gogglesData$gender) gogglesData$alcohol &lt;- factor(gogglesData$alcohol) str(gogglesData) ## &#39;data.frame&#39;: 48 obs. of 3 variables: ## $ gender : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ alcohol : Factor w/ 3 levels &quot;2 Pints&quot;,&quot;4 Pints&quot;,..: 3 3 3 3 3 3 3 3 1 1 ... ## $ attractiveness: int 65 70 60 60 60 55 60 55 70 65 ... También podemos cambiar el nombre de las variables si nos facilita la tarea de hacer gráficos por ejemplo. levels(gogglesData$alcohol)[match(&quot;None&quot;, levels(gogglesData$alcohol))] &lt;- &quot;P0&quot; levels(gogglesData$alcohol)[match(&quot;2 Pints&quot;, levels(gogglesData$alcohol))] &lt;- &quot;P2&quot; levels(gogglesData$alcohol)[match(&quot;4 Pints&quot;, levels(gogglesData$alcohol))] &lt;- &quot;P4&quot; str(gogglesData) ## &#39;data.frame&#39;: 48 obs. of 3 variables: ## $ gender : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ alcohol : Factor w/ 3 levels &quot;P2&quot;,&quot;P4&quot;,&quot;P0&quot;: 3 3 3 3 3 3 3 3 1 1 ... ## $ attractiveness: int 65 70 60 60 60 55 60 55 70 65 ... Fíjate que el nivel base quedó al final. levels(gogglesData$alcohol) ## [1] &quot;P2&quot; &quot;P4&quot; &quot;P0&quot; Necesitamos reordenar los niveles para este factor. gogglesData$alcohol &lt;- factor(gogglesData$alcohol, levels = c(&quot;P0&quot;, &quot;P2&quot;, &quot;P4&quot;)) levels(gogglesData$alcohol) ## [1] &quot;P0&quot; &quot;P2&quot; &quot;P4&quot; Luego, podemos hacer algunos gráficos para visualizar los efectos. Por ejemplo, podemos hacer un histograma de los valores de atractivo en función del género y del consumo de alcohol. fig_boxplot1 &lt;- ggplot(gogglesData, aes(alcohol, attractiveness)) + geom_boxplot() + facet_wrap(~gender) + labs(x = &quot;Consumo de alcohol&quot;, y = &quot;Atractivo promedio (%)&quot;) fig_boxplot1 Este mismo gráfico, valores de atractivo en función del género y del consumo de alcohol, se puede hacer en formato de líneas. fig_linesplot1 &lt;- ggplot(gogglesData, aes(alcohol, attractiveness, colour = gender)) + stat_summary(fun.y = mean, geom = &quot;point&quot;) + stat_summary(fun.y = mean, geom = &quot;line&quot;, aes(group= gender)) + stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, width = 0.2) + labs(x = &quot;Consumo de alcohol&quot;, y = &quot;Atractivo promedio (%)&quot;, colour = &quot;Gender&quot;) ## Warning: `fun.y` is deprecated. Use `fun` instead. ## `fun.y` is deprecated. Use `fun` instead. fig_linesplot1 O en formato de barras. fig_barplot1 &lt;- ggplot(gogglesData, aes(alcohol, attractiveness, fill = gender)) + stat_summary(fun.data = mean_cl_normal, geom = &quot;errorbar&quot;, position=position_dodge(width=0.90), width = 0.2) + stat_summary(fun.y = mean, geom = &quot;bar&quot;, position=&quot;dodge&quot;) + labs(x = &quot;Consumo de alcohol&quot;, y = &quot;Atractivo promedio (%)&quot;, fill = &quot;Gender&quot;) ## Warning: `fun.y` is deprecated. Use `fun` instead. fig_barplot1 Estos gráfico son muy informativos. ¿Que ves? Una manera de visualizar los efectos que estamos estudiando podemos separar los efectos. Esto es, podemos visualizar los niveles de atractivo en función de un sólo factor. Por ejemplo, podemos visualizar el efecto del género en los niveles de atractivo. Este efecto corresponde al efecto principal del género. fig_bargender1 &lt;- ggplot(gogglesData, aes(gender, attractiveness)) + stat_summary(fun.y = mean, geom = &quot;bar&quot;, fill = &quot;White&quot;, colour = &quot;Black&quot;) + stat_summary(fun.data = mean_cl_normal, geom = &quot;pointrange&quot;) + labs(x = &quot;Género&quot;, y = &quot;Atractivo promedio (%)&quot;) + scale_y_continuous(breaks=seq(0,80, by = 10)) ## Warning: `fun.y` is deprecated. Use `fun` instead. fig_bargender1 También podemos visualizar el efecto del consumo de alcohol en los niveles de atractivo. Este efecto corresponde al efecto principal del consumo de alcohol. fig_barbeer1 &lt;- ggplot(gogglesData, aes(alcohol, attractiveness)) + stat_summary(fun.y = mean, geom = &quot;bar&quot;, fill = &quot;White&quot;, colour = &quot;Black&quot;) + stat_summary(fun.data = mean_cl_normal, geom = &quot;pointrange&quot;) + labs(x = &quot;Consumo de alcohol&quot;, y = &quot;Atractivo promedio (%)&quot;) + scale_y_continuous(breaks=seq(0,80, by = 10)) ## Warning: `fun.y` is deprecated. Use `fun` instead. fig_barbeer1 Antes de hacer los análisis propiamente tal podemos describir un poco los datos y evaluar los supuestos de la estadística parámetrica. describ &lt;- by(gogglesData$attractiveness, gogglesData$gender, stat.desc) lapply(describ, round, 2) ## $Female ## nbr.val nbr.null nbr.na min max range sum ## 24.00 0.00 0.00 50.00 70.00 20.00 1445.00 ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 60.00 60.21 1.29 2.68 40.17 6.34 0.11 ## ## $Male ## nbr.val nbr.null nbr.na min max range sum ## 24.00 0.00 0.00 20.00 85.00 65.00 1355.00 ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 60.00 56.46 3.78 7.81 342.35 18.50 0.33 describ &lt;- by(gogglesData$attractiveness, gogglesData$alcohol, stat.desc) lapply(describ, round, 2) ## $P0 ## nbr.val nbr.null nbr.na min max range sum ## 16.00 0.00 0.00 50.00 80.00 30.00 1020.00 ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 62.50 63.75 2.12 4.51 71.67 8.47 0.13 ## ## $P2 ## nbr.val nbr.null nbr.na min max range sum ## 16.00 0.00 0.00 45.00 85.00 40.00 1035.00 ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 65.00 64.69 2.48 5.28 98.23 9.91 0.15 ## ## $P4 ## nbr.val nbr.null nbr.na min max range sum ## 16.00 0.00 0.00 20.00 70.00 50.00 745.00 ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 50.00 46.56 3.59 7.64 205.73 14.34 0.31 describ &lt;- by(gogglesData$attractiveness, list(gogglesData$alcohol, gogglesData$gender), stat.desc, basic = FALSE) lapply(describ, round, 2) ## [[1]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 60.00 60.62 1.75 4.14 24.55 4.96 0.08 ## ## [[2]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 62.50 62.50 2.31 5.47 42.86 6.55 0.10 ## ## [[3]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 55.00 57.50 2.50 5.91 50.00 7.07 0.12 ## ## [[4]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 67.50 66.88 3.65 8.64 106.70 10.33 0.15 ## ## [[5]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 67.50 66.88 4.43 10.47 156.70 12.52 0.19 ## ## [[6]] ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 32.50 35.62 3.83 9.06 117.41 10.84 0.30 También podemos evaluar la homogenididad de varianza. leveneTest(gogglesData$attractiveness, gogglesData$gender, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 19.979 5.08e-05 *** ## 46 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 leveneTest(gogglesData$attractiveness, gogglesData$alcohol, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 2.3238 0.1095 ## 45 leveneTest(gogglesData$attractiveness, interaction(gogglesData$alcohol, gogglesData$gender), center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 5 1.4252 0.2351 ## 42 Antes de hacer el análisis de ANOVA podemos aprovechar de setear las comparaciones planificadas. ¿Para un diseño de este tipo que comparaciones harías? Una posibilidad es evaluar el efecto del género. Es decir, comparar hombres versus mujeres. Para hacer esto usamos un dummy coding muy simple. ¿Por qué simple? Porque simplemente comparas uno contra el otro. Fijate en el orden de los niveles en cada factor. levels(gogglesData$gender) ## [1] &quot;Female&quot; &quot;Male&quot; Entonces, puedes crear el siguiente constraste .M_vs_F &lt;- c(-1, 1) .M_vs_F ## [1] -1 1 Otra posibilidad es evaluar el efecto del consumo de alcohol. Es decir, comparar agua versus pint versus 2 pints.Para hacer esto usamos otro dummy coding. Para hacer estos de nuevo nos fijamos en el orden de los niveles en cada factor. levels(gogglesData$alcohol) ## [1] &quot;P0&quot; &quot;P2&quot; &quot;P4&quot; ¿Que efectos podríamos querer ver? Por ejemplo, el efecto de ingerir alcohol. .Non_vs_P &lt;- c(-2, 1, 1) .Non_vs_P ## [1] -2 1 1 Otro efecto que podemos estudiar es la diferencia producidad por 1 pint versus 2 pints. .P2_vs_P4 &lt;- c(0, -1, 1) .P2_vs_P4 ## [1] 0 -1 1 Una vez que creamos los contraste lo ponemos en un vector. contrasts(gogglesData$alcohol) &lt;- cbind(.Non_vs_P, .P2_vs_P4) contrasts(gogglesData$gender) &lt;- cbind(.M_vs_F) Y los inyectamos en las bases de datos. contrasts(gogglesData$alcohol) &lt;- cbind(.Non_vs_P, .P2_vs_P4) contrasts(gogglesData$gender) &lt;- cbind(.M_vs_F) Luego puedes verificar para el factor género, y ... gogglesData$gender ## [1] Female Female Female Female Female Female Female Female Female Female Female Female Female ## [14] Female Female Female Female Female Female Female Female Female Female Female Male Male ## [27] Male Male Male Male Male Male Male Male Male Male Male Male Male ## [40] Male Male Male Male Male Male Male Male Male ## attr(,&quot;contrasts&quot;) ## .M_vs_F ## Female -1 ## Male 1 ## Levels: Female Male ... consumo de alcohol gogglesData$alcohol ## [1] P0 P0 P0 P0 P0 P0 P0 P0 P2 P2 P2 P2 P2 P2 P2 P2 P4 P4 P4 P4 P4 P4 P4 P4 P0 P0 P0 P0 P0 P0 P0 ## [32] P0 P2 P2 P2 P2 P2 P2 P2 P2 P4 P4 P4 P4 P4 P4 P4 P4 ## attr(,&quot;contrasts&quot;) ## .Non_vs_P .P2_vs_P4 ## P0 -2 0 ## P2 1 -1 ## P4 1 1 ## Levels: P0 P2 P4 Una vez que hemos seteado nuestros contrastes podemos hacer el modelo y visualizar los resultados. En el modelo tratamos de predecir los valores de atractivo en base al género, el consumo de alcohol y la interacción entre ambos factores. Para ello se usa un simbolo (*) que indica que queremos analizar los efectos principales y el efecto de interacción. gogglesModel &lt;- aov(attractiveness ~ gender*alcohol, gogglesData) Anova(gogglesModel, type=&quot;III&quot;) ## Anova Table (Type III tests) ## ## Response: attractiveness ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 163333 1 1967.0251 &lt; 2.2e-16 *** ## gender 169 1 2.0323 0.1614 ## alcohol 3332 2 20.0654 7.649e-07 *** ## gender:alcohol 1978 2 11.9113 7.987e-05 *** ## Residuals 3488 42 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Si miras los valores de F verás que hay un efecto principal del alcohol y un efecto de interacción género-consumo de alcohol. El efecto principal que tenemos aquí refleja que hay un efecto del alcohol (mira el gráfico). Pero, fíjate que el efecto del alcohol en realidad esta calificado por una interación con el género. Es decir, el efecto del consumo de alcohol sobre los niveles de atractivo no son iguales para los dos géneros. En otras palabras. A la luz de una interacción no tiene sentido interpretar el efecto principal. ¿Qué indican los resultados? Ten en cuenta los resultados estadísticos y el gráfico. fig_linesplot1 Los resultados muestran que las mujeres mantienen altos estándares en la selección de su pareja sin importar el consumo de alcohol. Los hombres toman 4 pints y terminan con parejas que tienen un menor atractivo. Es decir, ocurre el &quot;goggle bear effect&quot;. Veamos las comparaciones planificadas para revisar mayores detalles. summary.lm(gogglesModel) ## ## Call: ## aov(formula = attractiveness ~ gender * alcohol, data = gogglesData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -21.875 -5.625 -0.625 5.156 19.375 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 58.333 1.315 44.351 &lt; 2e-16 *** ## gender.M_vs_F -1.875 1.315 -1.426 0.161382 ## alcohol.Non_vs_P -2.708 0.930 -2.912 0.005727 ** ## alcohol.P2_vs_P4 -9.062 1.611 -5.626 1.37e-06 *** ## gender.M_vs_F:alcohol.Non_vs_P -2.500 0.930 -2.688 0.010258 * ## gender.M_vs_F:alcohol.P2_vs_P4 -6.562 1.611 -4.074 0.000201 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.112 on 42 degrees of freedom ## Multiple R-squared: 0.6111, Adjusted R-squared: 0.5648 ## F-statistic: 13.2 on 5 and 42 DF, p-value: 9.609e-08 ¿Qué vemos? Primero. No hay un impacto del género (gender.M_vs_F). Segundo. Parece que cualquier cantidad de alcohol afecta la percepción de atractivo cuando se compara con una condición sin alcohol (alcohol.Non_vs_P). Sin embargo, esto no es real. La comparación es significativa porque considera el efecto combinado de 2 y 4 pints, y las 4 pints tiene un efecto que arrastra el efecto total. De hecho si miramos el contraste de 2 versus 4 pints (alcohol.P2_vs_P4) vemos que hay un diferencia entre 2 y 4 pints. El promedio del grupo de 2 pints (64.69) es diferente del promedio del grupo de 4 pints (46.56). Esta diferencia es de -18.13 (46.56 - 64.69). El beta es este valor dividido por el número de grupos involucrados en el contraste (-18.13/2 = 9.06). Tercero. En las interacciones (gender.M_vs_F:alcohol.Non_vs_P y gender.M_vs_F:alcohol.P2_vs_P4) se evalúan sí los efectos del consumo de alcohol son diferentes entre hombres y mujeres. Sabemos que esta interacción refleja que el efecto del consumo de alcohol depende del género. Al igual que en el punto anterior observamos que hay un diferencia entre consumir 4 pints y 2 pints, pero esto ocurre sólo para los hombres. 10.3 ANOVA de medidas repetidas Ahora vamos a hacer un análisis un ANOVA de medidas repetidas. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Rmisc) library(pastecs) library(reshape) library(ez) library(multcomp) Primero importamos el set de datos y le damos una mirada. dat1 &lt;- read.csv(&quot;data/insectos_y_tiempo_vomito.csv&quot;, header = TRUE) str(dat1) ## &#39;data.frame&#39;: 8 obs. of 5 variables: ## $ participante : chr &quot;P1&quot; &quot;P2&quot; &quot;P3&quot; &quot;P4&quot; ... ## $ insecto.al.palo : int 8 9 6 5 8 7 10 12 ## $ testiculo.de.canguro: int 7 5 2 3 4 5 2 6 ## $ ojos.de.pescado : int 1 2 3 1 5 6 7 8 ## $ larvas.de.polillas : int 6 5 8 9 8 7 2 1 Enseguida transformamos los datos de formato wide a long y renombramos las columnas. dat1.long &lt;- melt(dat1, id = &quot;participante&quot;, measured = c(&quot;insecto.al.palo&quot;, &quot;testiculo.de.canguro&quot;, &quot;ojos.de.pescado&quot;, &quot;larvas.de.polillas&quot;)) names(dat1.long) &lt;- c(&quot;participante&quot;, &quot;animal&quot;, &quot;vomito&quot;) Antes de hacer cualquier análisis miramos los datos con un gráfico. Usamos la función summarySEwithin para calcular los estadísticos. datac &lt;- summarySEwithin(dat1.long, measurevar=&quot;vomito&quot;, withinvars=&quot;animal&quot;, idvar=&quot;participante&quot;) Luego hacemos el gráfico. ggplot(datac, aes(x=animal, y=vomito, group=1)) + geom_errorbar(width=.1, aes(ymin=vomito-se, ymax=vomito+se)) + geom_line(colour = &quot;Red&quot;, linetype = &quot;dashed&quot;) + geom_point() + ylab(&quot;Tiempo para vomitar (segundos)&quot;) + xlab(&quot;Tipo de comida&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) Luego podemos tener una descripción de los datos. test &lt;- by(dat1.long$vomito, dat1.long$animal, stat.desc, basic = FALSE, norm = TRUE) lapply(test,round,2) ## $insecto.al.palo ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 8.00 8.12 0.79 1.87 4.98 2.23 0.27 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.27 0.18 -1.21 -0.41 0.98 0.97 ## ## $testiculo.de.canguro ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 4.50 4.25 0.65 1.53 3.36 1.83 0.43 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.05 0.03 -1.66 -0.56 0.94 0.60 ## ## $ojos.de.pescado ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 4.00 4.12 0.97 2.30 7.55 2.75 0.67 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.10 0.07 -1.86 -0.63 0.91 0.37 ## ## $larvas.de.polillas ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 6.50 5.75 1.03 2.44 8.50 2.92 0.51 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## -0.51 -0.34 -1.49 -0.50 0.90 0.29 Finalmente, hacemos el análisis de ANOVA de medidas repetidas. model &lt;- ezANOVA(data = dat1.long, dv = .(vomito), wid = .(participante), within = .(animal), type = 3, detailed = TRUE) ## Warning: Converting &quot;participante&quot; to factor for ANOVA. model ## $ANOVA ## Effect DFn DFd SSn SSd F p p&lt;.05 ges ## 1 (Intercept) 1 7 990.125 17.375 398.899281 1.973536e-07 * 0.8529127 ## 2 animal 3 21 83.125 153.375 3.793806 2.557030e-02 * 0.3274249 ## ## $`Mauchly&#39;s Test for Sphericity` ## Effect W p p&lt;.05 ## 2 animal 0.136248 0.04684581 * ## ## $`Sphericity Corrections` ## Effect GGe p[GG] p[GG]&lt;.05 HFe p[HF] p[HF]&lt;.05 ## 2 animal 0.5328456 0.06258412 0.6657636 0.04833061 * ¿Qué observamos? El modelo sugiere que hay un efecto del tipo de animal sobre el número de vómitos. Sin embargo, el test de Mauchly nos dice que no se cumple el supuesto de esfericidad. Por lo tanto debemos mirar las correcciones (Greenhouse-Geisser [GG] o Huynd-Feldt [HF]). Luego del análisis de ANOVA podemos evaluar que comparaciones son significativamente diferentes. pairwise.t.test(dat1.long$vomito, dat1.long$animal, paired = TRUE, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using paired t tests ## ## data: dat1.long$vomito and dat1.long$animal ## ## insecto.al.palo testiculo.de.canguro ojos.de.pescado ## testiculo.de.canguro 0.0121 - - ## ojos.de.pescado 0.0056 1.0000 - ## larvas.de.polillas 1.0000 1.0000 1.0000 ## ## P value adjustment method: bonferroni Finalmente, también puedes notar que el modelo de ANOVA también describe el tamaño del efecto en forma de ges (generalized eta squared). 10.4 ANCOVA Ahora vamos a hacer un análisis un ANCOVA. Imagina que estuvimos estudiando el efecto de una droga sobre los niveles de inteligencia de unos individuos (revisa el capítulo sobre ANOVA). setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(ggplot2) library(Hmisc) library(Rmisc) library(effsize) library(pastecs) library(reshape2) library(car) library(effsize) library(effects) library(multcomp) dat1 &lt;- read.csv(&quot;data/inteligencia.csv&quot;, header = TRUE) dat1$Dosis &lt;- factor(dat1$Dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Baja&quot;, &quot;Alta&quot;)) dat1 ## Dosis Inteligencia ## 1 Placebo 3 ## 2 Placebo 2 ## 3 Placebo 1 ## 4 Placebo 1 ## 5 Placebo 4 ## 6 Baja 5 ## 7 Baja 2 ## 8 Baja 4 ## 9 Baja 2 ## 10 Baja 3 ## 11 Alta 7 ## 12 Alta 4 ## 13 Alta 5 ## 14 Alta 3 ## 15 Alta 6 # Podemos usar esta función para calcular los estadísticos a través de los participantes. datac &lt;- summarySE(dat1, measurevar=&quot;Inteligencia&quot;, groupvars=&quot;Dosis&quot;) # Luego hacemos el gráfico ggplot(datac, aes(x=Dosis, y=Inteligencia, group=1)) + geom_errorbar(width=.1, aes(ymin=Inteligencia-se, ymax=Inteligencia+se)) + geom_line(colour = &quot;Red&quot;, linetype = &quot;dashed&quot;) + geom_point() + ylab(&quot;Niveles de inteligencia&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) Para el análisis de ANOVA observamos lo siguiente. m_AOV &lt;- aov(Inteligencia ~ Dosis, data = dat1) summary(m_AOV) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dosis 2 20.13 10.067 5.119 0.0247 * ## Residuals 12 23.60 1.967 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Según este análisis la droga tiene un efecto en los niveles de inteligencia. Pero ¿qué pasa si tomamos en cuenta otros factores? Por ejemplo, qué pasa si tomamos en cuenta la edad de los participantes o los niveles de inteligencia de sus padres? Las variables continuas que no son parte de una manipulación experimental pero que tienen una influencia en la variable dependiente, se conocen como co-variables y se pueden incluir en un análisis de ANOVA. Cuándo medimos las co-variables y las incluimos en un análisis de varianza lo llamamos análisis de covarianza (o ANCOVA). En el siguiente ejemplo vamos a analizar el efecto de la droga sobre los niveles de inteligencia considerando además los niveles de inteligencia de uno de sus progenitores. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). # dat2 &lt;- read.csv(&quot;data/inteligencia_y_covariable.csv&quot;, header = TRUE) dat2$dosis &lt;- factor(dat2$dosis, levels = c(1:3), labels = c(&quot;Placebo&quot;, &quot;Low Dose&quot;, &quot;High Dose&quot;)) Luego, pasamos los datos a formato long. restructuredData &lt;- melt(dat2, id = c(&quot;dosis&quot;), measured = c(&quot;inteligencia&quot;, &quot;herencia&quot;)) colnames(restructuredData) &lt;- c(&quot;dosis&quot;, &quot;aspecto&quot;, &quot;valor&quot;) Luego, podemos hacer algunos gráficos. Por ejemplo, podemos visualizar los niveles de inteligencia en función de la dosis de droga. Al mismo podemos ver como que diferencias hay los niveles de inteligencia heredados. ggplot(restructuredData, aes(dosis, valor)) + geom_boxplot() + facet_wrap(~aspecto) + labs(x=&quot;Dosis&quot;, y =&quot;Inteligencia&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) Podemos observar cómo cambian los niveles de inteligencia individual en función de los niveles de inteligencia de los progenitores. Y podemos ver como cambia estos para los distintos niveles de droga. ggplot(dat2, aes(herencia, inteligencia, colour = dosis)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x=&quot;Inteligencia heredada&quot;, y =&quot;Inteligencia evocada por la droga&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) ## `geom_smooth()` using formula &#39;y ~ x&#39; En seguida podemos hacer una descripción de los datos. as.data.frame(lapply(by(dat2$inteligencia, dat2$dosis, stat.desc, basic = FALSE, norm = TRUE), round, 2)) ## Placebo Low.Dose High.Dose ## median 2.00 4.50 4.00 ## mean 3.22 4.88 4.85 ## SE.mean 0.60 0.52 0.59 ## CI.mean.0.95 1.37 1.22 1.28 ## var 3.19 2.12 4.47 ## std.dev 1.79 1.46 2.12 ## coef.var 0.55 0.30 0.44 ## skewness 0.99 0.43 0.43 ## skew.2SE 0.69 0.28 0.35 ## kurtosis -0.55 -1.48 -0.90 ## kurt.2SE -0.20 -0.50 -0.38 ## normtest.W 0.76 0.87 0.93 ## normtest.p 0.01 0.16 0.39 as.data.frame(lapply(by(dat2$herencia, dat2$dosis, stat.desc, basic = FALSE, norm = TRUE), round, 2)) ## Placebo Low.Dose High.Dose ## median 4.00 2.50 2.00 ## mean 3.44 3.12 2.00 ## SE.mean 0.69 0.61 0.45 ## CI.mean.0.95 1.59 1.44 0.99 ## var 4.28 2.98 2.67 ## std.dev 2.07 1.73 1.63 ## coef.var 0.60 0.55 0.82 ## skewness 0.22 0.42 0.21 ## skew.2SE 0.15 0.28 0.17 ## kurtosis -1.47 -1.50 -1.36 ## kurt.2SE -0.53 -0.51 -0.57 ## normtest.W 0.92 0.92 0.91 ## normtest.p 0.40 0.42 0.20 Podemos ver el gran promedio de inteligencia evocada por la droga (a travaés de todas las dosis). as.data.frame(lapply(stat.desc(dat2$inteligencia, basic = FALSE), round, 2)) ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 1 4 4.37 0.36 0.73 3.83 1.96 0.45 Podemos ver el gran promedio de inteligencia heredada (a travaés de todas las dosis). as.data.frame(lapply(stat.desc(dat2$herencia, basic = FALSE), round, 2)) ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 1 2.5 2.73 0.34 0.69 3.44 1.86 0.68 Luego podemos evaluar la homogeneidad de la varianza. leveneTest(dat2$inteligencia, dat2$dosis, center = median) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.3256 0.7249 ## 27 Dentro de los supuestos del ANCOVA debemos probar que nuestra variable independiente y la co-variable producen efectos independientes. Es decir, debemos probar que la co-variable no es afectada por la variable independiente. checkIndependenceModel &lt;- aov(herencia ~ dosis, data = dat2) summary(checkIndependenceModel) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dosis 2 12.77 6.385 1.979 0.158 ## Residuals 27 87.10 3.226 summary.lm(checkIndependenceModel) ## ## Call: ## aov(formula = herencia ~ dosis, data = dat2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.4444 -1.3646 -0.0625 1.0000 3.5556 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.4444 0.5987 5.753 4.06e-06 *** ## dosisLow Dose -0.3194 0.8727 -0.366 0.7172 ## dosisHigh Dose -1.4444 0.7788 -1.855 0.0746 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.796 on 27 degrees of freedom ## Multiple R-squared: 0.1279, Adjusted R-squared: 0.06326 ## F-statistic: 1.979 on 2 and 27 DF, p-value: 0.1577 La inteligencia heredada fue aproximadamente equivalente a través de las tres condiciones de drogas (placebo, dosis baja y alta). Este resultado nos permite decir que es apropiado utilizar la inteligencia heredada como co-variable en el análisis de ANCOVA. El ANCOVA se realiza como cualquier modelo lineal. Es necesario mencionar que cuando hacemos un modelo, R calcula usa una suma de cuadrados de Tipo I (o sumas secuenciales de cuadrados) por defecto. Esto significa que cualquier predictor ingresado en el modelo se evalúa después de los predictores anteriores en el modelo. Típicamente en los modelos tradicionales se usa una suma de cuadrados de tipo III, dónde los efectos de los predictores se evalúan después que se toman en cuenta todos los otros predictores. Para hacer esto creamos el modelo y luego usamos la función Anova e indicamos que queremos usar la suma de cuadrados de tipo III. ANCOVA_model &lt;- aov(inteligencia ~ herencia + dosis, dat2) Anova(ANCOVA_model, type=&quot;III&quot;) ## Anova Table (Type III tests) ## ## Response: inteligencia ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 12.943 1 4.2572 0.04920 * ## herencia 15.076 1 4.9587 0.03483 * ## dosis 25.185 2 4.1419 0.02745 * ## Residuals 79.047 26 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ¿Cómo se interpretan estos resultados? Lo primero que vemos es que los niveles de inteligencia individuales son modulados por los niveles de inteligencia de los progenitores. Más interesante aún es el segundo resultado, que indica que los niveles de inteligencia son modulados por la dosis de droga, incluso cuando los efectos de los niveles de inteligencia heredados son controlados. En suma, si hubieramos hecho sólo el ANOVA hubieramos observado lo siguiente: anovaModel &lt;- aov(inteligencia ~ dosis, dat2) summary(anovaModel) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dosis 2 16.84 8.422 2.416 0.108 ## Residuals 27 94.12 3.486 Pero, evaluando los niveles de inteligencia controlando por los niveles de inteligencia heredada llegamos a una conclusión distinta. En el modelo de ANCOVA queda por mirar los gráficos. plot(ANCOVA_model) ¿Qué vemos? El primer gráfico se puede usar para evaluar la homogeneidad de la varianza: si tiene forma de embudo, entonces estamos en problemas. En nuestro caso vemos que la dispersión de puntajes es más amplia en algunos puntos que en otros. Esto implica que los residuales pueden estar distribuidos de forma heteroscedástica. El segundo gráfico es un gráfico Q-Q que nos informa sobre la normalidad de los residuos en el modelo. Queremos que nuestros residuos se distribuyan normalmente, lo que significa que los puntos en el gráfico deben flotar alrededor de la línea diagonal. En nuestro los puntos se alejan de esta tendencia. Nuevamente, esta no es una buena noticia para el modelo. Estos gráficos sugieren que sería necesario realizar una versión robusta de ANCOVA. A pesar de los problemas que hayamos detectado, y con el objetivo de hacer un análisis completo del análisis de ANCOVA veremos otros aspectos importantes. Otro de los supuestos del ANCOVA que debemos probar es que existe una homogeneidad de las pendientes de regresión. Este supuesto significa que la relación entre la co-variable y la variable resultado (en este caso, inteligencia e inteligencia heredada) debe ser similar en diferentes niveles de la variable predictora (en este caso, en los tres grupos de dosis). Para probar esto, necesitamos ejecutar de nuevo un ANCOVA pero incluyendo la interacción entre la co-variable y la variable predictora. hoRS &lt;- aov(inteligencia ~ herencia*dosis, dat2) Anova(hoRS, type = &quot;III&quot;) ## Anova Table (Type III tests) ## ## Response: inteligencia ## Sum Sq Df F value Pr(&gt;F) ## (Intercept) 0.771 1 0.3157 0.579405 ## herencia 19.922 1 8.1565 0.008715 ** ## dosis 36.558 2 7.4836 0.002980 ** ## herencia:dosis 20.427 2 4.1815 0.027667 * ## Residuals 58.621 24 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Los efectos de la dosis de droga y la inteligencia heredada siguen siendo significativos, pero lo principal que nos interesa es la interacción. Un valor significativo en esta interacción sugiere que no cumple el supuesto de homogeneidad de las pendientes de regresión. Para los contrastes planificados podemos hacer algo similar a lo que hemos hecho antes. .plac_vs_drug &lt;- c(-2, 1, 1) .high_vs_low &lt;- c(0, -1, 1) contrasts(dat2$dosis) &lt;- cbind(.plac_vs_drug, .high_vs_low) Una vez que definimos los contrastes los podemos inyectar en la base de datos y luego realizamos el modelo nuevamente. ANCOVA_model &lt;- aov(inteligencia ~ dosis + herencia, dat2) ¿Cómo se interpretan estos resultados? Antes de mirar las comparaciones planificadas es buena idea calcular los promedios ajustados. En este caso en particular queremos saber los promedios de inteligencia en función de las dosis de droga ajustados por los niveles de inteligencia heredados. Para ello usamos la función effect. También podemos acceder a los SE de estos promedios. adjustedMeans &lt;- effect(&quot;dosis&quot;, ANCOVA_model, se=TRUE) summary(adjustedMeans) ## ## dosis effect ## dosis ## Placebo Low Dose High Dose ## 2.926370 4.712050 5.151251 ## ## Lower 95 Percent Confidence Limits ## dosis ## Placebo Low Dose High Dose ## 1.700854 3.435984 4.118076 ## ## Upper 95 Percent Confidence Limits ## dosis ## Placebo Low Dose High Dose ## 4.151886 5.988117 6.184427 adjustedMeans$se ## [1] 0.5962045 0.6207971 0.5026323 A diferencia de los promedios originales, cuando se ajustan los promedios se observa que los promedios de inteligencia para dosis alta y baja son bastante diferentes. Es decir, cuando se ajuste por los efectos de la inteligencia de los progenitores, a medida que aumenta la dosis de droga aumentan los niveles de inteligencia de los individuos. Veamos los contrastes planificados. summary.lm(ANCOVA_model) ## ## Call: ## aov(formula = inteligencia ~ dosis + herencia, data = dat2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.2622 -0.7899 -0.3230 0.8811 4.5699 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.1260 0.6250 5.002 3.34e-05 *** ## dosis.plac_vs_drug 0.6684 0.2400 2.785 0.00985 ** ## dosis.high_vs_low 0.2196 0.4056 0.541 0.59284 ## herencia 0.4160 0.1868 2.227 0.03483 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.744 on 26 degrees of freedom ## Multiple R-squared: 0.2876, Adjusted R-squared: 0.2055 ## F-statistic: 3.5 on 3 and 26 DF, p-value: 0.02954 En estos contrastes comparamos el efecto de la droga relativo al placebo (contraste 1) y el efecto de la dosis alta versus la dosis baja (contraste 2). Pero, además estos contrates están ajustados por los niveles de inteligencia heredados. ¿Qué vemos? Primero, que hay un efecto de la droga por sobre el placebo. Segundo. No parece haber una efecto de la dosis alta por sobre la dosis baja. El modelo además nos dice que hay una relación entre los niveles de inteligencia producidos por la droga y los niveles de inteligencia heredados. El beta es ~0.42. Asumiendo los otros factores en igualdad de condiciones, si la inteligencia del progenitor de un individuo aumenta en una 1 unidad, la inteligencia del individuo aumenta en alredor de la mitad. Esto los podemos ver en el siguiente gráfico. ggplot(dat2, aes(herencia, inteligencia)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x=&quot;Inteligencia heredada&quot;, y =&quot;Inteligencia evocada&quot;) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) ## `geom_smooth()` using formula &#39;y ~ x&#39; Por último, también podemos hacer pruebas posthoc. Para hacer estos análisis en los promedios ajustados debemos usar la función glht. postHocs &lt;- glht(ANCOVA_model, linfct = mcp(dosis = &quot;Tukey&quot;)) summary(postHocs) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = inteligencia ~ dosis + herencia, data = dat2) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## Low Dose - Placebo == 0 1.7857 0.8494 2.102 0.1087 ## High Dose - Placebo == 0 2.2249 0.8028 2.771 0.0265 * ## High Dose - Low Dose == 0 0.4392 0.8112 0.541 0.8517 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) confint(postHocs) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = inteligencia ~ dosis + herencia, data = dat2) ## ## Quantile = 2.4855 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## Low Dose - Placebo == 0 1.7857 -0.3254 3.8967 ## High Dose - Placebo == 0 2.2249 0.2295 4.2202 ## High Dose - Low Dose == 0 0.4392 -1.5770 2.4555 De este análisis observamos que sólo hay diferencias de inteligencia (cuando controlamos por los efecto de inteligencia heredada) cuando comparamos el placebo y la dosis alta de droga. 10.5 MANOVA Ahora vamos a hacer un análisis de MANOVA. El análisis de MANOVA se realizar porque el ANOVA lidia más que nada con una variable dependiente. Pero, ¿qué pasa cuando realizamos muchas mediciones? En el siguiente estudio se aplicaron distintos tratamientos para enfrentar cierto tipo de problemas psicopatológicos. Había un grupo control (NT), y grupos a que se le aplicaron terapia condutual (BT) o terapia cognitivo-conductual (CBT). Además, de estos grupos (que reflejan las variables independientes), se midió la frecuencia de dos cosas: conductas y pensamientos. Para empezar carguemos las librerías. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) library(car) library(ggplot2) library(mvnormtest) #library(mvoutlier) library(pastecs) library(reshape) #library(WRS) Carguemos los datos. ocdData &lt;- read.csv(&quot;data/OCD.csv&quot;, header = TRUE) ocdData$Grupo &lt;- factor(ocdData$Grupo, levels = c(&quot;CBT&quot;, &quot;BT&quot;, &quot;No Treatment Control&quot;), labels = c(&quot;CBT&quot;, &quot;BT&quot;, &quot;NT&quot;)) Re-ordenemos los niveles dentro del factor de grupo para que en el gráfico aparezca el grupo control en primer lugar. ocdData$Grupo &lt;- factor(ocdData$Grupo, levels(ocdData$Grupo)[c(3,1,2)]) Luego transformemos los datos a formato Long-. ocdMelt &lt;- melt(ocdData, id = c(&quot;Grupo&quot;), measured = c(&quot;Acciones&quot;, &quot;Pensamientos&quot;)) names(ocdMelt) &lt;- c(&quot;Grupo&quot;, &quot;Medicion&quot;, &quot;Frecuencia&quot;) Hagamos un gráfico de dispersión. ocdScatter &lt;- ggplot(ocdData, aes(Acciones, Pensamientos)) ocdScatter + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Conductas obsesivas&quot;, y = &quot;Pensamientos obsesivos&quot;) + facet_wrap(~Grupo, ncol = 3) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) ## `geom_smooth()` using formula &#39;y ~ x&#39; Hagamos un gráfico de barras. ocdBar &lt;- ggplot(ocdMelt, aes(Grupo, Frecuencia, fill = Medicion)) ocdBar + stat_summary(fun.data = mean_cl_boot, geom = &quot;errorbar&quot;, position = position_dodge(width=0.90), width = 0.2) + stat_summary(fun.y = mean, geom = &quot;bar&quot;, position = &quot;dodge&quot;) + labs(x = &quot;Grupo&quot;, y = &quot;Frencuencia&quot;, fill = &quot;Medición&quot;) + scale_y_continuous(breaks = seq(0, 20, by = 2)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) ## Warning: `fun.y` is deprecated. Use `fun` instead. Hagamos un histograma. ocdBoxplot &lt;- ggplot(ocdMelt, aes(Grupo, Frecuencia, colour = Medicion)) ocdBoxplot + geom_boxplot() + labs(x = &quot;Grupo&quot;, y = &quot;Frecuencia&quot;, colour = &quot;Medición&quot;) + scale_y_continuous(breaks = seq(0, 20, by = 2)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) Luego podemos hacer una descripción de los datos. descrip &lt;- by(ocdData$Acciones, ocdData$Grupo, stat.desc, basic = FALSE, norm = TRUE) lapply(descrip,round,2) ## $NT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 5.00 5.00 0.33 0.75 1.11 1.05 0.21 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.51 0.37 -1.22 -0.46 0.86 0.07 ## ## $CBT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 5.00 4.90 0.38 0.86 1.43 1.20 0.24 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.17 0.12 -1.18 -0.44 0.95 0.69 ## ## $BT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 4.00 3.70 0.56 1.26 3.12 1.77 0.48 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## -0.46 -0.34 -1.45 -0.54 0.87 0.11 descrip &lt;- by(ocdData$Pensamientos, ocdData$Grupo, stat.desc, basic = FALSE, norm = TRUE) lapply(descrip,round,2) ## $NT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 14.00 15.00 0.75 1.69 5.56 2.36 0.16 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.96 0.70 -0.54 -0.20 0.83 0.03 ## ## $CBT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 13.50 13.40 0.60 1.36 3.60 1.90 0.14 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.09 0.07 -1.67 -0.63 0.91 0.31 ## ## $BT ## median mean SE.mean CI.mean.0.95 var std.dev coef.var ## 14.50 15.20 0.66 1.50 4.40 2.10 0.14 ## skewness skew.2SE kurtosis kurt.2SE normtest.W normtest.p ## 0.61 0.44 -1.28 -0.48 0.88 0.12 Luego de describir los datos podemos comprobar algunos supuestos antes de hacer el análisis de MANOVA. Primero debemos chequear la homogeneidad de las matrices de covarianza, comparando los valores que encontremos. Idealmente deberían ser similares a través de los grupos. by(ocdData[, 2:3], ocdData$Grupo , cov) ## ocdData$Grupo: NT ## Acciones Pensamientos ## Acciones 1.111111 -1.111111 ## Pensamientos -1.111111 5.555556 ## -------------------------------------------------------------------------- ## ocdData$Grupo: CBT ## Acciones Pensamientos ## Acciones 1.43333333 0.04444444 ## Pensamientos 0.04444444 3.60000000 ## -------------------------------------------------------------------------- ## ocdData$Grupo: BT ## Acciones Pensamientos ## Acciones 3.122222 2.511111 ## Pensamientos 2.511111 4.400000 En este caso se encuentran diferencias, pero ya que los grupos tienen un n similar no es algo de lo que tengamos que preocuparnos. Luego tenemos que testear la normalidad multivariada. Para ello necesitamos aplicar una prueba de normalidada los grupos individuales, y transponer los datos para que estén en un formato adecuado. nt &lt;- t(ocdData[21:30, 2:3]) cbt &lt;- t(ocdData[1:10, 2:3]) bt &lt;- t(ocdData[11:20, 2:3]) mshapiro.test(nt) ## ## Shapiro-Wilk normality test ## ## data: Z ## W = 0.82605, p-value = 0.02998 mshapiro.test(cbt) ## ## Shapiro-Wilk normality test ## ## data: Z ## W = 0.9592, p-value = 0.7767 mshapiro.test(bt) ## ## Shapiro-Wilk normality test ## ## data: Z ## W = 0.89122, p-value = 0.175 El análisis sugiere que podrían haber problemas de normalidad en el grupo control. Por ahora lo vamos a ignorar. Pero mirando los datos se puede detectar un outlier. Y eliminando este outlier se puede realizar el análisis de normalidad para revisar si haciendo esto se corrige el problema de normalidad. Antes de hacer el análisis principal podemos setear nuestros contrastes de interés. .NT_vs_CBT &lt;- c(1, 0, 0) .NT_vs_BT &lt;- c(0, 1, 0) contrasts(ocdData$Grupo) &lt;- cbind(.NT_vs_CBT, .NT_vs_BT) Luego para definir la variable dependiente creamos un vector con las dos mediciones. Luego se realiza el modelo de la misma forma como se define en una regresión simple. Finalmente revisamos el resultados del modelo. outcome &lt;- cbind(ocdData$Acciones, ocdData$Pensamientos) ocdModel &lt;- manova(outcome ~ Grupo, data = ocdData) summary(ocdModel, intercept = TRUE) ## Df Pillai approx F num Df den Df Pr(&gt;F) ## (Intercept) 1 0.98285 745.23 2 26 &lt; 2e-16 *** ## Grupo 2 0.31845 2.56 4 54 0.04904 * ## Residuals 27 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Hay cuatro pruebas estadísticas que se pueden usar en MANOVA (traza de Pillai, lambda de Wilks, traza de Hotelling y prueba de raíz más grande de Roy). La prueba usada mas común es la traza de Pillai. Pero otras pruebas se pueden usar para condiciones particulares. Otros análisis se pueden hacer de la siguiente manera: summary(ocdModel, intercept = TRUE, test = &quot;Wilks&quot;) ## Df Wilks approx F num Df den Df Pr(&gt;F) ## (Intercept) 1 0.01715 745.23 2 26 &lt; 2e-16 *** ## Grupo 2 0.69851 2.55 4 52 0.04966 * ## Residuals 27 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(ocdModel, intercept = TRUE, test = &quot;Hotelling&quot;) ## Df Hotelling-Lawley approx F num Df den Df Pr(&gt;F) ## (Intercept) 1 57.325 745.23 2 26 &lt;2e-16 *** ## Grupo 2 0.407 2.55 4 50 0.0508 . ## Residuals 27 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(ocdModel, intercept = TRUE, test = &quot;Roy&quot;) ## Df Roy approx F num Df den Df Pr(&gt;F) ## (Intercept) 1 57.325 745.23 2 26 &lt; 2e-16 *** ## Grupo 2 0.335 4.52 2 27 0.02027 * ## Residuals 27 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Finalmente luego de este análisis se pueden hacer análisis tipo ANOVA. Se puede aplicar # Recuerda: outcome &lt;- cbind(ocdData$Acciones, ocdData$Pensamientos) summary.aov(ocdModel) ## Response 1 : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Grupo 2 10.467 5.2333 2.7706 0.08046 . ## Residuals 27 51.000 1.8889 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Response 2 : ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Grupo 2 19.467 9.7333 2.1541 0.1355 ## Residuals 27 122.000 4.5185 Para los análisis de ANOVA observamos que no existen diferencias significativas entre los distintos tipos de terapia. Sólo con el fin de completar los análisis vamos a revisar las comparaciones planificadas. Pero no podemos intepretar estos resultados. Se pueden analizar los cambios en la frecuencia de acciones en función de los tratamientos. actionModel &lt;- lm(Acciones ~ Grupo, data = ocdData) summary.lm(actionModel) ## ## Call: ## lm(formula = Acciones ~ Grupo, data = ocdData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.700 -0.975 0.100 1.075 2.300 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.7000 0.4346 8.513 3.98e-09 *** ## Grupo.NT_vs_CBT 1.3000 0.6146 2.115 0.0438 * ## Grupo.NT_vs_BT 1.2000 0.6146 1.952 0.0613 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.374 on 27 degrees of freedom ## Multiple R-squared: 0.1703, Adjusted R-squared: 0.1088 ## F-statistic: 2.771 on 2 and 27 DF, p-value: 0.08046 Se pueden analizar los cambios en la frecuencia de pensamientos en función de los tratamientos. thoughtsModel &lt;- lm(Pensamientos ~ Grupo, data = ocdData) summary.lm(thoughtsModel) ## ## Call: ## lm(formula = Pensamientos ~ Grupo, data = ocdData) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.40 -1.40 -0.70 1.45 5.00 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 15.2000 0.6722 22.612 &lt;2e-16 *** ## Grupo.NT_vs_CBT -0.2000 0.9506 -0.210 0.8349 ## Grupo.NT_vs_BT -1.8000 0.9506 -1.893 0.0691 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.126 on 27 degrees of freedom ## Multiple R-squared: 0.1376, Adjusted R-squared: 0.07372 ## F-statistic: 2.154 on 2 and 27 DF, p-value: 0.1355 "],["otros-análisis.html", "Capítulo 11 Otros análisis 11.1 Análisis de proporciones", " Capítulo 11 Otros análisis En este capítulo vamos a revisar otros análisis estadísticos. 11.1 Análisis de proporciones Imagina que estás analizando una base de datos dónde los participantes tenían que elegir entre dos tipos de chocolates. Primero seteamos nuestro directorio de trabajo y graficar los datos. Cargamos la librería ggplot2 y otras librerías que nos serviran. Si no tienes estas librerías debes instalarlas. Luego importamos nuestro set de datos y lo miramos. setwd(&quot;C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica&quot;) prefsAB &lt;- read.csv(&quot;data/prefsAB.csv&quot;) prefsAB$Participante &lt;- factor(prefsAB$Participante) # convertimos Participante a factor prefsAB$Preferencia &lt;- factor(prefsAB$Preferencia) # convertimos Preferencia a factor head(prefsAB) ## Participante Preferencia ## 1 1 Sahne-Nuss ## 2 2 Sahne-Nuss ## 3 3 Sahne-Nuss ## 4 4 Sahne-Nuss ## 5 5 Sahne-Nuss ## 6 6 Sahne-Nuss Luego realizamos un gráfico para visualizar diferencias en las preferencias. library(ggplot2) ggplot(prefsAB, aes(Preferencia, ..count..)) + geom_bar(aes(fill = Preferencia), position = &quot;dodge&quot;) + ylab(&quot;Número de personas&quot;) Podemos usar la función xtabs para obtener una tabla de contigencia. Luego con la función chisq.test cálculamos la probabilidad que estas dos preferencias esten igualmente distribuidas (una prueba clásica de chi cuadrado). (tabla.contingencia &lt;- xtabs( ~ Preferencia, prefsAB)) ## Preferencia ## Sahne-Nuss Trencito ## 46 14 chisq.test(tabla.contingencia) ## ## Chi-squared test for given probabilities ## ## data: tabla.contingencia ## X-squared = 17.067, df = 1, p-value = 3.609e-05 Otro test parecido, pero mas exacto es un test binomial. binom.test(tabla.contingencia) ## ## Exact binomial test ## ## data: tabla.contingencia ## number of successes = 46, number of trials = 60, p-value = 4.224e-05 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.6396172 0.8661627 ## sample estimates: ## probability of success ## 0.7666667 Ahora imagina que estás analizando una base de datos dónde los participantes tenían que elegir entre 3 tipos de chocolates. Nuevamente, importamos primero nuestro set de datos. prefsABC &lt;- read.csv(&quot;data/prefsABC.csv&quot;) prefsABC$Participante &lt;- factor(prefsABC$Participante) # convertimos Participante a factor prefsABC$Preferencia &lt;- factor(prefsABC$Preferencia) # convertimos Preferencia a factor head(prefsABC) ## Participante Preferencia ## 1 1 Golden-Nuss ## 2 2 Golden-Nuss ## 3 3 Sahne-Nuss ## 4 4 Golden-Nuss ## 5 5 Golden-Nuss ## 6 6 Sahne-Nuss Realizamos el gráfico para visualizar diferencias en las preferencias. library(ggplot2) ggplot(prefsABC, aes(Preferencia, ..count..)) + geom_bar(aes(fill = Preferencia), position = &quot;dodge&quot;) + ylab(&quot;Número de personas&quot;) Podemos usar la función xtabs para obtener una tabla de contigencia. Luego con la función chisq.test cálculamos la probabilidad que estas dos preferencias esten igualmente distribuidas (una prueba clásica de chi cuadrado). (tabla.contingencia &lt;- xtabs( ~ Preferencia, prefsABC)) ## Preferencia ## Golden-Nuss Sahne-Nuss Trencito ## 31 21 8 chisq.test(tabla.contingencia) ## ## Chi-squared test for given probabilities ## ## data: tabla.contingencia ## X-squared = 13.3, df = 2, p-value = 0.001294 Otro test parecido, pero mas exacto es un test multinomial. library(XNomial) xmulti(tabla.contingencia, c(1/3, 1/3, 1/3), statName = &quot;Prob&quot;) ## ## P value (Prob) = 0.0008024 Luego que pesquisamos diferencias generales podemos hacer comparaciones más específicas entre pares de elementos. Podemos usar la función p.adjust para ajustar el valor de p para tener en cuenta el problema de comparaciones múltiples. PrefA &lt;- binom.test(sum(prefsABC$Preferencia == &quot;Trencito&quot;), nrow(prefsABC), p=1/3) PrefB &lt;- binom.test(sum(prefsABC$Preferencia == &quot;Sahne-Nuss&quot;), nrow(prefsABC), p=1/3) PrefC &lt;- binom.test(sum(prefsABC$Preferencia == &quot;Golden-Nuss&quot;), nrow(prefsABC), p=1/3) p.adjust(c(PrefA$p.value, PrefB$p.value, PrefC$p.value), method=&quot;holm&quot;) ## [1] 0.001659954 0.785201685 0.007446980 En un siguiente nivel de complejidad imagina que ahora estás analizando una base de datos dónde los participantes tenían que elegir entre 2 tipos de chocolates, pero además se registró si era un hombre o una mujer. Nuevamente, importamos primero nuestro set de datos. prefsABsex &lt;- read.csv(&quot;data/prefsABsex.csv&quot;) prefsABsex$Participante &lt;- factor(prefsABsex$Participante) # convertimos a factor prefsABsex$Preferencia &lt;- factor(prefsABsex$Preferencia) # convertimos a factor prefsABsex$Genero &lt;- factor(prefsABsex$Genero) # convertimos a factor head(prefsABsex) ## Participante Preferencia Genero ## 1 1 Sahne-Nuss Femenino ## 2 2 Sahne-Nuss Femenino ## 3 3 Sahne-Nuss Femenino ## 4 4 Sahne-Nuss Masculino ## 5 5 Sahne-Nuss Femenino ## 6 6 Sahne-Nuss Masculino Realizamos el gráfico para visualizar diferencias en las preferencias. library(ggplot2) ggplot(prefsABsex, aes(Preferencia, ..count..)) + geom_bar(aes(fill = Preferencia), position = &quot;dodge&quot;) + facet_wrap( ~ Genero) + ylab(&quot;Número de personas&quot;) Podemos usar la función xtabs para obtener una tabla de contigencia. Luego con la función chisq.test cálculamos la probabilidad que estas dos preferencias en función del género esten igualmente distribuidas. (tabla.contingencia &lt;- xtabs( ~ Preferencia + Genero, prefsABsex)) ## Genero ## Preferencia Femenino Masculino ## Sahne-Nuss 29 17 ## Trencito 2 12 chisq.test(tabla.contingencia) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: tabla.contingencia ## X-squared = 8.3588, df = 1, p-value = 0.003838 Otro test parecido, pero mas exacto es un test de Fisher fisher.test(tabla.contingencia) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: tabla.contingencia ## p-value = 0.001877 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 1.862023 101.026914 ## sample estimates: ## odds ratio ## 9.844814 Finalmente, imagina que ahora estás analizando una base de datos dónde los participantes tenían que elegir entre 3 tipos de chocolates, pero además se registró si era un hombre o una mujer. Nuevamente, importamos primero nuestro set de datos. prefsABCsex &lt;- read.csv(&quot;data/prefsABCsex.csv&quot;) prefsABCsex$Participante &lt;- factor(prefsABCsex$Participante) # convertimos a factor prefsABCsex$Preferencia &lt;- factor(prefsABCsex$Preferencia) # convertimos a factor prefsABCsex$Genero &lt;- factor(prefsABCsex$Genero) # convertimos a factor head(prefsABCsex) ## Participante Preferencia Genero ## 1 1 Golden-Nuss Femenino ## 2 2 Golden-Nuss Masculino ## 3 3 Sahne-Nuss Masculino ## 4 4 Golden-Nuss Masculino ## 5 5 Golden-Nuss Masculino ## 6 6 Sahne-Nuss Femenino Realizamos el gráfico para visualizar diferencias en las preferencias. library(ggplot2) ggplot(prefsABCsex, aes(Preferencia, ..count..)) + geom_bar(aes(fill = Preferencia), position = &quot;dodge&quot;) + facet_wrap( ~ Genero) + ylab(&quot;Número de personas&quot;) Podemos usar la función xtabs para obtener una tabla de contigencia. Luego con la función chisq.test cálculamos la probabilidad que estas dos preferencias en función del género esten igualmente distribuidas. (tabla.contingencia &lt;- xtabs( ~ Preferencia + Genero, prefsABCsex)) ## Genero ## Preferencia Femenino Masculino ## Golden-Nuss 11 20 ## Sahne-Nuss 15 6 ## Trencito 3 5 chisq.test(tabla.contingencia) ## Warning in chisq.test(tabla.contingencia): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: tabla.contingencia ## X-squared = 6.9111, df = 2, p-value = 0.03157 Otro test parecido, pero mas exacto es un test de Fisher fisher.test(tabla.contingencia) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: tabla.contingencia ## p-value = 0.03261 ## alternative hypothesis: two.sided Luego que pesquisamos diferencias generales podemos hacer comparaciones más específicas entre pares de elementos. Primero, podemos hacer test binomiales sólo para los hombres. Hay diferencias significativas entre las preferencias de los hombres? male_A &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]$Preferencia == &quot;Trencito&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]), p=1/3) male_B &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]$Preferencia == &quot;Sahne-Nuss&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]), p=1/3) male_C &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]$Preferencia == &quot;Golden-Nuss&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Masculino&quot;,]), p=1/3) pvalues &lt;- p.adjust(c(male_A$p.value, male_B$p.value, male_C$p.value), method=&quot;holm&quot;) formatC(pvalues, format = &quot;f&quot;, digits = 6) ## [1] &quot;0.109474&quot; &quot;0.126622&quot; &quot;0.001297&quot; Segundo, podemos hacer test binomiales sólo para las mujeres. Hay diferencias significativas entre las preferencias de las mujeres? female_A &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]$Preferencia == &quot;Trencito&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]), p=1/3) female_B &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]$Preferencia == &quot;Sahne-Nuss&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]), p=1/3) female_C &lt;- binom.test(sum(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]$Preferencia == &quot;Golden-Nuss&quot;), nrow(prefsABCsex[prefsABCsex$Genero == &quot;Femenino&quot;,]), p=1/3) pvalues &lt;- p.adjust(c(female_A$p.value, female_B$p.value, female_C$p.value), method=&quot;holm&quot;) formatC(pvalues, format = &quot;f&quot;, digits = 6) ## [1] &quot;0.027033&quot; &quot;0.094478&quot; &quot;0.693970&quot; "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
