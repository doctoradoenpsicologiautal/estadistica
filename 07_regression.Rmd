# La regresión

En este capítulo vamos a revisar el elemento básico para hacer modelos estadísticos: la regresión lineal.

## Modelos estadísticos
Revisa este <a href="https://www.youtube.com/watch?v=DOIjIB1FGYY" target="_blank">video (17')</a> y trata de responder:

- ¿Qué es un modelo estadístico?
- ¿Por qué es importante tener buenos modelos?
- ¿Cómo de determina el error en un modelo?
- ¿Qué son los grados de libertad?

## La ecuación de la recta
Revisa este <a href="https://www.youtube.com/watch?v=In1vL_kZeYk" target="_blank">video (8')</a> y trata de responder:

- ¿Cómo se define la línea de la ecuación de un GLM que se ajuste mejor a los datos?
- ¿Cuál es el modelo más básico con el cual se compara un modelo que uno construya?

## La suma de cuadrados
Revisa este <a href="https://www.youtube.com/watch?v=maFx6TKuaQI" target="_blank">video (14')</a> y trata de responder:

- ¿Qué es la SS total?
- ¿Qué es la SS de los residuales?
- ¿Qué es la SS del modelo?
- ¿Cómo se establece que un modelo dado explica mejor los datos que un modelo básico?
- ¿Cómo se establece cuan bueno es un modelo comparado con cuan malo es? ¿Lo que explica y lo que no explica un modelo?

## La regresión con R

Ahora vamos a hacer un análisis básico de regresión. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas). Luego importamos el set de datos y le damos una mirada.

```{r}
setwd("C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica")

library(ggplot2)
library(car)
```

Imagina que eres manager de un grupo musical y debes definir como invertir parte de tu presupuesto. A lo que aspiras en el fondo esa aumentar la venta de discos. Para ellos pirmero debes evaluar que factores afectan la venta de discos. Uno de estos factores es la cantidad de dineo invertido en la publicidad. En ese sentido, te gustaría saber cuál es la relación entre el dinero invertido en publicidad y el número de discos vendidos.

```{r}
album1 <- read.csv("data/datos_ventas_de_discos_1.csv", header = TRUE) # load data
head(album1)
```

Primero graficamos.

```{r}
ggplot(album1,
       aes(publicidad, ventas)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x="Cantidad de dinero gastado en publicidad",
       y="Ventas")
```

Lo que nos dice el sentido común, y lo que vemos en el gráfico efectivamente es que a mayor dinero invertido en publicidad debería haber mayores ventas. Es este un buen modelo para predecir el número de ventas a partir del dinero invertido en publicidad? Para analizar estos podemos hacer un modelo lineal con la función **lm**. En esta función usamos la típica relación entre resultado (ouctome) y variable explicativa (predictor), y le indicamos a R que base de datos usamos (datos):
newModel <- lm(outcome~predictor, datos)
Luego podemos visualizar los resulatdos con la función **summary**.

```{r}
m_album <- lm(ventas ~ publicidad, data = album1)
summary(m_album)
```

En qué debemos fijarnos dentro de los resultados que obtenemos al aplicar un módelo líneal?
En la línea siguientes a "Call" aparece el módelo que usamos.
También aparecen los llamados coeficientes que reflejan bajo el nombre de "Estimate" que refleja con que magnitud una variable predictora predice una variable resultado. Por ejemplo, por cada unidad de publicidad invertida el aumento en el número de ventas es 0.09. Y esta relación es significativa, o sea es diferente de 0 (lo que ocurre cuando no hay ninguna relación entre ambas variables).


En el fondo este análisis nos dice que la publicidad si impacta sobre la venta de los discos.
Sin embargo, a publicidad no es el único que podría afectar las ventas. En este sentido, podríamos estudiar otros factores que afectan esta variable resultados. Para ello hacemos lo que se llama una regresión múltiple.

Primero cargamos los datos.
```{r}
album2 <- read.csv("data/datos_ventas_de_discos_2.csv", header = TRUE) # load data
head(album2)
```

Podemos graficar la relación entre alguna variable de interés y el número de ventas.
Por ejemplo, podríamos visualizar el impacto de la frecuencia de aparición de un tema musical en la radio.

```{r}
ggplot(album2,
       aes(publicidad, radio)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x="Número de apariciones en la radio",
       y="Ventas")
```

Luego podríamos hacer un modelo para entender el impacto de distintos factores en la venta de discos.

```{r}
m_album2 <- lm(ventas ~ publicidad + radio + eventos, data = album2)
summary(m_album2)
```

¿Qué conclusiones sacas de este análisis?

## La correlación con R

Ahora vamos a hacer un análisis de correlación. En la práctica es lo mismo que hacer una regresión, pero hay algunas funciones dedicadas más a las correlaciones.

Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas).

```{r}
setwd("C:/Users/Usuario/Documents/JoseLuis/UTalca_2018/Estadistica_Bookdown/estadistica")

library(Hmisc)
library(ggplot2)
library(boot)
library(ggm)
library(ggpubr)
library(ggcorrplot)
library(dplyr)
```

Luego importamos el set de datos y le damos una mirada.

```{r}
examData <- read.delim("data/ExamAnxiety.dat",  header = TRUE)
head(examData)
```

Recuerda siempre hacer un gráfico para ver los datos.
Por ejemplo, podríamos graficar los niveles de ansiedad versus los resultados en un exámen.

```{r}
scatter <- ggplot(examData, aes(Anxiety, Exam))
scatter + 
  geom_point() + geom_smooth(method = "lm", colour = "Red") +
  labs(x = "Niveles de ansiedad", y = "Desempeño en el examen (%)")
```

Para hacer una correlación podemos simplemente usar la función **cor** seleccionando nuestras colmunas de interés. Esta función nos devuelve los coeficientes de correlación. Por defecto se ejecuta una correlación de Pearson.

```{r}
cor(examData[, c("Exam", "Anxiety")])
```

Otra función que podemos usar  **rcorr**. Esta función nos devuelve los coeficientes de correlación. Fíjate que para usar esta función le decimos a R explícitamente que librería queremos usar, es decir, Hmisc.

```{r}
Hmisc::rcorr(as.matrix(examData[, c("Exam", "Anxiety")]))
```

Por último otra función que podemos usar  **cor.test**. Esta función nos devuelve Varias cosas: el valor de p y el coeficiente de correlación.

```{r}
cor.test(examData$Anxiety, examData$Exam)
```

También existen otras funciones que nos permiten hacer un gráfico que contenga

```{r}
ggscatter(examData, x = "Anxiety", y = "Exam",
               add = "reg.line", conf.int = TRUE,
               cor.coef = TRUE, cor.method = "spearman",
               xlab = "Niveles de ansiedad ", ylab = "Desempeño en el examen (%)") +
  theme(text = element_text(size=15))
```

El coeficiente de determinación es una medida que indica la varianza en una variable que es comparida por otra variable.  El coeficiente de determinación se puede calcular desde el coeficiente de correlación, elevándolo al cuadrado, y adicionalmente lo podemos multiplicar por 100 para leerlo como porcentaje.

```{r}
cor(examData[, c("Exam", "Anxiety")])^2 * 100
```


```{r}
corr_selected <- examData %>% 
  select(Revise, Exam, Anxiety) %>% 
  cor(use = "pairwise") %>%
  round(1)

ggcorrplot(corr_selected, type = "lower", lab = TRUE, show.legend = TRUE)
```

Un paso mas allá de las correlaciones bivariadas (entre dos variables) son las correlaciones parciales. La correlación nos permiten investigar la asociación entre dos variables, tomando en cuenta una tercera variable. Es decir, estudiamos una correlación entre dos variables controlando por el efecto de una tercera variable.

Para trabajar esto en R primero vamos a seleccionar algunas columnas de interés.

```{r}
examData2 <- examData[, c("Exam", "Anxiety", "Revise")]
```

Luego aplicamos la función **pcor**. En esta función las primeras dos variables son las que queremos estudiar, y en tercer lugar la variables por la que queremos controlar. En el siguiente ejemplo queremos estudiar la relación entre el desempeño en una examen y los niveles de ansiedad, controlando por el tiempo que pasaron los estudiantes haciendo revisión antes del examen.

```{r}
(pc <- pcor(c("Exam", "Anxiety", "Revise"), var(examData2)))
```

Nuevamente podemos calcular el coeficiente de determinación

```{r}
pc^2 * 100
```

Para obtener mas información podemos usar la función **pcor.test** a la que le inyectamos el objeto que recién creamos. Al usar la función primero hay que decirle cuál es la variable dónde esta los datos (pc en nuestro caso), luego cuantas variables controles hay (1 en nuestro caso) y finalmente cuál es el tamaño de la muestra (103 en nuestro caso).

```{r}
pcor.test(pc, 1, 103)
```

De esta manera sabemos el valor de p para la prueba de asociación entre dos variables, controlando por el efecto de una tercera variable.
