# Más allá del ANOVA

En este capítulo vamos a revisar que otros tipos de ANOVA podemos realizar.

## Tipos de ANOVA
Revisa este <a href="https://www.youtube.com/watch?v=ha_fahDpbSg" target="_blank">video (13')</a> y trata de responder:

- ¿De qué depende el tipo de ANOVA que utilicemos?

## ANOVA factorial

Ahora vamos a hacer un análisis de ANOVA factorial. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas).

```{r}
setwd(Sys.getenv("BOOKDOWN_PROJECT_PATH"))

library(ggplot2)
library(Hmisc)
library(Rmisc)
library(effsize)
library(pastecs)
library(reshape2)
library(car)
library(effsize)
```

Primero importamos el set de datos y le damos una mirada.

```{r}
gogglesData <- read.csv("data/goggle_beer_effect.csv", header = TRUE)
head(gogglesData)
```

Enseguida es útil decirle a R que variables corresponden a factores.

```{r}
gogglesData$gender <- factor(gogglesData$gender)
gogglesData$alcohol <- factor(gogglesData$alcohol)

str(gogglesData)
```

También podemos cambiar el nombre de las variables si nos facilita la tarea de hacer gráficos por ejemplo.

```{r}
levels(gogglesData$alcohol)[match("None", levels(gogglesData$alcohol))] <- "P0"
levels(gogglesData$alcohol)[match("2 Pints", levels(gogglesData$alcohol))] <- "P2"
levels(gogglesData$alcohol)[match("4 Pints", levels(gogglesData$alcohol))] <- "P4"

str(gogglesData)
```

Fíjate que el nivel base quedó al final.

```{r}
levels(gogglesData$alcohol)
```

Necesitamos reordenar los niveles para este factor.

```{r}
gogglesData$alcohol <- factor(gogglesData$alcohol,
                              levels = c("P0", "P2", "P4"))
levels(gogglesData$alcohol)
```

Luego, podemos hacer algunos gráficos para visualizar los efectos.
Por ejemplo, podemos hacer un histograma de los valores de atractivo en función del género y del consumo de alcohol.

```{r}
fig_boxplot1 <- ggplot(gogglesData, aes(alcohol, attractiveness)) +
  geom_boxplot() + 
  facet_wrap(~gender) + 
  labs(x = "Consumo de alcohol", y = "Atractivo promedio (%)") +
    theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
fig_boxplot1
```

Este mismo gráfico, valores de atractivo en función del género y del consumo de alcohol, se puede hacer en formato de líneas.


```{r}
fig_linesplot1 <- ggplot(gogglesData, aes(alcohol, attractiveness, colour = gender)) +
  stat_summary(fun.y = mean, geom = "point") +
  stat_summary(fun.y = mean, geom = "line", aes(group= gender)) +
  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2) +
  labs(x = "Consumo de alcohol", y = "Atractivo promedio (%)", colour = "Gender") +
    theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
fig_linesplot1
```

O en formato de barras.


```{r}
fig_barplot1 <- ggplot(gogglesData, aes(alcohol, attractiveness, fill = gender)) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar",
               position=position_dodge(width=0.90), width = 0.2) +
  stat_summary(fun.y = mean, geom = "bar", position="dodge") +
  labs(x = "Consumo de alcohol", y = "Atractivo promedio (%)", fill = "Gender") +  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
fig_barplot1
```

Estos gráfico son muy informativos. ¿Que ves?
Una manera de visualizar los efectos que estamos estudiando podemos separar los efectos. Esto es, podemos visualizar los niveles de atractivo en función de un sólo factor.

Por ejemplo, podemos visualizar el efecto del género en los niveles de atractivo.
Este efecto corresponde al *efecto principal* del género.

```{r}
fig_bargender1 <- ggplot(gogglesData, aes(gender, attractiveness)) +
  stat_summary(fun.y = mean, geom = "bar", 
               fill = "White", colour = "Black") +
  stat_summary(fun.data = mean_cl_normal, geom = "pointrange") +
  labs(x = "Género", y = "Atractivo promedio (%)") +
  scale_y_continuous(breaks=seq(0,80, by = 10)) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
fig_bargender1
```

También podemos visualizar el efecto del consumo de alcohol en los niveles de atractivo.
Este efecto corresponde al *efecto principal* del consumo de alcohol.

```{r}
fig_barbeer1 <- ggplot(gogglesData, aes(alcohol, attractiveness)) +
  stat_summary(fun.y = mean, geom = "bar", 
                   fill = "White", colour = "Black") +
  stat_summary(fun.data = mean_cl_normal, geom = "pointrange") +
  labs(x = "Consumo de alcohol", y = "Atractivo promedio (%)") +
  scale_y_continuous(breaks=seq(0,80, by = 10)) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"))
fig_barbeer1
```

Antes de hacer los análisis propiamente tal podemos describir un poco los datos y evaluar los supuestos de la estadística parámetrica.

```{r}
describ <- by(gogglesData$attractiveness, 
   gogglesData$gender, stat.desc)
lapply(describ, round, 2)
```

```{r}
describ <- by(gogglesData$attractiveness, 
              gogglesData$alcohol, stat.desc)
lapply(describ, round, 2)
```

```{r}
describ <- by(gogglesData$attractiveness, 
              list(gogglesData$alcohol, gogglesData$gender), 
              stat.desc, basic = FALSE)
lapply(describ, round, 2)
```

También podemos evaluar la homogenididad de varianza.

```{r}
leveneTest(gogglesData$attractiveness, 
           gogglesData$gender, center = median)
```

```{r}
leveneTest(gogglesData$attractiveness, 
           gogglesData$alcohol, center = median)
```


```{r}
leveneTest(gogglesData$attractiveness, 
           interaction(gogglesData$alcohol, gogglesData$gender),
           center = median)
```

Antes de hacer el análisis de ANOVA podemos aprovechar de setear las comparaciones planificadas.
¿Para un diseño de este tipo que comparaciones harías?

Una posibilidad es evaluar el efecto del género. Es decir, comparar hombres versus mujeres.
Para hacer esto usamos un dummy coding muy simple. ¿Por qué simple? Porque simplemente comparas uno contra el otro. Fijate en el orden de los niveles en cada factor.

```{r}
levels(gogglesData$gender)
```

Entonces, puedes crear el siguiente constraste

```{r}
.M_vs_F <- c(-1, 1)
.M_vs_F
```

Otra posibilidad es evaluar el efecto del consumo de alcohol. Es decir, comparar agua versus  pint versus 2 pints.Para hacer esto usamos otro dummy coding. Para hacer estos de nuevo nos fijamos en el orden de los niveles en cada factor.

```{r}
levels(gogglesData$alcohol)
```

¿Que efectos podríamos querer ver? Por ejemplo, el efecto de ingerir alcohol.

```{r}
.Non_vs_P <- c(-2, 1, 1)
.Non_vs_P
```

Otro efecto que podemos estudiar es la diferencia producidad por 1 pint versus 2 pints.

```{r}
.P2_vs_P4 <- c(0, -1, 1)
.P2_vs_P4
```

Una vez que creamos los contraste lo ponemos en un vector.

```{r}
contrasts(gogglesData$alcohol) <- cbind(.Non_vs_P, .P2_vs_P4)
contrasts(gogglesData$gender) <- cbind(.M_vs_F)
```

Y los inyectamos en las bases de datos.

```{r}
contrasts(gogglesData$alcohol) <- cbind(.Non_vs_P, .P2_vs_P4)
contrasts(gogglesData$gender) <- cbind(.M_vs_F)
```

Luego puedes verificar para el factor género, y ... 

```{r}
gogglesData$gender
```

... consumo de alcohol

```{r}
gogglesData$alcohol
```

Una vez que hemos seteado nuestros contrastes podemos hacer el modelo y visualizar los resultados.
En el modelo tratamos de predecir los valores de atractivo en base al género, el consumo de alcohol y la interacción entre ambos factores. Para ello se usa un simbolo (*) que indica que queremos analizar los efectos principales y el efecto de interacción.

```{r}
gogglesModel <- aov(attractiveness ~ gender*alcohol, gogglesData)
Anova(gogglesModel, type="III")
```

Si miras los valores de F verás que hay un efecto principal del alcohol y un efecto de interacción género-consumo de alcohol. El efecto principal que tenemos aquí refleja que hay un efecto del alcohol (mira el gráfico). Pero, fíjate que el efecto del alcohol en realidad esta calificado por una interación con el género. Es decir, el efecto del consumo de alcohol sobre los niveles de atractivo no son iguales para los dos géneros. En otras palabras. A la luz de una interacción no tiene sentido interpretar el efecto principal.

¿Qué indican los resultados? Ten en cuenta los resultados estadísticos y el gráfico.

```{r}
fig_linesplot1
```

Los resultados muestran que las mujeres mantienen altos estándares en la selección de su pareja sin importar el consumo de alcohol. Los hombres toman 4 pints y terminan con parejas que tienen un menor atractivo. Es decir, ocurre el "goggle bear effect".


Veamos las comparaciones planificadas para revisar mayores detalles.

```{r}
summary.lm(gogglesModel)
```

¿Qué vemos?
Primero. No hay un impacto del género (gender.M_vs_F).

Segundo. Parece que cualquier cantidad de alcohol afecta la percepción de atractivo cuando se compara con una condición sin alcohol (alcohol.Non_vs_P). Sin embargo, esto no es real. La comparación es significativa porque considera el efecto combinado de 2 y 4 pints, y las 4 pints tiene un efecto que arrastra el efecto total. De hecho si miramos el contraste de 2 versus 4 pints (alcohol.P2_vs_P4) vemos que hay un diferencia entre 2 y 4 pints. El promedio del grupo de 2 pints (64.69) es diferente del promedio del grupo de 4 pints (46.56). Esta diferencia es de -18.13 (46.56 - 64.69). El beta es este valor dividido por el número de grupos involucrados en el contraste (-18.13/2 = 9.06).

Tercero. En las interacciones (gender.M_vs_F:alcohol.Non_vs_P y gender.M_vs_F:alcohol.P2_vs_P4) se evalúan sí los efectos del consumo de alcohol son diferentes entre hombres y mujeres. Sabemos que esta interacción refleja que el efecto del consumo de alcohol depende del género. Al igual que en el punto anterior observamos que hay un diferencia entre consumir 4 pints y 2 pints, pero esto ocurre sólo para los hombres.

## ANOVA de medidas repetidas

Ahora vamos a hacer un análisis un ANOVA de medidas repetidas. Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas).

```{r}
setwd(Sys.getenv("BOOKDOWN_PROJECT_PATH"))

library(ggplot2)
library(Rmisc)
library(pastecs)
library(reshape)
library(ez)
library(multcomp)
```

Primero importamos el set de datos y le damos una mirada.

```{r}
dat1 <- read.csv("data/insectos_y_tiempo_vomito.csv", header = TRUE)
str(dat1)
```

Enseguida transformamos los datos de formato wide a long y renombramos las columnas.

```{r}
dat1.long <- melt(dat1, 
                 id = "participante", 
                 measured = c("insecto.al.palo", 
                              "testiculo.de.canguro", 
                              "ojos.de.pescado",
                              "larvas.de.polillas"))
names(dat1.long) <- c("participante", "animal", "vomito")
```

Antes de hacer cualquier análisis miramos los datos con un gráfico.
Usamos la función **summarySEwithin** para calcular los estadísticos.

```{r}
datac <- summarySEwithin(dat1.long, 
                         measurevar="vomito", 
                         withinvars="animal", 
                         idvar="participante")
```

Luego hacemos el gráfico.

```{r}
ggplot(datac, aes(x=animal, y=vomito, group=1)) +
  geom_errorbar(width=.1, aes(ymin=vomito-se, ymax=vomito+se)) +
  geom_line(colour = "Red", linetype = "dashed") + 
  geom_point() +
  ylab("Tiempo para vomitar (segundos)") +
  xlab("Tipo de comida") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Luego podemos tener una descripción de los datos.

```{r}
test <- by(dat1.long$vomito, 
           dat1.long$animal, 
           stat.desc, 
           basic = FALSE, 
           norm = TRUE)
lapply(test,round,2)
```

Finalmente, hacemos el análisis de ANOVA de medidas repetidas.

```{r}
model <- ezANOVA(data = dat1.long,
                 dv = .(vomito),
                 wid = .(participante),
                 within = .(animal),
                 type = 3,
                 detailed = TRUE)
model
```

¿Qué observamos?
El modelo sugiere que hay un efecto del tipo de animal sobre el número de vómitos.
Sin embargo, el test de Mauchly nos dice que no se cumple el supuesto de esfericidad.
Por lo tanto debemos mirar las correcciones (Greenhouse-Geisser [GG] o Huynd-Feldt [HF]).

Luego del análisis de ANOVA podemos evaluar que comparaciones son significativamente diferentes.

```{r}
pairwise.t.test(dat1.long$vomito, 
                dat1.long$animal,
                paired = TRUE, 
                p.adjust.method = "bonferroni")
```

Finalmente, también puedes notar que el modelo de ANOVA también describe el tamaño del efecto en forma de ges (generalized eta squared).

## ANCOVA

Ahora vamos a hacer un análisis un ANCOVA.
Imagina que estuvimos estudiando el efecto de una droga sobre los niveles de inteligencia de unos individuos (revisa el capítulo sobre ANOVA).

```{r}
setwd(Sys.getenv("BOOKDOWN_PROJECT_PATH"))

library(ggplot2)
library(Hmisc)
library(Rmisc)
library(effsize)
library(pastecs)
library(reshape2)
library(car)
library(effsize)
library(effects)
library(multcomp)
```

```{r}
dat1 <- read.csv("data/inteligencia.csv", header = TRUE)
dat1$Dosis <- factor(dat1$Dosis, 
                            levels = c(1:3), labels = c("Placebo", "Baja", "Alta"))
dat1

# Podemos usar esta función para calcular los estadísticos a través de los participantes.
datac <- summarySE(dat1, 
                   measurevar="Inteligencia", 
                   groupvars="Dosis")

# Luego hacemos el gráfico
ggplot(datac, aes(x=Dosis, y=Inteligencia, group=1)) +
  geom_errorbar(width=.1, aes(ymin=Inteligencia-se, ymax=Inteligencia+se)) +
  geom_line(colour = "Red", linetype = "dashed") + 
  geom_point() +
  ylab("Niveles de inteligencia") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Para el análisis de ANOVA observamos lo siguiente.

```{r}
m_AOV <- aov(Inteligencia ~ Dosis, data = dat1)
summary(m_AOV)
```

Según este análisis la droga tiene un efecto en los niveles de inteligencia.
Pero ¿qué pasa si tomamos en cuenta otros factores? Por ejemplo, qué pasa si tomamos en cuenta la edad de los participantes o los niveles de inteligencia de sus padres? Las variables continuas que no son parte de una manipulación experimental pero que tienen una influencia en la variable dependiente, se conocen como co-variables y se pueden incluir en un análisis de ANOVA. Cuándo medimos las co-variables y las incluimos en un análisis de varianza lo llamamos análisis de covarianza (o ANCOVA).

En el siguiente ejemplo vamos a analizar el efecto de la droga sobre los niveles de inteligencia considerando además los niveles de inteligencia de uno de sus progenitores.

Primero seteamos nuestro directorio de trabajo y cargamos las librerías que necesitemos (si no las tienes instaladas debes instalarlas).

```{r}
# 
dat2 <- read.csv("data/inteligencia_y_covariable.csv", header = TRUE)
dat2$dosis <- factor(dat2$dosis,
                   levels = c(1:3),
                   labels = c("Placebo",
                              "Low Dose",
                              "High Dose"))
```

Luego, pasamos los datos a formato long.

```{r}
restructuredData <- melt(dat2,
                         id = c("dosis"),
                         measured = c("inteligencia", "herencia"))
colnames(restructuredData) <- c("dosis", "aspecto", "valor")
```

Luego, podemos hacer algunos gráficos.
Por ejemplo, podemos visualizar los niveles de inteligencia en función de la dosis de droga. Al mismo podemos ver como que diferencias hay los niveles de inteligencia heredados.

```{r}
ggplot(restructuredData, aes(dosis, valor)) +
  geom_boxplot() +
  facet_wrap(~aspecto) +
  labs(x="Dosis", y ="Inteligencia") +
     theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Podemos observar cómo cambian los niveles de inteligencia individual en función de los niveles de inteligencia de los progenitores. Y podemos ver como cambia estos para los distintos niveles de droga.

```{r}
ggplot(dat2, aes(herencia, inteligencia, colour = dosis)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x="Inteligencia heredada", y ="Inteligencia evocada por la droga") + 
   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

En seguida podemos hacer una descripción de los datos.

```{r}
as.data.frame(lapply(by(dat2$inteligencia, 
                        dat2$dosis,
                        stat.desc, 
                        basic = FALSE, 
                        norm = TRUE), 
                     round, 2))
```

```{r}
as.data.frame(lapply(by(dat2$herencia,
                        dat2$dosis,
                        stat.desc, 
                        basic = FALSE, 
                        norm = TRUE), 
                     round, 2))
```

Podemos ver el gran promedio de inteligencia evocada por la droga (a travaés de todas las dosis).

```{r}
as.data.frame(lapply(stat.desc(dat2$inteligencia,
                               basic = FALSE), 
                     round, 2))
```

Podemos ver el gran promedio de inteligencia heredada (a travaés de todas las dosis).

```{r}
as.data.frame(lapply(stat.desc(dat2$herencia,
                               basic = FALSE), 
                     round, 2))
```

Luego podemos evaluar la homogeneidad de la varianza.

```{r}
leveneTest(dat2$inteligencia, dat2$dosis, center = median)
```

Dentro de los supuestos del ANCOVA debemos probar que nuestra variable independiente y la co-variable producen efectos independientes. Es decir, debemos probar que la co-variable no es afectada por la variable independiente.

```{r}
checkIndependenceModel <- aov(herencia ~ dosis, data = dat2)
summary(checkIndependenceModel)
summary.lm(checkIndependenceModel)
```

La inteligencia heredada fue aproximadamente equivalente a través de las tres condiciones de drogas (placebo, dosis baja y alta). Este resultado nos permite decir que es apropiado utilizar la inteligencia heredada como co-variable en el análisis de ANCOVA.

El ANCOVA se realiza como cualquier modelo lineal. Es necesario mencionar que cuando hacemos un modelo, R calcula usa una suma de cuadrados de Tipo I (o sumas secuenciales de cuadrados) por defecto. Esto significa que cualquier predictor ingresado en el modelo se evalúa después de los predictores anteriores en el modelo. Típicamente en los modelos tradicionales se usa una suma de cuadrados de tipo III, dónde los efectos de los predictores se evalúan después que se toman en cuenta todos los otros predictores. Para hacer esto creamos el modelo y luego usamos la función **Anova** e indicamos que queremos usar la suma de cuadrados de tipo III.

```{r}
ANCOVA_model <- aov(inteligencia ~ herencia + dosis, dat2)
Anova(ANCOVA_model, type="III")
```

¿Cómo se interpretan estos resultados?
Lo primero que vemos es que los niveles de inteligencia individuales son modulados por los niveles de inteligencia de los progenitores. Más interesante aún es el segundo resultado, que indica que los niveles de inteligencia son modulados por la dosis de droga, incluso cuando los efectos de los niveles de inteligencia heredados son controlados.

En suma, si hubieramos hecho sólo el ANOVA hubieramos observado lo siguiente:

```{r}
anovaModel <- aov(inteligencia ~ dosis, dat2)
summary(anovaModel)
```

Pero, evaluando los niveles de inteligencia controlando por los niveles de inteligencia heredada llegamos a una conclusión distinta.

En el modelo de ANCOVA queda por mirar los gráficos.

```{r}
plot(ANCOVA_model)
```

¿Qué vemos?
El primer gráfico se puede usar para evaluar la homogeneidad de la varianza: si tiene forma de embudo, entonces estamos en problemas. En nuestro caso vemos que la dispersión de puntajes es más amplia en algunos puntos que en otros. Esto implica que los residuales pueden estar distribuidos de forma heteroscedástica.

El segundo gráfico es un gráfico Q-Q que nos informa sobre la normalidad de los residuos en el modelo. Queremos que nuestros residuos se distribuyan normalmente, lo que significa que los puntos en el gráfico deben flotar alrededor de la línea diagonal. En nuestro los puntos se alejan de esta tendencia. Nuevamente, esta no es una buena noticia para el modelo. Estos gráficos sugieren que sería necesario realizar una versión robusta de ANCOVA.

A pesar de los problemas que hayamos detectado, y con el objetivo de hacer un análisis completo del análisis de ANCOVA veremos otros aspectos importantes.

Otro de los supuestos del ANCOVA que debemos probar es que existe una homogeneidad de las pendientes de regresión. Este supuesto significa que la relación entre la co-variable y la variable resultado (en este caso, inteligencia e inteligencia heredada) debe ser similar en diferentes niveles de la variable predictora (en este caso, en los tres grupos de dosis). Para probar esto, necesitamos ejecutar de nuevo un ANCOVA pero incluyendo la interacción entre la co-variable y la variable predictora.

```{r}
hoRS <- aov(inteligencia ~ herencia*dosis,
            dat2)
Anova(hoRS, type = "III")
```

Los efectos de la dosis de droga y la inteligencia heredada siguen siendo significativos, pero lo principal que nos interesa es la interacción. Un valor significativo en esta interacción sugiere que no cumple el supuesto de homogeneidad de las pendientes de regresión.

Para los contrastes planificados podemos hacer algo similar a lo que hemos hecho antes.

```{r}
.plac_vs_drug <- c(-2, 1, 1)
.high_vs_low <- c(0, -1, 1)
contrasts(dat2$dosis) <- cbind(.plac_vs_drug, .high_vs_low)
```

Una vez que definimos los contrastes los podemos inyectar en la base de datos y luego realizamos el modelo nuevamente.

```{r}
ANCOVA_model <- aov(inteligencia ~ dosis + herencia, dat2)
```

¿Cómo se interpretan estos resultados?
Antes de mirar las comparaciones planificadas es buena idea calcular los promedios ajustados. En este caso en particular queremos saber los promedios de inteligencia en función de las dosis de droga ajustados por los niveles de inteligencia heredados. Para ello usamos la función **effect**. También podemos acceder a los SE de estos promedios.

```{r}
adjustedMeans <- effect("dosis", ANCOVA_model, se=TRUE)
summary(adjustedMeans)
adjustedMeans$se
```

A diferencia de los promedios originales, cuando se ajustan los promedios se observa que los promedios de inteligencia para dosis alta y baja son bastante diferentes. Es decir, cuando se ajuste por los efectos de la inteligencia de los progenitores, a medida que aumenta la dosis de droga aumentan los niveles de inteligencia de los individuos.

Veamos los contrastes planificados.

```{r}
summary.lm(ANCOVA_model)
```

En estos contrastes comparamos el efecto de la droga relativo al placebo (contraste 1) y el efecto de la dosis alta versus la dosis baja (contraste 2). Pero, además estos contrates están ajustados por los niveles de inteligencia heredados. ¿Qué vemos? Primero, que hay un efecto de la droga por sobre el placebo. Segundo. No parece haber una efecto de la dosis alta por sobre la dosis baja. 

El modelo además nos dice que hay una relación entre los niveles de inteligencia producidos por la droga y los niveles de inteligencia heredados. El beta es ~0.42. Asumiendo los otros factores en igualdad de condiciones, si la inteligencia del progenitor de un individuo aumenta en una 1 unidad, la inteligencia del individuo aumenta en alredor de la mitad. Esto los podemos ver en el siguiente gráfico.

```{r}
ggplot(dat2, aes(herencia, inteligencia)) +
  geom_point() +
  geom_smooth(method = "lm") +
  labs(x="Inteligencia heredada", y ="Inteligencia evocada") + 
   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Por último, también podemos hacer pruebas posthoc. Para hacer estos análisis en los promedios ajustados debemos usar la función **glht**.

```{r}
postHocs <- glht(ANCOVA_model, linfct = mcp(dosis = "Tukey"))
summary(postHocs)
confint(postHocs)
```

De este análisis observamos que sólo hay diferencias de inteligencia (cuando controlamos por los efecto de inteligencia heredada) cuando comparamos el placebo y la dosis alta de droga.

## MANOVA

Ahora vamos a hacer un análisis de MANOVA.
El análisis de MANOVA se realizar porque el ANOVA lidia más que nada con una variable dependiente. Pero, ¿qué pasa cuando realizamos muchas mediciones? 

En el siguiente estudio se aplicaron distintos tratamientos para enfrentar cierto tipo de problemas psicopatológicos. Había un grupo control (NT), y grupos a que se le aplicaron terapia condutual (BT) o terapia cognitivo-conductual (CBT). Además, de estos grupos (que reflejan las variables independientes), se midió la frecuencia de dos cosas: conductas y pensamientos.

Para empezar carguemos las librerías.

```{r}
setwd(Sys.getenv("BOOKDOWN_PROJECT_PATH"))

library(car)
library(ggplot2)
library(mvnormtest)
#library(mvoutlier)
library(pastecs)
library(reshape)
#library(WRS)
```

Carguemos los datos.

```{r}
ocdData <- read.csv("data/OCD.csv", header = TRUE)
ocdData$Grupo <- factor(ocdData$Grupo,
                        levels = c("CBT", "BT", "No Treatment Control"),
                        labels = c("CBT", "BT", "NT"))
```

Re-ordenemos los niveles dentro del factor de grupo para que en el gráfico aparezca el grupo control en primer lugar.

```{r}

ocdData$Grupo <- factor(ocdData$Grupo,
                        levels(ocdData$Grupo)[c(3,1,2)])
```

Luego transformemos los datos a formato Long-.

```{r}

ocdMelt <- melt(ocdData, 
                id = c("Grupo"),
                measured = c("Acciones", "Pensamientos"))
names(ocdMelt) <- c("Grupo", "Medicion", "Frecuencia")
```

Hagamos un gráfico de dispersión.

```{r}
ocdScatter <- ggplot(ocdData, aes(Acciones, Pensamientos))
ocdScatter + geom_point() + geom_smooth(method = "lm") +
  labs(x = "Conductas obsesivas", y = "Pensamientos obsesivos") +
  facet_wrap(~Grupo, ncol = 3) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Hagamos un gráfico de barras.

```{r}
ocdBar <- ggplot(ocdMelt, aes(Grupo, Frecuencia, fill = Medicion))
ocdBar + 
  stat_summary(fun.data = mean_cl_boot,
               geom = "errorbar", 
               position = position_dodge(width=0.90),
               width = 0.2) +
  stat_summary(fun.y = mean, 
               geom = "bar", 
               position = "dodge") +
  labs(x = "Grupo", y = "Frencuencia", fill = "Medición") + 
  scale_y_continuous(breaks = seq(0, 20, by = 2)) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Hagamos un histograma.

```{r}
ocdBoxplot <- ggplot(ocdMelt, aes(Grupo, Frecuencia, colour = Medicion))
ocdBoxplot + 
  geom_boxplot() + 
  labs(x = "Grupo", y = "Frecuencia", colour = "Medición") + 
  scale_y_continuous(breaks = seq(0, 20, by = 2)) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))
```

Luego podemos hacer una descripción de los datos.

```{r}
descrip <- by(ocdData$Acciones, 
           ocdData$Grupo, 
           stat.desc, 
           basic = FALSE, 
           norm = TRUE)
lapply(descrip,round,2)
```

```{r}
descrip <- by(ocdData$Pensamientos, 
           ocdData$Grupo, 
           stat.desc, 
           basic = FALSE, 
           norm = TRUE)
lapply(descrip,round,2)
```

Luego de describir los datos podemos comprobar algunos supuestos antes de hacer el análisis de MANOVA.

Primero debemos chequear la homogeneidad de las matrices de covarianza, comparando los valores que encontremos. Idealmente deberían ser similares a través de los grupos.

```{r}
by(ocdData[, 2:3], ocdData$Grupo , cov)
```

En este caso se encuentran diferencias, pero ya que los grupos tienen un n similar no es algo de lo que tengamos que preocuparnos.

Luego tenemos que testear la normalidad multivariada. Para ello necesitamos aplicar una prueba de normalidada los grupos individuales, y transponer los datos para que estén en un formato adecuado.

```{r}
nt <- t(ocdData[21:30, 2:3])
cbt <- t(ocdData[1:10, 2:3])
bt <- t(ocdData[11:20, 2:3])

mshapiro.test(nt)
mshapiro.test(cbt)
mshapiro.test(bt)
```

El análisis sugiere que podrían haber problemas de normalidad en el grupo control. Por ahora lo vamos a ignorar. Pero mirando los datos se puede detectar un outlier. Y eliminando este outlier se puede realizar el análisis de normalidad para revisar si haciendo esto se corrige el problema de normalidad.

Antes de hacer el análisis principal podemos setear nuestros contrastes de interés.

```{r}
.NT_vs_CBT <- c(1, 0, 0)
.NT_vs_BT <- c(0, 1, 0)
contrasts(ocdData$Grupo) <- cbind(.NT_vs_CBT, .NT_vs_BT)
```

Luego para definir la variable dependiente creamos un vector con las dos mediciones.
Luego se realiza el modelo de la misma forma como se define en una regresión simple.
Finalmente revisamos el resultados del modelo.

```{r}
outcome <- cbind(ocdData$Acciones, ocdData$Pensamientos)
ocdModel <- manova(outcome ~ Grupo, data = ocdData)
summary(ocdModel, intercept = TRUE)
```

Hay cuatro pruebas estadísticas que se pueden usar en MANOVA (traza de Pillai, lambda de Wilks, traza de Hotelling y prueba de raíz más grande de Roy). La prueba usada mas común es la traza de Pillai. Pero otras pruebas se pueden usar para condiciones particulares.

Otros análisis se pueden hacer de la siguiente manera:

```{r}
summary(ocdModel, intercept = TRUE, test = "Wilks")
summary(ocdModel, intercept = TRUE, test = "Hotelling")
summary(ocdModel, intercept = TRUE, test = "Roy")
```

Finalmente luego de este análisis se pueden hacer análisis tipo ANOVA.
Se puede aplicar 

```{r}
# Recuerda: outcome <- cbind(ocdData$Acciones, ocdData$Pensamientos)
summary.aov(ocdModel)

```

Para los análisis de ANOVA observamos que no existen diferencias significativas entre los distintos tipos de terapia. Sólo con el fin de completar los análisis vamos a revisar las comparaciones planificadas. Pero no podemos intepretar estos resultados.

Se pueden analizar los cambios en la frecuencia de acciones en función de los tratamientos.

```{r}
actionModel <- lm(Acciones ~ Grupo, data = ocdData)
summary.lm(actionModel)
```

Se pueden analizar los cambios en la frecuencia de pensamientos en función de los tratamientos.

```{r}
thoughtsModel <- lm(Pensamientos ~ Grupo, data = ocdData)
summary.lm(thoughtsModel)
```
